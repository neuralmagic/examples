{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Hugging Face Models Using Optimum and Running Them in DeepSparse\n",
    "\n",
    "This guide harnesses the power of Neural Magic's DeepSparse Inference Runtime library in combination with Hugging Face's ONNX models. DeepSparse offers a cutting-edge solution for efficient and accelerated inference on deep learning models, optimizing performance and resource utilization. By seamlessly integrating DeepSparse with Hugging Face's ONNX models, users can experience lightning-fast inference times while maintaining the flexibility and versatility of the widely adopted ONNX format alongside the  `Optimum` library for PyTorch model ONNX exporting.\n",
    "\n",
    "This notebook will use several popular models found on the Hugging Face Hub for text classification, zero-shot classification, question answering, and NER.\n",
    "\n",
    "The flow for this guide includes:\n",
    "\n",
    "1. Exporting models to ONNX using `optimum-cli`.\n",
    "2. Running inference with ONNX models with DeepSparse.\n",
    "\n",
    "## Install DeepSparse and Optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepsparse-nightly[transformers] in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (1.6.0.20230811)\n",
      "Requirement already satisfied: optimum[exporters] in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (1.11.2)\n",
      "Requirement already satisfied: sparsezoo-nightly~=1.6.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (1.6.0.20230811)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (1.21.6)\n",
      "Requirement already satisfied: onnx<1.15.0,>=1.5.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (1.12.0)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.8.2 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (1.10.12)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.0.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (4.66.1)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (3.20.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (8.0.4)\n",
      "Requirement already satisfied: nm-transformers-nightly~=1.6.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (1.6.0.20230811)\n",
      "Requirement already satisfied: datasets<=2.11 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (1.18.4)\n",
      "Requirement already satisfied: scikit-learn in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (1.3.0)\n",
      "Requirement already satisfied: seqeval in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse-nightly[transformers]) (1.2.2)\n",
      "Requirement already satisfied: coloredlogs in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from optimum[exporters]) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from optimum[exporters]) (1.12)\n",
      "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from optimum[exporters]) (4.31.0)\n",
      "Requirement already satisfied: torch>=1.9 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from optimum[exporters]) (2.0.0)\n",
      "Requirement already satisfied: packaging in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from optimum[exporters]) (23.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from optimum[exporters]) (0.16.4)\n",
      "Requirement already satisfied: onnxruntime in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from optimum[exporters]) (1.15.1)\n",
      "Requirement already satisfied: timm in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from optimum[exporters]) (0.9.5)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from datasets<=2.11->deepsparse-nightly[transformers]) (12.0.1)\n",
      "Requirement already satisfied: dill in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from datasets<=2.11->deepsparse-nightly[transformers]) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from datasets<=2.11->deepsparse-nightly[transformers]) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from datasets<=2.11->deepsparse-nightly[transformers]) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from datasets<=2.11->deepsparse-nightly[transformers]) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from datasets<=2.11->deepsparse-nightly[transformers]) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from datasets<=2.11->deepsparse-nightly[transformers]) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from datasets<=2.11->deepsparse-nightly[transformers]) (0.18.0)\n",
      "Requirement already satisfied: filelock in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (3.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (4.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from nm-transformers-nightly~=1.6.0->deepsparse-nightly[transformers]) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from nm-transformers-nightly~=1.6.0->deepsparse-nightly[transformers]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from nm-transformers-nightly~=1.6.0->deepsparse-nightly[transformers]) (0.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly[transformers]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly[transformers]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly[transformers]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly[transformers]) (2023.7.22)\n",
      "Requirement already satisfied: py-machineid>=0.3.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from sparsezoo-nightly~=1.6.0->deepsparse-nightly[transformers]) (0.4.3)\n",
      "Requirement already satisfied: geocoder>=1.38.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from sparsezoo-nightly~=1.6.0->deepsparse-nightly[transformers]) (1.38.1)\n",
      "Requirement already satisfied: networkx in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torch>=1.9->optimum[exporters]) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->optimum[exporters]) (59.5.0)\n",
      "Requirement already satisfied: wheel in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->optimum[exporters]) (0.41.1)\n",
      "Requirement already satisfied: cmake in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.9->optimum[exporters]) (3.27.2)\n",
      "Requirement already satisfied: lit in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.9->optimum[exporters]) (16.0.6)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum[exporters]) (0.1.99)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from coloredlogs->optimum[exporters]) (10.0)\n",
      "Requirement already satisfied: flatbuffers in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from onnxruntime->optimum[exporters]) (23.5.26)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from scikit-learn->deepsparse-nightly[transformers]) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from scikit-learn->deepsparse-nightly[transformers]) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from scikit-learn->deepsparse-nightly[transformers]) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from sympy->optimum[exporters]) (1.3.0)\n",
      "Requirement already satisfied: torchvision in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from timm->optimum[exporters]) (0.15.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from aiohttp->datasets<=2.11->deepsparse-nightly[transformers]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from aiohttp->datasets<=2.11->deepsparse-nightly[transformers]) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from aiohttp->datasets<=2.11->deepsparse-nightly[transformers]) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from aiohttp->datasets<=2.11->deepsparse-nightly[transformers]) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from aiohttp->datasets<=2.11->deepsparse-nightly[transformers]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from aiohttp->datasets<=2.11->deepsparse-nightly[transformers]) (1.3.1)\n",
      "Requirement already satisfied: future in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly[transformers]) (0.18.3)\n",
      "Requirement already satisfied: ratelim in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly[transformers]) (0.1.6)\n",
      "Requirement already satisfied: six in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly[transformers]) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from pandas->datasets<=2.11->deepsparse-nightly[transformers]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from pandas->datasets<=2.11->deepsparse-nightly[transformers]) (2023.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from jinja2->torch>=1.9->optimum[exporters]) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from torchvision->timm->optimum[exporters]) (9.5.0)\n",
      "Requirement already satisfied: decorator in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from ratelim->geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly[transformers]) (5.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install deepsparse-nightly[transformers] optimum[exporters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification | Sentiment Analysis\n",
    "\n",
    "Let's export the DistilBERT SST-2 model for sentiment analysis to an output folder called `tc_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Framework not specified. Using pt to export to ONNX.\n",
      "Automatic task detection to text-classification (possible synonyms are: sequence-classification, zero-shot-classification).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeroshot/nm/examples/env/bin/optimum-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/zeroshot/nm/examples/env/lib/python3.10/site-packages/optimum/commands/optimum_cli.py\", line 163, in main\n",
      "    service.run()\n",
      "  File \"/home/zeroshot/nm/examples/env/lib/python3.10/site-packages/optimum/commands/export/onnx.py\", line 219, in run\n",
      "    main_export(\n",
      "  File \"/home/zeroshot/nm/examples/env/lib/python3.10/site-packages/optimum/exporters/onnx/__main__.py\", line 446, in main_export\n",
      "    _, onnx_outputs = export_models(\n",
      "  File \"/home/zeroshot/nm/examples/env/lib/python3.10/site-packages/optimum/exporters/onnx/convert.py\", line 760, in export_models\n",
      "    export(\n",
      "  File \"/home/zeroshot/nm/examples/env/lib/python3.10/site-packages/optimum/exporters/onnx/convert.py\", line 838, in export\n",
      "    raise MinimumVersionError(\n",
      "optimum.exporters.error_utils.MinimumVersionError: The current version of Transformers does not allow for the export of the model. Minimum required is 4.25.0, got: 1.5.0.42301\n"
     ]
    }
   ],
   "source": [
    "!optimum-cli export onnx --model distilbert-base-uncased-finetuned-sst-2-english tc_model --sequence_length 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and run inference with DeepSparse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsparse import Pipeline\n",
    "\n",
    "text_input = \"Snorlax loves my Tesla!\"\n",
    "\n",
    "pipe = Pipeline.create(task=\"sentiment-analysis\", model_path=\"./tc_model/\")\n",
    "inference = pipe(text_input)\n",
    "print(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepsparse -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER\n",
    "\n",
    "Let's export the BERT Base NER model to an output folder called `ner_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!optimum-cli export onnx --model dslim/bert-base-NER ner_model --sequence_length 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and run inference with DeepSparse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from deepsparse import Pipeline\n",
    "\n",
    "def run_deepsparse(model_path, text_input, task):\n",
    "    pipeline = Pipeline.create(task=task, model_path=model_path)\n",
    "    start_time = perf_counter()\n",
    "    inference = pipeline(text_input)\n",
    "    end_time = perf_counter()\n",
    "    execution_time_deepsparse = end_time - start_time\n",
    "    return inference, execution_time_deepsparse\n",
    "\n",
    "model_path = \"./ner_model/model.onnx\"\n",
    "task = \"token-classification\"\n",
    "text_input = \"Snorlax loves my Tesla!\"\n",
    "\n",
    "inference_deepsparse, execution_time_deepsparse = run_deepsparse(model_path, text_input, task)\n",
    "print(f\"Deepsparse code snippet execution time: {execution_time_deepsparse:.4f} seconds\")\n",
    "print(inference_deepsparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "\n",
    "Let's export the RoBERTa Base model for Question Answering to an output folder called `qa_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!optimum-cli export onnx --model deepset/roberta-base-squad2 qa_model --sequence_length 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and run inference with DeepSparse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from deepsparse import Pipeline\n",
    "\n",
    "def run_deepsparse(model_path, question, context, task):\n",
    "    pipeline = Pipeline.create(task=task, model_path=model_path)\n",
    "    start_time = perf_counter()\n",
    "    inference = pipeline(question=\"What's my name?\", context=\"My name is Snorlax\")\n",
    "    end_time = perf_counter()\n",
    "    execution_time_deepsparse = end_time - start_time\n",
    "    return inference, execution_time_deepsparse\n",
    "\n",
    "\n",
    "model_path = \"./qa_model/model.onnx\"\n",
    "task = \"question-answering\"\n",
    "question = \"who loves Tesla?\"\n",
    "context = \"Snorlax loves my Tesla?\"\n",
    "\n",
    "inference_deepsparse, execution_time_deepsparse = run_deepsparse(model_path, question, context, task)\n",
    "print(f\"Deepsparse code snippet execution time: {execution_time_deepsparse:.4f} seconds\")\n",
    "print(inference_deepsparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot Text Classification\n",
    "\n",
    "Let's export the DistilBERT MNLI Base model to an output folder called `zs_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!optimum-cli export onnx --model typeform/distilbert-base-uncased-mnli zs_model --sequence_length 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and run inference with DeepSparse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from deepsparse import Pipeline\n",
    "\n",
    "def run_deepsparse(model_path, text_input, task, labels):\n",
    "    pipeline = Pipeline.create(\n",
    "        task=task, model_scheme=\"mnli\", \n",
    "        model_config={\"hypothesis_template\": \"This text is related to {}\"}, \n",
    "        model_path=model_path\n",
    "    )\n",
    "    start_time = perf_counter()\n",
    "    inference = pipeline(text_input, labels)\n",
    "    end_time = perf_counter()\n",
    "    execution_time_deepsparse = end_time - start_time\n",
    "    return inference, execution_time_deepsparse\n",
    "\n",
    "model_path = \"./zs_model/model.onnx\"\n",
    "task = \"zero_shot_text_classification\"\n",
    "text_input = \"I like pepperoni pizza.\"\n",
    "labels = [\"food\", \"movies\", \"sports\"]\n",
    "\n",
    "inference_deepsparse, execution_time_deepsparse = run_deepsparse(model_path, text_input, task, labels)\n",
    "print(f\"Deepsparse code snippet execution time: {execution_time_deepsparse:.4f} seconds\")\n",
    "print(inference_deepsparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "\n",
    "Let's export the Resnet-50 model to an output folder called `ic_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!optimum-cli export onnx --model microsoft/resnet-50 ic_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and run inference with DeepSparse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from deepsparse import Pipeline\n",
    "\n",
    "def run_deepsparse(model_path, image, task):\n",
    "    pipeline = Pipeline.create(task=task, model_path=model_path, input_shapes=[1,3,224,224])\n",
    "    start_time = perf_counter()\n",
    "    inference = pipeline(images=image)\n",
    "    end_time = perf_counter()\n",
    "    execution_time_deepsparse = end_time - start_time\n",
    "    return inference, execution_time_deepsparse\n",
    "\n",
    "image = \"./notebooks/optimum-export/cat.jpg\"\n",
    "model_path =\"ic_model/model.onnx\"\n",
    "task = \"image_classification\"\n",
    "\n",
    "inference_deepsparse, execution_time_deepsparse = run_deepsparse(model_path, image, task)\n",
    "print(f\"Deepsparse code snippet execution time: {execution_time_deepsparse:.4f} seconds\")\n",
    "print(inference_deepsparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Segmentation\n",
    "\n",
    "Let's export the DEtection TRansformer(DETR) model to an output folder called `is_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!optimum-cli export onnx --model facebook/detr-resnet-50-panoptic is_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and run inference with DeepSparse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from deepsparse import Pipeline\n",
    "\n",
    "def run_deepsparse(model_path, image, task):\n",
    "    pipeline = Pipeline.create(task=task, model_path=model_path, input_shapes=[1,3,224,224], image_size=(224,224))\n",
    "    start_time = perf_counter()\n",
    "    inference = pipeline(images=image)\n",
    "    end_time = perf_counter()\n",
    "    execution_time_deepsparse = end_time - start_time\n",
    "    return inference, execution_time_deepsparse\n",
    "\n",
    "image = \"./notebooks/optimum-export/thailand.jpeg\"\n",
    "model_path =\"is_model/model.onnx\"\n",
    "task = \"yolov8\"\n",
    "\n",
    "inference_deepsparse, execution_time_deepsparse = run_deepsparse(model_path, image, task)\n",
    "print(f\"Deepsparse code snippet execution time: {execution_time_deepsparse:.4f} seconds\")\n",
    "print(inference_deepsparse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
