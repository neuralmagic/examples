{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fus1Bm2nY3hv"
      },
      "source": [
        "# Exporting Hugging Face Models Using Optimum and Running Them in DeepSparse\n",
        "\n",
        "This guide harnesses the power of Neural Magic's DeepSparse Inference Runtime library in combination with Hugging Face's ONNX models. DeepSparse offers a cutting-edge solution for efficient and accelerated inference on deep learning models, optimizing performance and resource utilization. By seamlessly integrating DeepSparse with Hugging Face's ONNX models, users can experience lightning-fast inference times while maintaining the flexibility and versatility of the widely adopted ONNX format alongside the  `Optimum` library for PyTorch model ONNX exporting.\n",
        "\n",
        "This notebook will use several popular models found on the Hugging Face Hub for text classification, zero-shot classification, question answering, and NER.\n",
        "\n",
        "The flow for this guide includes:\n",
        "\n",
        "1. Exporting models to ONNX using `optimum-cli`.\n",
        "2. Running inference with ONNX models with DeepSparse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug3U5GeMY6Bg"
      },
      "source": [
        "## Install DeepSparse and Optimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul9jw3lyYENL",
        "outputId": "c65d6282-cd32-45c4-dbba-69a34deef900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepsparse-nightly in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (1.6.0.20230906)\n",
            "Collecting optimum[exporters]\n",
            "  Using cached optimum-1.13.1-py3-none-any.whl (396 kB)\n",
            "Requirement already satisfied: sparsezoo-nightly~=1.6.0 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from deepsparse-nightly) (1.6.0.20230906)\n",
            "Requirement already satisfied: requests>=2.0.0 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from deepsparse-nightly) (2.31.0)\n",
            "Requirement already satisfied: onnx<1.15.0,>=1.5.0 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from deepsparse-nightly) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from deepsparse-nightly) (3.20.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from deepsparse-nightly) (8.1.7)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from deepsparse-nightly) (4.66.1)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.8.2 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from deepsparse-nightly) (1.10.12)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from deepsparse-nightly) (1.21.6)\n",
            "Requirement already satisfied: packaging in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from optimum[exporters]) (23.1)\n",
            "Collecting coloredlogs\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Collecting huggingface-hub>=0.8.0\n",
            "  Using cached huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
            "Collecting transformers[sentencepiece]>=4.26.0\n",
            "  Using cached transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "Collecting sympy\n",
            "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "Requirement already satisfied: torch>=1.9 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from optimum[exporters]) (1.12.0)\n",
            "Collecting datasets\n",
            "  Using cached datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "Collecting timm\n",
            "  Using cached timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "Collecting onnxruntime\n",
            "  Using cached onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2023.9.1-py3-none-any.whl (173 kB)\n",
            "Collecting filelock\n",
            "  Using cached filelock-3.12.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly) (3.2.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly) (3.4)\n",
            "Requirement already satisfied: geocoder>=1.38.0 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from sparsezoo-nightly~=1.6.0->deepsparse-nightly) (1.38.1)\n",
            "Requirement already satisfied: pandas>1.3 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from sparsezoo-nightly~=1.6.0->deepsparse-nightly) (2.0.3)\n",
            "Requirement already satisfied: py-machineid>=0.3.0 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from sparsezoo-nightly~=1.6.0->deepsparse-nightly) (0.4.3)\n",
            "Collecting regex!=2019.12.17\n",
            "  Using cached regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
            "Collecting safetensors>=0.3.1\n",
            "  Using cached safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91\n",
            "  Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Collecting multiprocess\n",
            "  Using cached multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "Collecting aiohttp\n",
            "  Using cached aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Collecting fsspec[http]<2023.9.0,>=2023.1.0\n",
            "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
            "Collecting xxhash\n",
            "  Using cached xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Collecting pyarrow>=8.0.0\n",
            "  Using cached pyarrow-13.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.0 MB)\n",
            "Collecting dill<0.3.8,>=0.3.0\n",
            "  Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "Collecting flatbuffers\n",
            "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Requirement already satisfied: torchvision in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from timm->optimum[exporters]) (0.13.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Using cached multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Using cached yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: ratelim in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (0.1.6)\n",
            "Requirement already satisfied: six in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (1.16.0)\n",
            "Requirement already satisfied: future in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (0.18.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from pandas>1.3->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from pandas>1.3->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (2023.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from pandas>1.3->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (2023.3.post1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from torchvision->timm->optimum[exporters]) (10.0.1)\n",
            "Requirement already satisfied: decorator in /home/zeroshot/nm/examples/env1/lib/python3.10/site-packages (from ratelim->geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (5.1.1)\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, mpmath, flatbuffers, xxhash, sympy, regex, pyarrow, multidict, humanfriendly, fsspec, frozenlist, filelock, dill, attrs, async-timeout, yarl, multiprocess, huggingface-hub, coloredlogs, aiosignal, transformers, timm, onnxruntime, aiohttp, datasets, optimum\n",
            "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 coloredlogs-15.0.1 datasets-2.14.5 dill-0.3.7 filelock-3.12.4 flatbuffers-23.5.26 frozenlist-1.4.0 fsspec-2023.6.0 huggingface-hub-0.17.1 humanfriendly-10.0 mpmath-1.3.0 multidict-6.0.4 multiprocess-0.70.15 onnxruntime-1.15.1 optimum-1.13.1 pyarrow-13.0.0 regex-2023.8.8 safetensors-0.3.3 sentencepiece-0.1.99 sympy-1.12 timm-0.9.7 tokenizers-0.13.3 transformers-4.33.2 xxhash-3.3.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install deepsparse-nightly optimum[exporters]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AO46o2fZgM7"
      },
      "source": [
        "## Text Classification | Sentiment Analysis\n",
        "\n",
        "Let's export the `SamLowe/roberta-base-go_emotions` model for sentiment analysis to an output folder called `tc_model`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr4nR_bwYGHQ",
        "outputId": "794a9ed0-131c-43ce-b2d8-27b3d345c07b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Framework not specified. Using pt to export to ONNX.\n",
            "Automatic task detection to text-classification (possible synonyms are: sequence-classification, zero-shot-classification).\n",
            "Using the export variant default. Available variants are:\n",
            "\t- default: The default ONNX variant.\n",
            "Using framework PyTorch: 2.0.1+cu117\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Post-processing the exported models...\n",
            "Weight deduplication check in the ONNX export requires accelerate. Please install accelerate to run it.\n",
            "Validating models in subprocesses...\n",
            "Validating ONNX model tc_model/model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (logits)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 28) matches (2, 28)\n",
            "\t\t-[✓] all values close (atol: 0.0001)\n",
            "The ONNX export succeeded and the exported model was saved at: tc_model\n"
          ]
        }
      ],
      "source": [
        "!optimum-cli export onnx --model SamLowe/roberta-base-go_emotions tc_model --sequence_length 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHXqLF-tZnSR"
      },
      "source": [
        "Load model and run inference with DeepSparse:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zoqimTNZpCY",
        "outputId": "3fc6cd2a-2f49-4e9d-89d5-8ca3f5a5b30e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeroshot/nm/examples/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-09-13 09:56:38 deepsparse.transformers WARNING  The neuralmagic fork of transformers may not be installed. It can be installed via `pip install nm_transformers`\n",
            "2023-09-13 09:56:38 __main__     INFO     Overwriting in-place the input shapes of the transformer model at ./tc_model/model.onnx\n",
            "DeepSparse, Copyright 2021-present / Neuralmagic, Inc. version: 1.6.0.20230906 COMMUNITY | (f5e597bf) (release) (optimized) (system=avx2_vnni, binary=avx2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels=['love'] scores=[0.8388857841491699]\n",
            "TimerManager({'engine_forward': 0.13723947099992984, 'pre_process': 0.00742578099993807, 'post_process': 0.0009767349999947328, 'total_inference': 0.14570146899995962})\n"
          ]
        }
      ],
      "source": [
        "from deepsparse import Pipeline\n",
        "\n",
        "text_input = \"Snorlax loves my Tesla!\"\n",
        "\n",
        "pipe = Pipeline.create(task=\"sentiment-analysis\", model_path=\"./tc_model\")\n",
        "inference = pipe(text_input)\n",
        "print(inference)\n",
        "print(pipe.timer_manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bVmHe23ZvMG"
      },
      "source": [
        "## NER\n",
        "\n",
        "Let's export the `Jean-Baptiste/camembert-ner` French NER model to an output folder called `ner_model`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vN3aBX8Zz2m",
        "outputId": "5674cb6e-af77-491e-ff43-b2687b606c41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Framework not specified. Using pt to export to ONNX.\n",
            "Automatic task detection to token-classification.\n",
            "Using the export variant default. Available variants are:\n",
            "\t- default: The default ONNX variant.\n",
            "Using framework PyTorch: 2.0.1+cu117\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Post-processing the exported models...\n",
            "Weight deduplication check in the ONNX export requires accelerate. Please install accelerate to run it.\n",
            "Validating models in subprocesses...\n",
            "Validating ONNX model ner_model/model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (logits)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 128, 5) matches (2, 128, 5)\n",
            "\t\t-[x] values not close enough, max diff: 0.0007433891296386719 (atol: 0.0001)\n",
            "The ONNX export succeeded with the warning: The maximum absolute difference between the output of the reference model and the ONNX exported model is not within the set tolerance 0.0001:\n",
            "- logits: max diff = 0.0007433891296386719.\n",
            " The exported model was saved at: ner_model\n"
          ]
        }
      ],
      "source": [
        "!optimum-cli export onnx --model Jean-Baptiste/camembert-ner ner_model --sequence_length 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvY6nHxrZ3Kb"
      },
      "source": [
        "Load model and run inference with DeepSparse:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFk8lh6yZ6r-",
        "outputId": "c46ed0d4-3183-4a8e-c59e-5ffb5a848f99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-13 09:57:11 __main__     INFO     Overwriting in-place the input shapes of the transformer model at ./ner_model/model.onnx\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predictions=[[TokenClassificationResult(entity='I-PER', score=0.9719225168228149, word='▁ge', start=0, end=2, index=1, is_grouped=False), TokenClassificationResult(entity='I-PER', score=0.9716293811798096, word='orge', start=2, end=6, index=2, is_grouped=False), TokenClassificationResult(entity='I-PER', score=0.995206892490387, word='▁was', start=6, end=10, index=3, is_grouped=False), TokenClassificationResult(entity='I-PER', score=0.9953275322914124, word='h', start=10, end=11, index=4, is_grouped=False), TokenClassificationResult(entity='I-PER', score=0.9947953224182129, word='ington', start=11, end=17, index=5, is_grouped=False), TokenClassificationResult(entity='I-LOC', score=0.9657747745513916, word='▁was', start=28, end=32, index=9, is_grouped=False), TokenClassificationResult(entity='I-LOC', score=0.9659914970397949, word='h', start=32, end=33, index=10, is_grouped=False), TokenClassificationResult(entity='I-LOC', score=0.961447536945343, word='ington', start=33, end=39, index=11, is_grouped=False)]]\n",
            "TimerManager({'engine_forward': 0.16359582700010833, 'pre_process': 0.0007111050001640251, 'post_process': 0.0005851470000379777, 'total_inference': 0.16492504799998642})\n"
          ]
        }
      ],
      "source": [
        "from deepsparse import Pipeline\n",
        "\n",
        "text_input = \"george washington est allé à washington!\"\n",
        "\n",
        "pipe = Pipeline.create(task=\"token-classification\", model_path=\"./ner_model\")\n",
        "inference = pipe(text_input)\n",
        "\n",
        "print(inference)\n",
        "print(pipe.timer_manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63itUSzgZ9lv"
      },
      "source": [
        "## Question Answering\n",
        "\n",
        "Let's export the `deepset/electra-base-squad2` model for Question Answering to an output folder called `qa_model`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWRUGwGpZ-0d",
        "outputId": "da9d80a8-c575-4c6d-8197-72b0fbf143b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Framework not specified. Using pt to export to ONNX.\n",
            "Automatic task detection to question-answering.\n",
            "Using the export variant default. Available variants are:\n",
            "\t- default: The default ONNX variant.\n",
            "Using framework PyTorch: 2.0.1+cu117\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Post-processing the exported models...\n",
            "Weight deduplication check in the ONNX export requires accelerate. Please install accelerate to run it.\n",
            "Validating models in subprocesses...\n",
            "Validating ONNX model qa_model/model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (end_logits, start_logits)\n",
            "\t- Validating ONNX Model output \"start_logits\":\n",
            "\t\t-[✓] (2, 128) matches (2, 128)\n",
            "\t\t-[✓] all values close (atol: 0.0001)\n",
            "\t- Validating ONNX Model output \"end_logits\":\n",
            "\t\t-[✓] (2, 128) matches (2, 128)\n",
            "\t\t-[✓] all values close (atol: 0.0001)\n",
            "The ONNX export succeeded and the exported model was saved at: qa_model\n"
          ]
        }
      ],
      "source": [
        "!optimum-cli export onnx --model deepset/electra-base-squad2 qa_model --sequence_length 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iiwu_LhaBQs"
      },
      "source": [
        "Load model and run inference with DeepSparse:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfux8brxaDxp",
        "outputId": "8f843554-f1f2-4014-8021-c89d554e1330"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-13 09:57:41 __main__     INFO     Overwriting in-place the input shapes of the transformer model at ./qa_model/model.onnx\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score=2.424950361251831 answer='Snorlax' start=11 end=18\n",
            "TimerManager({'engine_forward': 0.09078278999982103, 'pre_process': 0.0017440609999539447, 'post_process': 0.002852336999922045, 'total_inference': 0.09541724099995008})\n"
          ]
        }
      ],
      "source": [
        "from deepsparse import Pipeline\n",
        "\n",
        "pipe = Pipeline.create(task=\"question-answering\", model_path=\"./qa_model\")\n",
        "inference = pipe(question=\"What's my name?\", context=\"My name is Snorlax\")\n",
        "\n",
        "question = \"who loves Tesla?\"\n",
        "context = \"Snorlax loves my Tesla?\"\n",
        "\n",
        "print(inference)\n",
        "print(pipe.timer_manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7iAXJIXaIYR"
      },
      "source": [
        "## Zero-Shot Text Classification\n",
        "\n",
        "Let's export the DistilBERT MNLI Base model to an output folder called `zs_model`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDyE_frFaIyD",
        "outputId": "02e11b99-32d0-4bcd-e6fe-72aef68ada57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Framework not specified. Using pt to export to ONNX.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "Automatic task detection to text-classification (possible synonyms are: sequence-classification, zero-shot-classification).\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "Using the export variant default. Available variants are:\n",
            "\t- default: The default ONNX variant.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "Using framework PyTorch: 2.0.1+cu117\n",
            "/home/zeroshot/nm/examples/env/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Post-processing the exported models...\n",
            "Weight deduplication check in the ONNX export requires accelerate. Please install accelerate to run it.\n",
            "Validating models in subprocesses...\n",
            "Validating ONNX model zs_model/model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (logits)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 3) matches (2, 3)\n",
            "\t\t-[✓] all values close (atol: 0.0001)\n",
            "The ONNX export succeeded and the exported model was saved at: zs_model\n"
          ]
        }
      ],
      "source": [
        "!optimum-cli export onnx --model typeform/distilbert-base-uncased-mnli zs_model --sequence_length 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IPA5KYpaI93"
      },
      "source": [
        "Load model and run inference with DeepSparse:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "KKpI-c_fd116",
        "outputId": "6e622005-5633-4b4d-9f7a-9ae1c05bb42f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-13 09:58:08 __main__     INFO     Overwriting in-place the input shapes of the transformer model at ./zs_model/model.onnx\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences='I like pepperoni pizza.' labels=['food', 'sports', 'movies'] scores=[0.9594793319702148, 0.0325121246278286, 0.008008550852537155]\n",
            "TimerManager({'engine_forward': 0.13312921599981564, 'pre_process': 0.0024127279998538143, 'post_process': 0.0008873450001374295, 'total_inference': 0.13646740300009697})\n"
          ]
        }
      ],
      "source": [
        "from deepsparse import Pipeline\n",
        "\n",
        "pipe = Pipeline.create(\n",
        "    task=\"zero_shot_text_classification\",\n",
        "    model_scheme=\"mnli\",\n",
        "    model_config={\"hypothesis_template\": \"This text is related to {}\"},\n",
        "    model_path=\"./zs_model\"\n",
        ")\n",
        "\n",
        "sequence = \"I like pepperoni pizza.\"\n",
        "labels = [\"food\", \"movies\", \"sports\"]\n",
        "\n",
        "inference = pipe(sequences=sequence, labels=labels)\n",
        "\n",
        "print(inference)\n",
        "print(pipe.timer_manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHg-nPBTaSBB"
      },
      "source": [
        "## Image Classification\n",
        "\n",
        "Let's export the `nateraw/vit-age-classifier` model to an output folder called `ic_model`. This model classifies a person's age based on their picture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepsparse[image-classification] in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (1.5.2)\n",
            "\u001b[33mWARNING: deepsparse 1.5.2 does not provide the extra 'image-classification'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: requests>=2.0.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse[image-classification]) (2.31.0)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.8.2 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse[image-classification]) (1.10.12)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse[image-classification]) (8.1.7)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse[image-classification]) (3.20.1)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse[image-classification]) (4.66.1)\n",
            "Requirement already satisfied: onnx<1.15.0,>=1.5.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse[image-classification]) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse[image-classification]) (1.21.6)\n",
            "Requirement already satisfied: sparsezoo~=1.5.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from deepsparse[image-classification]) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from onnx<1.15.0,>=1.5.0->deepsparse[image-classification]) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse[image-classification]) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse[image-classification]) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse[image-classification]) (2023.7.22)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse[image-classification]) (1.26.16)\n",
            "Requirement already satisfied: pyyaml>=5.1.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from sparsezoo~=1.5.0->deepsparse[image-classification]) (6.0.1)\n",
            "Requirement already satisfied: py-machineid>=0.3.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from sparsezoo~=1.5.0->deepsparse[image-classification]) (0.4.3)\n",
            "Requirement already satisfied: pandas>1.3 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from sparsezoo~=1.5.0->deepsparse[image-classification]) (2.0.3)\n",
            "Requirement already satisfied: geocoder>=1.38.0 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from sparsezoo~=1.5.0->deepsparse[image-classification]) (1.38.1)\n",
            "Requirement already satisfied: future in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from geocoder>=1.38.0->sparsezoo~=1.5.0->deepsparse[image-classification]) (0.18.3)\n",
            "Requirement already satisfied: six in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from geocoder>=1.38.0->sparsezoo~=1.5.0->deepsparse[image-classification]) (1.16.0)\n",
            "Requirement already satisfied: ratelim in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from geocoder>=1.38.0->sparsezoo~=1.5.0->deepsparse[image-classification]) (0.1.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from pandas>1.3->sparsezoo~=1.5.0->deepsparse[image-classification]) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from pandas>1.3->sparsezoo~=1.5.0->deepsparse[image-classification]) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from pandas>1.3->sparsezoo~=1.5.0->deepsparse[image-classification]) (2.8.2)\n",
            "Requirement already satisfied: decorator in /home/zeroshot/nm/examples/env/lib/python3.10/site-packages (from ratelim->geocoder>=1.38.0->sparsezoo~=1.5.0->deepsparse[image-classification]) (5.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install deepsparse[image-classification]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MVnYezlaSoL",
        "outputId": "29b0a6cd-acf1-42d6-f929-ef6a6f35883a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Framework not specified. Using pt to export to ONNX.\n",
            "Automatic task detection to image-classification.\n",
            "/home/zeroshot/nm/examples/env/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n",
            "Using the export variant default. Available variants are:\n",
            "\t- default: The default ONNX variant.\n",
            "Using framework PyTorch: 2.0.1+cu117\n",
            "/home/zeroshot/nm/examples/env/lib/python3.10/site-packages/transformers/models/vit/modeling_vit.py:170: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if num_channels != self.num_channels:\n",
            "/home/zeroshot/nm/examples/env/lib/python3.10/site-packages/transformers/models/vit/modeling_vit.py:176: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if height != self.image_size[0] or width != self.image_size[1]:\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Post-processing the exported models...\n",
            "Weight deduplication check in the ONNX export requires accelerate. Please install accelerate to run it.\n",
            "Validating models in subprocesses...\n",
            "Validating ONNX model ic_model/model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (logits)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 9) matches (2, 9)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "The ONNX export succeeded and the exported model was saved at: ic_model\n"
          ]
        }
      ],
      "source": [
        "!optimum-cli export onnx --model nateraw/vit-age-classifier ic_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yD6ZzpTaUx3"
      },
      "source": [
        "Load model and run inference with DeepSparse:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGGXN1EbaU3b",
        "outputId": "46cce637-949f-4fca-9b19-37d73e46479a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-18 09:28:35 deepsparse.utils.onnx INFO     Overwriting in-place the input shapes of the model at ic_model/model.onnx\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels=[3] scores=[7.151614665985107]\n",
            "TimerManager({'post_process': 0.0008744990000195685, 'total_inference': 0.14688509499956126, 'engine_forward': 0.13076873600039107, 'pre_process': 0.015200159999949392})\n"
          ]
        }
      ],
      "source": [
        "from deepsparse import Pipeline\n",
        "\n",
        "image_path = \"./face.jpg\"\n",
        "\n",
        "pipe = Pipeline.create(\n",
        "    task=\"image_classification\",\n",
        "    model_path=\"./ic_model\",\n",
        "    input_shapes=[1,3,224,224]\n",
        "  )\n",
        "\n",
        "inference = pipe(images=image_path)\n",
        "print(inference)\n",
        "print(pipe.timer_manager)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
