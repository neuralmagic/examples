{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exporting Hugging Face Models Using Optimum and Running Them in DeepSparse\n",
        "\n",
        "This guide harnesses the power of Neural Magic's DeepSparse Inference Runtime library in combination with Hugging Face's ONNX models. DeepSparse offers a cutting-edge solution for efficient and accelerated inference on deep learning models, optimizing performance and resource utilization. By seamlessly integrating DeepSparse with Hugging Face's ONNX models, users can experience lightning-fast inference times while maintaining the flexibility and versatility of the widely adopted ONNX format alongside the  `Optimum` library for PyTorch model ONNX exporting.\n",
        "\n",
        "This notebook will use several popular models found on the Hugging Face Hub for text classification, zero-shot classification, question answering, and NER.\n",
        "\n",
        "The flow for this guide includes:\n",
        "\n",
        "1. Exporting models to ONNX using `optimum-cli`.\n",
        "2. Running inference with ONNX models with DeepSparse."
      ],
      "metadata": {
        "id": "fus1Bm2nY3hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install DeepSparse and Optimum"
      ],
      "metadata": {
        "id": "ug3U5GeMY6Bg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul9jw3lyYENL",
        "outputId": "c65d6282-cd32-45c4-dbba-69a34deef900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepsparse-nightly\n",
            "  Downloading deepsparse_nightly-1.6.0.20230825-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (44.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum[exporters]\n",
            "  Downloading optimum-1.12.0-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.6/380.6 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sparsezoo-nightly~=1.6.0 (from deepsparse-nightly)\n",
            "  Downloading sparsezoo_nightly-1.6.0.20230825-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from deepsparse-nightly) (1.23.5)\n",
            "Collecting onnx<1.15.0,>=1.5.0 (from deepsparse-nightly)\n",
            "  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.8.2 (from deepsparse-nightly)\n",
            "  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse-nightly) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse-nightly) (4.66.1)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse-nightly) (3.20.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse-nightly) (8.1.7)\n",
            "Collecting coloredlogs (from optimum[exporters])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum[exporters]) (1.12)\n",
            "Collecting transformers[sentencepiece]>=4.26.0 (from optimum[exporters])\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from optimum[exporters]) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum[exporters]) (23.1)\n",
            "Collecting huggingface-hub>=0.8.0 (from optimum[exporters])\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from optimum[exporters])\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime (from optimum[exporters])\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm (from optimum[exporters])\n",
            "  Downloading timm-0.9.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse-nightly) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse-nightly) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse-nightly) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse-nightly) (2023.7.22)\n",
            "Requirement already satisfied: pandas>1.3 in /usr/local/lib/python3.10/dist-packages (from sparsezoo-nightly~=1.6.0->deepsparse-nightly) (1.5.3)\n",
            "Collecting py-machineid>=0.3.0 (from sparsezoo-nightly~=1.6.0->deepsparse-nightly)\n",
            "  Downloading py_machineid-0.4.3-py3-none-any.whl (4.4 kB)\n",
            "Collecting geocoder>=1.38.0 (from sparsezoo-nightly~=1.6.0->deepsparse-nightly)\n",
            "  Downloading geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[exporters]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[exporters]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[exporters]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->optimum[exporters]) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->optimum[exporters]) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum[exporters]) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece]>=4.26.0->optimum[exporters])\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[sentencepiece]>=4.26.0->optimum[exporters])\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]>=4.26.0->optimum[exporters])\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->optimum[exporters])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[exporters]) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->optimum[exporters])\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->optimum[exporters])\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->optimum[exporters])\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[exporters]) (3.8.5)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->optimum[exporters]) (23.5.26)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum[exporters]) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->optimum[exporters]) (0.15.2+cu118)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters]) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters]) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters]) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters]) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters]) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters]) (1.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (0.18.3)\n",
            "Collecting ratelim (from geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly)\n",
            "  Downloading ratelim-0.1.6-py2.py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>1.3->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>1.3->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (2023.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->optimum[exporters]) (2.1.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm->optimum[exporters]) (9.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ratelim->geocoder>=1.38.0->sparsezoo-nightly~=1.6.0->deepsparse-nightly) (4.4.2)\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, py-machineid, xxhash, ratelim, pydantic, onnx, humanfriendly, dill, multiprocess, huggingface-hub, geocoder, coloredlogs, transformers, sparsezoo-nightly, onnxruntime, deepsparse-nightly, datasets, timm, optimum\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.2.1\n",
            "    Uninstalling pydantic-2.2.1:\n",
            "      Successfully uninstalled pydantic-2.2.1\n",
            "Successfully installed coloredlogs-15.0.1 datasets-2.14.4 deepsparse-nightly-1.6.0.20230825 dill-0.3.7 geocoder-1.38.1 huggingface-hub-0.16.4 humanfriendly-10.0 multiprocess-0.70.15 onnx-1.14.1 onnxruntime-1.15.1 optimum-1.12.0 py-machineid-0.4.3 pydantic-1.10.12 ratelim-0.1.6 safetensors-0.3.3 sentencepiece-0.1.99 sparsezoo-nightly-1.6.0.20230825 timm-0.9.5 tokenizers-0.13.3 transformers-4.32.1 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install deepsparse-nightly optimum[exporters]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Classification | Sentiment Analysis\n",
        "\n",
        "Let's export the `SamLowe/roberta-base-go_emotions` model for sentiment analysis to an output folder called `tc_model`:"
      ],
      "metadata": {
        "id": "4AO46o2fZgM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!optimum-cli export onnx --model SamLowe/roberta-base-go_emotions tc_model --sequence_length 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr4nR_bwYGHQ",
        "outputId": "794a9ed0-131c-43ce-b2d8-27b3d345c07b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-29 13:42:14.755235: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Framework not specified. Using pt to export to ONNX.\n",
            "Downloading (…)lve/main/config.json: 100% 1.92k/1.92k [00:00<00:00, 3.22MB/s]\n",
            "Downloading pytorch_model.bin: 100% 499M/499M [00:04<00:00, 101MB/s]\n",
            "Automatic task detection to text-classification (possible synonyms are: sequence-classification, zero-shot-classification).\n",
            "Downloading (…)okenizer_config.json: 100% 380/380 [00:00<00:00, 2.23MB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 798k/798k [00:00<00:00, 57.6MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 43.4MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 95.4MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 280/280 [00:00<00:00, 1.40MB/s]\n",
            "Using framework PyTorch: 2.0.1+cu118\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Post-processing the exported models...\n",
            "Validating models in subprocesses...\n",
            "2023-08-29 13:42:41.186131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Validating ONNX model tc_model/model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (logits)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 28) matches (2, 28)\n",
            "\t\t-[✓] all values close (atol: 0.0001)\n",
            "The ONNX export succeeded and the exported model was saved at: tc_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model and run inference with DeepSparse:"
      ],
      "metadata": {
        "id": "qHXqLF-tZnSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepsparse import Pipeline\n",
        "\n",
        "text_input = \"Snorlax loves my Tesla!\"\n",
        "\n",
        "pipe = Pipeline.create(task=\"sentiment-analysis\", model_path=\"./tc_model\")\n",
        "inference = pipe(text_input)\n",
        "print(inference)\n",
        "print(pipe.timer_manager)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zoqimTNZpCY",
        "outputId": "3fc6cd2a-2f49-4e9d-89d5-8ca3f5a5b30e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-08-29 13:43:02 deepsparse.transformers WARNING  The neuralmagic fork of transformers may not be installed. It can be installed via `pip install nm_transformers`\n",
            "WARNING:deepsparse.transformers:The neuralmagic fork of transformers may not be installed. It can be installed via `pip install nm_transformers`\n",
            "2023-08-29 13:43:07 __main__     INFO     Overwriting in-place the input shapes of the transformer model at ./tc_model/model.onnx\n",
            "INFO:__main__:Overwriting in-place the input shapes of the transformer model at ./tc_model/model.onnx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels=['love'] scores=[0.8388857841491699]\n",
            "TimerManager({'engine_forward': 0.37699663099999725, 'total_inference': 0.3789412719999916, 'pre_process': 0.0014164960000186966, 'post_process': 0.00048448900000153117})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER\n",
        "\n",
        "Let's export the `Jean-Baptiste/camembert-ner` French NER model to an output folder called `ner_model`:"
      ],
      "metadata": {
        "id": "6bVmHe23ZvMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!optimum-cli export onnx --model Jean-Baptiste/camembert-ner ner_model --sequence_length 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vN3aBX8Zz2m",
        "outputId": "5674cb6e-af77-491e-ff43-b2687b606c41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-29 13:46:17.543971: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Framework not specified. Using pt to export to ONNX.\n",
            "Downloading (…)lve/main/config.json: 100% 892/892 [00:00<00:00, 2.09MB/s]\n",
            "Downloading model.safetensors: 100% 440M/440M [00:07<00:00, 59.4MB/s]\n",
            "Automatic task detection to token-classification.\n",
            "Downloading (…)okenizer_config.json: 100% 269/269 [00:00<00:00, 1.01MB/s]\n",
            "Downloading (…)tencepiece.bpe.model: 100% 811k/811k [00:00<00:00, 180MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 210/210 [00:00<00:00, 1.25MB/s]\n",
            "Using framework PyTorch: 2.0.1+cu118\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Post-processing the exported models...\n",
            "Validating models in subprocesses...\n",
            "2023-08-29 13:46:47.475248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Validating ONNX model ner_model/model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (logits)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 128, 5) matches (2, 128, 5)\n",
            "\t\t-[✓] all values close (atol: 0.0001)\n",
            "The ONNX export succeeded and the exported model was saved at: ner_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model and run inference with DeepSparse:"
      ],
      "metadata": {
        "id": "PvY6nHxrZ3Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepsparse import Pipeline\n",
        "\n",
        "text_input = \"george washington est allé à washington!\"\n",
        "\n",
        "pipe = Pipeline.create(task=\"token-classification\", model_path=\"./ner_model\")\n",
        "inference = pipe(text_input)\n",
        "\n",
        "print(inference)\n",
        "print(pipe.timer_manager)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFk8lh6yZ6r-",
        "outputId": "c46ed0d4-3183-4a8e-c59e-5ffb5a848f99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-08-29 13:46:59 __main__     INFO     Overwriting in-place the input shapes of the transformer model at ./ner_model/model.onnx\n",
            "INFO:__main__:Overwriting in-place the input shapes of the transformer model at ./ner_model/model.onnx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions=[[TokenClassificationResult(entity='I-PER', score=0.9719225168228149, word='▁ge', start=0, end=2, index=1, is_grouped=False), TokenClassificationResult(entity='I-PER', score=0.9716293811798096, word='orge', start=2, end=6, index=2, is_grouped=False), TokenClassificationResult(entity='I-PER', score=0.995206892490387, word='▁was', start=6, end=10, index=3, is_grouped=False), TokenClassificationResult(entity='I-PER', score=0.9953275322914124, word='h', start=10, end=11, index=4, is_grouped=False), TokenClassificationResult(entity='I-PER', score=0.9947953224182129, word='ington', start=11, end=17, index=5, is_grouped=False), TokenClassificationResult(entity='I-LOC', score=0.9657747745513916, word='▁was', start=28, end=32, index=9, is_grouped=False), TokenClassificationResult(entity='I-LOC', score=0.9659914970397949, word='h', start=32, end=33, index=10, is_grouped=False), TokenClassificationResult(entity='I-LOC', score=0.961447536945343, word='ington', start=33, end=39, index=11, is_grouped=False)]]\n",
            "TimerManager({'engine_forward': 0.3993458770000302, 'total_inference': 0.4020000669999604, 'pre_process': 0.001061354000000847, 'post_process': 0.0015504159999863987})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question Answering\n",
        "\n",
        "Let's export the `deepset/electra-base-squad2` model for Question Answering to an output folder called `qa_model`:"
      ],
      "metadata": {
        "id": "63itUSzgZ9lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!optimum-cli export onnx --model deepset/electra-base-squad2 qa_model --sequence_length 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWRUGwGpZ-0d",
        "outputId": "da9d80a8-c575-4c6d-8197-72b0fbf143b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-29 13:48:50.942486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Framework not specified. Using pt to export to ONNX.\n",
            "Downloading (…)lve/main/config.json: 100% 635/635 [00:00<00:00, 1.02MB/s]\n",
            "Downloading model.safetensors: 100% 436M/436M [00:06<00:00, 65.3MB/s]\n",
            "Automatic task detection to question-answering.\n",
            "Downloading (…)okenizer_config.json: 100% 200/200 [00:00<00:00, 987kB/s]\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 43.1MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 112/112 [00:00<00:00, 672kB/s]\n",
            "Using framework PyTorch: 2.0.1+cu118\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Post-processing the exported models...\n",
            "Validating models in subprocesses...\n",
            "2023-08-29 13:49:17.017348: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Validating ONNX model qa_model/model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (start_logits, end_logits)\n",
            "\t- Validating ONNX Model output \"start_logits\":\n",
            "\t\t-[✓] (2, 128) matches (2, 128)\n",
            "\t\t-[✓] all values close (atol: 0.0001)\n",
            "\t- Validating ONNX Model output \"end_logits\":\n",
            "\t\t-[✓] (2, 128) matches (2, 128)\n",
            "\t\t-[✓] all values close (atol: 0.0001)\n",
            "The ONNX export succeeded and the exported model was saved at: qa_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model and run inference with DeepSparse:"
      ],
      "metadata": {
        "id": "2iiwu_LhaBQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepsparse import Pipeline\n",
        "\n",
        "pipe = Pipeline.create(task=\"question-answering\", model_path=\"./qa_model\")\n",
        "inference = pipe(question=\"What's my name?\", context=\"My name is Snorlax\")\n",
        "\n",
        "question = \"who loves Tesla?\"\n",
        "context = \"Snorlax loves my Tesla?\"\n",
        "\n",
        "print(inference)\n",
        "print(pipe.timer_manager)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfux8brxaDxp",
        "outputId": "8f843554-f1f2-4014-8021-c89d554e1330"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-08-29 13:49:27 __main__     INFO     Overwriting in-place the input shapes of the transformer model at ./qa_model/model.onnx\n",
            "INFO:__main__:Overwriting in-place the input shapes of the transformer model at ./qa_model/model.onnx\n",
            "/usr/local/lib/python3.10/dist-packages/deepsparse/transformers/pipelines/question_answering.py:598: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return numpy.array(array)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score=2.424950361251831 answer='Snorlax' start=11 end=18\n",
            "TimerManager({'engine_forward': 0.3993458770000302, 'total_inference': 0.4020000669999604, 'pre_process': 0.001061354000000847, 'post_process': 0.0015504159999863987})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-Shot Text Classification\n",
        "\n",
        "Let's export the DistilBERT MNLI Base model to an output folder called `zs_model`:"
      ],
      "metadata": {
        "id": "h7iAXJIXaIYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!optimum-cli export onnx --model typeform/distilbert-base-uncased-mnli zs_model --sequence_length 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDyE_frFaIyD",
        "outputId": "02e11b99-32d0-4bcd-e6fe-72aef68ada57"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-29 13:50:48.869498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Framework not specified. Using pt to export to ONNX.\n",
            "Downloading (…)lve/main/config.json: 100% 776/776 [00:00<00:00, 1.80MB/s]\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "Downloading model.safetensors: 100% 268M/268M [00:01<00:00, 217MB/s]\n",
            "Automatic task detection to text-classification (possible synonyms are: sequence-classification, zero-shot-classification).\n",
            "Downloading (…)okenizer_config.json: 100% 258/258 [00:00<00:00, 1.33MB/s]\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 28.1MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 112/112 [00:00<00:00, 614kB/s]\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "Using framework PyTorch: 2.0.1+cu118\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Post-processing the exported models...\n",
            "Validating models in subprocesses...\n",
            "2023-08-29 13:51:05.169887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Validating ONNX model zs_model/model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (logits)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 3) matches (2, 3)\n",
            "\t\t-[✓] all values close (atol: 0.0001)\n",
            "The ONNX export succeeded and the exported model was saved at: zs_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model and run inference with DeepSparse:"
      ],
      "metadata": {
        "id": "5IPA5KYpaI93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepsparse import Pipeline\n",
        "\n",
        "pipe = Pipeline.create(\n",
        "    task=\"zero_shot_text_classification\",\n",
        "    model_scheme=\"mnli\",\n",
        "    model_config={\"hypothesis_template\": \"This text is related to {}\"},\n",
        "    model_path=\"./zs_model\"\n",
        ")\n",
        "\n",
        "sequence = \"I like pepperoni pizza.\"\n",
        "labels = [\"food\", \"movies\", \"sports\"]\n",
        "\n",
        "inference = pipe(sequences=sequence, labels=labels)\n",
        "\n",
        "print(inference)\n",
        "print(pipe.timer_manager)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "KKpI-c_fd116",
        "outputId": "6e622005-5633-4b4d-9f7a-9ae1c05bb42f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9a473cd3a1e2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepsparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m pipe = Pipeline.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zero_shot_text_classification\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_scheme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mnli\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deepsparse/pipeline.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(task, model_path, engine_type, batch_size, num_cores, scheduler, input_shapes, alias, context, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0mobject\u001b[0m \u001b[0minitialized\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mpipeline_constructor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_task_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deepsparse/pipeline.py\u001b[0m in \u001b[0;36m_get_task_constructor\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# install extra packages so should only import and register once a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;31m# transformers task is specified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mSupportedTasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_register_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_REGISTERED_PIPELINES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_REGISTERED_PIPELINES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deepsparse/tasks.py\u001b[0m in \u001b[0;36mcheck_register_task\u001b[0;34m(cls, task, extra_tasks)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_nlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;31m# trigger transformers pipelines to register with Pipeline.register\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mdeepsparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_image_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deepsparse/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0m_check_transformers_install\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deepsparse/transformers/__init__.py\u001b[0m in \u001b[0;36m_check_transformers_install\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNM_INTEGRATED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         _LOGGER.warning(\n\u001b[1;32m     46\u001b[0m             \u001b[0;34m\"the neuralmagic fork of transformers may not be installed. it can be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module transformers has no attribute NM_INTEGRATED"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Classification\n",
        "\n",
        "Let's export the `nateraw/vit-age-classifier` model to an output folder called `ic_model`. This model classifies a person's age based on their picture:"
      ],
      "metadata": {
        "id": "vHg-nPBTaSBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!optimum-cli export onnx --model nateraw/vit-age-classifier ic_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MVnYezlaSoL",
        "outputId": "29b0a6cd-acf1-42d6-f929-ef6a6f35883a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-29 13:57:18.298960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Framework not specified. Using pt to export to ONNX.\n",
            "Downloading (…)lve/main/config.json: 100% 850/850 [00:00<00:00, 1.61MB/s]\n",
            "Downloading pytorch_model.bin: 100% 343M/343M [00:05<00:00, 60.6MB/s]\n",
            "Automatic task detection to image-classification.\n",
            "Downloading (…)rocessor_config.json: 100% 197/197 [00:00<00:00, 808kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n",
            "Using framework PyTorch: 2.0.1+cu118\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/modeling_vit.py:170: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if num_channels != self.num_channels:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/modeling_vit.py:176: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if height != self.image_size[0] or width != self.image_size[1]:\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Post-processing the exported models...\n",
            "Validating models in subprocesses...\n",
            "2023-08-29 13:57:46.553403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Validating ONNX model ic_model/model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (logits)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 9) matches (2, 9)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "The ONNX export succeeded and the exported model was saved at: ic_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model and run inference with DeepSparse:"
      ],
      "metadata": {
        "id": "5yD6ZzpTaUx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepsparse import Pipeline\n",
        "\n",
        "pipe = Pipeline.create(\n",
        "    task=\"image_classification\",\n",
        "    model_path=\"./ic_model\",\n",
        "    input_shapes=[1,3,224,224]\n",
        "  )\n",
        "\n",
        "inference = pipe(images=\"./face.jpg\")\n",
        "\n",
        "print(inference.labels)\n",
        "print(pipe.timer_manager)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGGXN1EbaU3b",
        "outputId": "46cce637-949f-4fca-9b19-37d73e46479a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-08-29 14:01:37 deepsparse.utils.onnx INFO     Overwriting in-place the input shapes of the model at ic_model/model.onnx\n",
            "INFO:deepsparse.utils.onnx:Overwriting in-place the input shapes of the model at ic_model/model.onnx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3]\n",
            "TimerManager({'engine_forward': 1.037140602999898, 'total_inference': 1.0436674009999933, 'pre_process': 0.004802337999990414, 'post_process': 0.0016723179999189597})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Segmentation\n",
        "\n",
        "Let's export the DEtection TRansformer(DETR) model to an output folder called `is_model`:"
      ],
      "metadata": {
        "id": "XdjWBju3aZVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepsparse[yolov8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZdy9ocqhpkr",
        "outputId": "7c33be78-1c69-462c-866e-31659dbc12ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepsparse[yolov8] in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: sparsezoo~=1.5.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (1.21.6)\n",
            "Requirement already satisfied: onnx<1.15.0,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (1.12.0)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (1.10.12)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (4.66.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (3.20.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (8.1.7)\n",
            "Requirement already satisfied: torchvision<=0.13,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (0.13.0)\n",
            "Requirement already satisfied: opencv-python<=4.6.0.66 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (4.6.0.66)\n",
            "Requirement already satisfied: ultralytics==8.0.30 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (8.0.30)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (3.7.1)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (1.12.0)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (2.12.3)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (0.12.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (5.9.5)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.30->deepsparse[yolov8]) (1.30.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx<1.15.0,>=1.5.0->deepsparse[yolov8]) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[yolov8]) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[yolov8]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[yolov8]) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[yolov8]) (2023.7.22)\n",
            "Requirement already satisfied: py-machineid>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.5.0->deepsparse[yolov8]) (0.4.3)\n",
            "Requirement already satisfied: geocoder>=1.38.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.5.0->deepsparse[yolov8]) (1.38.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.5.0->deepsparse[yolov8]) (0.18.3)\n",
            "Requirement already satisfied: ratelim in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.5.0->deepsparse[yolov8]) (0.1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.5.0->deepsparse[yolov8]) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.30->deepsparse[yolov8]) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.30->deepsparse[yolov8]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.30->deepsparse[yolov8]) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.30->deepsparse[yolov8]) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.30->deepsparse[yolov8]) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.30->deepsparse[yolov8]) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.30->deepsparse[yolov8]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.30->deepsparse[yolov8]) (2023.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (1.57.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (3.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (2.3.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (0.41.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.30->deepsparse[yolov8]) (0.19.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.30->deepsparse[yolov8]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.30->deepsparse[yolov8]) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.30->deepsparse[yolov8]) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.30->deepsparse[yolov8]) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.30->deepsparse[yolov8]) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.30->deepsparse[yolov8]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.30->deepsparse[yolov8]) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.30->deepsparse[yolov8]) (4.8.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ultralytics==8.0.30->deepsparse[yolov8]) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ultralytics==8.0.30->deepsparse[yolov8]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ultralytics==8.0.30->deepsparse[yolov8]) (0.2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->ultralytics==8.0.30->deepsparse[yolov8]) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!optimum-cli export onnx --model facebook/detr-resnet-50-panoptic is_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFo1ZDIhaZbz",
        "outputId": "eecb9347-ee37-4a17-91d4-e9e3d4a665f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
            "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
            "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
            "ImportError: numpy.core._multiarray_umath failed to import\n",
            "ImportError: numpy.core.umath failed to import\n",
            "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
            "ImportError: numpy.core._multiarray_umath failed to import\n",
            "ImportError: numpy.core.umath failed to import\n",
            "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
            "ImportError: numpy.core._multiarray_umath failed to import\n",
            "ImportError: numpy.core.umath failed to import\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/optimum-cli\", line 5, in <module>\n",
            "    from optimum.commands.optimum_cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/commands/__init__.py\", line 17, in <module>\n",
            "    from .export import ExportCommand, ONNXExportCommand, TFLiteExportCommand\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/commands/export/__init__.py\", line 16, in <module>\n",
            "    from .base import ExportCommand\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/commands/export/base.py\", line 18, in <module>\n",
            "    from .onnx import ONNXExportCommand\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/commands/export/onnx.py\", line 20, in <module>\n",
            "    from ...exporters import TasksManager\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/exporters/__init__.py\", line 16, in <module>\n",
            "    from .tasks import TasksManager  # noqa\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/exporters/tasks.py\", line 31, in <module>\n",
            "    from ..utils.import_utils import is_onnx_available\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/utils/__init__.py\", line 43, in <module>\n",
            "    from .input_generators import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/utils/input_generators.py\", line 32, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/__init__.py\", line 42, in <module>\n",
            "    from tensorflow.python import data\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/__init__.py\", line 21, in <module>\n",
            "    from tensorflow.python.data import experimental\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/__init__.py\", line 97, in <module>\n",
            "    from tensorflow.python.data.experimental import service\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/service/__init__.py\", line 419, in <module>\n",
            "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 22, in <module>\n",
            "    from tensorflow.python.data.experimental.ops import compression_ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/compression_ops.py\", line 16, in <module>\n",
            "    from tensorflow.python.data.util import structure\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/util/structure.py\", line 22, in <module>\n",
            "    from tensorflow.python.data.util import nest\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/util/nest.py\", line 34, in <module>\n",
            "    from tensorflow.python.framework import sparse_tensor as _sparse_tensor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/sparse_tensor.py\", line 25, in <module>\n",
            "    from tensorflow.python.framework import constant_op\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 25, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/dtypes.py\", line 37, in <module>\n",
            "    _np_bfloat16 = _pywrap_bfloat16.TF_bfloat16_type()\n",
            "TypeError: Unable to convert function return value to a Python type! The signature was\n",
            "\t() -> handle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model and run inference with DeepSparse:"
      ],
      "metadata": {
        "id": "1jQx-gkwaZiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepsparse import Pipeline\n",
        "\n",
        "pipe = Pipeline.create(\n",
        "    task=\"yolov8\",\n",
        "    model_path=\"./is_model\",\n",
        "    input_shapes=[1,3,224,224],\n",
        "    image_size=(224,224)\n",
        ")\n",
        "\n",
        "inference = pipe(images=\"./thailand.jpeg\")\n",
        "\n",
        "print(inference)\n",
        "print(pipe.timer_manager)"
      ],
      "metadata": {
        "id": "TRYAPklOaZnX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}