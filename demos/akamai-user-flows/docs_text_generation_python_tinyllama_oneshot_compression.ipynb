{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f88e7912644644cc9aebde158506dc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5613f09607d4931a1b6b416a62b96b1",
              "IPY_MODEL_cbe8cbc443c6477bbf6ae9e308798e24",
              "IPY_MODEL_b9e1df5d33af4959864474bc34a57bd5"
            ],
            "layout": "IPY_MODEL_26aa6d41217a41b18c4f374d815de764"
          }
        },
        "b5613f09607d4931a1b6b416a62b96b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d172de3545ad45fca55377f9cf885797",
            "placeholder": "​",
            "style": "IPY_MODEL_4d883091390a43d9989db7fa35d569bf",
            "value": "Downloading readme: 100%"
          }
        },
        "cbe8cbc443c6477bbf6ae9e308798e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14e6cf5d1cb44bf8b8aef9db167d27ba",
            "max": 5337,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2132083cadb34d3a945964c41c3f1663",
            "value": 5337
          }
        },
        "b9e1df5d33af4959864474bc34a57bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b2b7cb1e2414ab5b5d10f253c552c36",
            "placeholder": "​",
            "style": "IPY_MODEL_d7123dcd52c0452583c3ad987b45d7fd",
            "value": " 5.34k/5.34k [00:00&lt;00:00, 452kB/s]"
          }
        },
        "26aa6d41217a41b18c4f374d815de764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d172de3545ad45fca55377f9cf885797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d883091390a43d9989db7fa35d569bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14e6cf5d1cb44bf8b8aef9db167d27ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2132083cadb34d3a945964c41c3f1663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b2b7cb1e2414ab5b5d10f253c552c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7123dcd52c0452583c3ad987b45d7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d5068e1150a4a6fb37479e951afb021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a2aff8bd85547aaa4c9653fdd6df456",
              "IPY_MODEL_63ed9a07377b43aa853896815418b8c6",
              "IPY_MODEL_a022a1fe4cb94b33a3338ffe49f7a407"
            ],
            "layout": "IPY_MODEL_4b0539dffc3b49d1aa83c4b061c8649a"
          }
        },
        "9a2aff8bd85547aaa4c9653fdd6df456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7604dad8589d4889b97893e06aa1c467",
            "placeholder": "​",
            "style": "IPY_MODEL_3d0e7ecce8e94c06af51842cf2d69456",
            "value": "Downloading data files: 100%"
          }
        },
        "63ed9a07377b43aa853896815418b8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60baad141b7f4f3b83c6877a8993c541",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cea37a88bba94744b936af4b8c5b6519",
            "value": 1
          }
        },
        "a022a1fe4cb94b33a3338ffe49f7a407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f601c6f2c524b5eba928c2a80c9b63a",
            "placeholder": "​",
            "style": "IPY_MODEL_b82da9a5c2ec4d09bd1f0156182b1321",
            "value": " 1/1 [00:01&lt;00:00,  1.08s/it]"
          }
        },
        "4b0539dffc3b49d1aa83c4b061c8649a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7604dad8589d4889b97893e06aa1c467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d0e7ecce8e94c06af51842cf2d69456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60baad141b7f4f3b83c6877a8993c541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea37a88bba94744b936af4b8c5b6519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f601c6f2c524b5eba928c2a80c9b63a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b82da9a5c2ec4d09bd1f0156182b1321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "668badd5598b4da7af99bdf32f31bdd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f70b8a6637f444c0ac0ed44749b78697",
              "IPY_MODEL_541442e255294dfa9d2fdb8eacee84ee",
              "IPY_MODEL_2d1aca37e36d4cb2b0366a7932056270"
            ],
            "layout": "IPY_MODEL_4b9149f4721a4d9ab959334ccf7f4254"
          }
        },
        "f70b8a6637f444c0ac0ed44749b78697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b936680e59443f6861cd89af51d30a8",
            "placeholder": "​",
            "style": "IPY_MODEL_cd5dd0c507b547cf94c346cf0112ba79",
            "value": "Downloading data: 100%"
          }
        },
        "541442e255294dfa9d2fdb8eacee84ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ed569c0a3ce43e8be760b0cbb74254e",
            "max": 15565850,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04eff42db8dd4c8aba8af3b1f81b72a0",
            "value": 15565850
          }
        },
        "2d1aca37e36d4cb2b0366a7932056270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19b19a009311428981b292b176174b00",
            "placeholder": "​",
            "style": "IPY_MODEL_293f27e94dfb4b2bab3472baa1726a94",
            "value": " 15.6M/15.6M [00:01&lt;00:00, 13.7MB/s]"
          }
        },
        "4b9149f4721a4d9ab959334ccf7f4254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b936680e59443f6861cd89af51d30a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd5dd0c507b547cf94c346cf0112ba79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ed569c0a3ce43e8be760b0cbb74254e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04eff42db8dd4c8aba8af3b1f81b72a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19b19a009311428981b292b176174b00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293f27e94dfb4b2bab3472baa1726a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9146b61b3201444e9fb373c0b3b7b14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e45c83311cd94ac99160fb288abbbd29",
              "IPY_MODEL_291ea8a22bb14538886c98a3f3d0e7f1",
              "IPY_MODEL_93384fbfec79426db3be4b64e4990acf"
            ],
            "layout": "IPY_MODEL_c069360907a641c2ab4d51ca896f494a"
          }
        },
        "e45c83311cd94ac99160fb288abbbd29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b47a9f7e3780449f9e4d9af483e0f6d4",
            "placeholder": "​",
            "style": "IPY_MODEL_d558a7bc2de24045a10aab4f47ec3a9c",
            "value": "Extracting data files: 100%"
          }
        },
        "291ea8a22bb14538886c98a3f3d0e7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86bf644c5f964776ad30d114705b1fe5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24115b25f973427f900c8ccf7d3e43c5",
            "value": 1
          }
        },
        "93384fbfec79426db3be4b64e4990acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b2da72dda0487dbac7eb75ed1adfe5",
            "placeholder": "​",
            "style": "IPY_MODEL_a3b699d0b3c54c8985adbfe1763be57c",
            "value": " 1/1 [00:00&lt;00:00, 60.37it/s]"
          }
        },
        "c069360907a641c2ab4d51ca896f494a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b47a9f7e3780449f9e4d9af483e0f6d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d558a7bc2de24045a10aab4f47ec3a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86bf644c5f964776ad30d114705b1fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24115b25f973427f900c8ccf7d3e43c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53b2da72dda0487dbac7eb75ed1adfe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3b699d0b3c54c8985adbfe1763be57c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d85c92fbc1641e2bdb0853e7ff1e6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49b2b8b38cac4a4da98537f6575e0e7e",
              "IPY_MODEL_b20339935f2e42d4b427f230843a55d2",
              "IPY_MODEL_fa1a692f071c40d7bb4bbe1d7ec8809d"
            ],
            "layout": "IPY_MODEL_98541916af0646e8a5e4f64b90feff1d"
          }
        },
        "49b2b8b38cac4a4da98537f6575e0e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a3dd6dda51949e7a48e0a0529318259",
            "placeholder": "​",
            "style": "IPY_MODEL_083bdbd53be045d7ad2c18e5375de3ef",
            "value": "Generating train split: 100%"
          }
        },
        "b20339935f2e42d4b427f230843a55d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a1199a0b5045b29c1f75dec65cc8dd",
            "max": 24926,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4454e5d8f3014570b69859602be522dc",
            "value": 24926
          }
        },
        "fa1a692f071c40d7bb4bbe1d7ec8809d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa35bb93a4e74833afbfc04f849525c5",
            "placeholder": "​",
            "style": "IPY_MODEL_493b05f50f6c41deaea605da7dc4fb2e",
            "value": " 24926/24926 [00:00&lt;00:00, 172974.30 examples/s]"
          }
        },
        "98541916af0646e8a5e4f64b90feff1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a3dd6dda51949e7a48e0a0529318259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083bdbd53be045d7ad2c18e5375de3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56a1199a0b5045b29c1f75dec65cc8dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4454e5d8f3014570b69859602be522dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa35bb93a4e74833afbfc04f849525c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "493b05f50f6c41deaea605da7dc4fb2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f890caff902465e8e7dac7b21869836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f800199bc8bb47d59e1236874490d4a0",
              "IPY_MODEL_bf09fe3887b04671aebef9d33608b5b3",
              "IPY_MODEL_b990d04d4e72475ba80823390f66de81"
            ],
            "layout": "IPY_MODEL_f59a5bd89fca4381aa52e787741b3912"
          }
        },
        "f800199bc8bb47d59e1236874490d4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7da13fe7a4ae436faeefed737092ba5a",
            "placeholder": "​",
            "style": "IPY_MODEL_210b60a9bdc4420695044b9aaa9834e6",
            "value": "Map: 100%"
          }
        },
        "bf09fe3887b04671aebef9d33608b5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_876ed6cd27484a04b85766c4ee8fa63f",
            "max": 24926,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65c072e48daa4b948ae0722b7555df28",
            "value": 24926
          }
        },
        "b990d04d4e72475ba80823390f66de81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_176c7743445440ce8068ce085b3f8ef9",
            "placeholder": "​",
            "style": "IPY_MODEL_c90075d6148a4b319d9013802910406d",
            "value": " 24926/24926 [00:01&lt;00:00, 14559.65 examples/s]"
          }
        },
        "f59a5bd89fca4381aa52e787741b3912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da13fe7a4ae436faeefed737092ba5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "210b60a9bdc4420695044b9aaa9834e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "876ed6cd27484a04b85766c4ee8fa63f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65c072e48daa4b948ae0722b7555df28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "176c7743445440ce8068ce085b3f8ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90075d6148a4b319d9013802910406d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b5d22f62189499bba79b301f1b82c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3785c1bccf943449c61a53117738435",
              "IPY_MODEL_9c2cb8fb37044fadb3f2489046e49c2a",
              "IPY_MODEL_af95c89538d642aba3aedc52517bc273"
            ],
            "layout": "IPY_MODEL_1893f8c5d22a4399a978c9143c007ebb"
          }
        },
        "c3785c1bccf943449c61a53117738435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_859ddf7426664c9db9d48911694cdd0c",
            "placeholder": "​",
            "style": "IPY_MODEL_278e7e63d81f427b936e1216d9a54aea",
            "value": "Removing unneeded columns: 100%"
          }
        },
        "9c2cb8fb37044fadb3f2489046e49c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803ac0a865f04c68a6ed81f468e0e947",
            "max": 24926,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b453bf2141b43e19b6878e3e7ac9f98",
            "value": 24926
          }
        },
        "af95c89538d642aba3aedc52517bc273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5b165ed08d44010927ad9c692d11f5c",
            "placeholder": "​",
            "style": "IPY_MODEL_aa24312996d34ae980d633d5a33e2b0b",
            "value": " 24926/24926 [00:00&lt;00:00, 442073.22 examples/s]"
          }
        },
        "1893f8c5d22a4399a978c9143c007ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "859ddf7426664c9db9d48911694cdd0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "278e7e63d81f427b936e1216d9a54aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "803ac0a865f04c68a6ed81f468e0e947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b453bf2141b43e19b6878e3e7ac9f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5b165ed08d44010927ad9c692d11f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa24312996d34ae980d633d5a33e2b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0845f9268c0e4611ae06453c427ba0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_587e5bbc302e4e1ea788b3d6566f8b44",
              "IPY_MODEL_9b11504298ef42c59f116d4a87b633e5",
              "IPY_MODEL_6b6c9d1d40844e82ab1f9a77245e9c55"
            ],
            "layout": "IPY_MODEL_052aab2e46c04aec9d74a2d2c790c89b"
          }
        },
        "587e5bbc302e4e1ea788b3d6566f8b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac6ecb4e2138488899e562a479c3ccf3",
            "placeholder": "​",
            "style": "IPY_MODEL_f85c6233cf4f4db890eba08dbb033ccd",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "9b11504298ef42c59f116d4a87b633e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05140cbe91884cddbf91d1bc4fee97b6",
            "max": 24926,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7e6e30493e74fef87038c6bb33e15e4",
            "value": 24926
          }
        },
        "6b6c9d1d40844e82ab1f9a77245e9c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec6e29307b8945a6bb5c897ac39e722a",
            "placeholder": "​",
            "style": "IPY_MODEL_7da61493a2834b909345f564a1a3f952",
            "value": " 24926/24926 [00:07&lt;00:00, 2406.74 examples/s]"
          }
        },
        "052aab2e46c04aec9d74a2d2c790c89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac6ecb4e2138488899e562a479c3ccf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f85c6233cf4f4db890eba08dbb033ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05140cbe91884cddbf91d1bc4fee97b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7e6e30493e74fef87038c6bb33e15e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec6e29307b8945a6bb5c897ac39e722a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da61493a2834b909345f564a1a3f952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "457f2f1288ee4ef7b42e4b74f6d8c98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f7e797b92cd4b17a96b78e612d60cc9",
              "IPY_MODEL_55d92469e7e148ed81c1bfb65d164549",
              "IPY_MODEL_84e705e3f8494fcabed8d36286ed9055"
            ],
            "layout": "IPY_MODEL_d68c61025f384a69896795d65f81c846"
          }
        },
        "0f7e797b92cd4b17a96b78e612d60cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d43110b54e44b3a938da85d89c11ac",
            "placeholder": "​",
            "style": "IPY_MODEL_a651933758224425b82b107539c84bdb",
            "value": "Adding labels: 100%"
          }
        },
        "55d92469e7e148ed81c1bfb65d164549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20f0af5f21994973a675e28fe6749f87",
            "max": 24926,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_642fa87839214e7e921a3032b51106dc",
            "value": 24926
          }
        },
        "84e705e3f8494fcabed8d36286ed9055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a30b5e378fce4cb0bd2be85896d1e1c0",
            "placeholder": "​",
            "style": "IPY_MODEL_ae143e5099744d1fb8dccf775cb7e3b3",
            "value": " 24926/24926 [00:12&lt;00:00, 2177.94 examples/s]"
          }
        },
        "d68c61025f384a69896795d65f81c846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d43110b54e44b3a938da85d89c11ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a651933758224425b82b107539c84bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20f0af5f21994973a675e28fe6749f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "642fa87839214e7e921a3032b51106dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a30b5e378fce4cb0bd2be85896d1e1c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae143e5099744d1fb8dccf775cb7e3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f9920e370e04da8a47874cd5899dc9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa9cfab7cbf9469e98789961e725f30c",
              "IPY_MODEL_04a557a9e21b46368e9d211ebfb626a0",
              "IPY_MODEL_ff732003a9af43b2a8863b8fdbe87108"
            ],
            "layout": "IPY_MODEL_ae66997262a3431db7fa6762ecc84621"
          }
        },
        "fa9cfab7cbf9469e98789961e725f30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4993e670b42432e885c7c9da59d0a5c",
            "placeholder": "​",
            "style": "IPY_MODEL_7d6e5f99c58a4d0aaf39677afbdf8de7",
            "value": "Downloading readme: 100%"
          }
        },
        "04a557a9e21b46368e9d211ebfb626a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0238ea41c4940b0adcdfdb601cfc32b",
            "max": 6523,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2f053ad2e384a1c97c49a855e38b34a",
            "value": 6523
          }
        },
        "ff732003a9af43b2a8863b8fdbe87108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76355ffa043347c3b943221a8568b159",
            "placeholder": "​",
            "style": "IPY_MODEL_ab6bae775f7a4b898e7b0f387fd19334",
            "value": " 6.52k/6.52k [00:00&lt;00:00, 509kB/s]"
          }
        },
        "ae66997262a3431db7fa6762ecc84621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4993e670b42432e885c7c9da59d0a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6e5f99c58a4d0aaf39677afbdf8de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0238ea41c4940b0adcdfdb601cfc32b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f053ad2e384a1c97c49a855e38b34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76355ffa043347c3b943221a8568b159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab6bae775f7a4b898e7b0f387fd19334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a1098f07ccd4ee8a11952b5354a2e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3a407ec7ebd41cb849e4698eaadb2fc",
              "IPY_MODEL_e4df270ad2df44babd51e4f09a3c5eff",
              "IPY_MODEL_0ea82ed228bc452c8c1794912f01e407"
            ],
            "layout": "IPY_MODEL_5f6bc092dc334150ad8d33847387d105"
          }
        },
        "a3a407ec7ebd41cb849e4698eaadb2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc9849214994df482649fd0e33c1a98",
            "placeholder": "​",
            "style": "IPY_MODEL_61837b439b16479580349dd826032aaf",
            "value": "Downloading data files: 100%"
          }
        },
        "e4df270ad2df44babd51e4f09a3c5eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_676a8aacf7654e3e94e18dae1a3ae746",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b5ace557181434daa24edd76a2ffa0d",
            "value": 1
          }
        },
        "0ea82ed228bc452c8c1794912f01e407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bba53d4759b4f2fa4895e2a268b9387",
            "placeholder": "​",
            "style": "IPY_MODEL_bf82aeefef2a4dffabaf10d436e6e0b4",
            "value": " 1/1 [00:00&lt;00:00,  4.22it/s]"
          }
        },
        "5f6bc092dc334150ad8d33847387d105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc9849214994df482649fd0e33c1a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61837b439b16479580349dd826032aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "676a8aacf7654e3e94e18dae1a3ae746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b5ace557181434daa24edd76a2ffa0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bba53d4759b4f2fa4895e2a268b9387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf82aeefef2a4dffabaf10d436e6e0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb13eb0b01d64f52aaef8a947390d200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59a1231e607f42fa8ec51beea31797fd",
              "IPY_MODEL_a1923de7f96344cd88adfe7a05110968",
              "IPY_MODEL_9fa778aa58b34f7eb13fdf99d2788c20"
            ],
            "layout": "IPY_MODEL_354c34a58f814ca88a2b862af261e803"
          }
        },
        "59a1231e607f42fa8ec51beea31797fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce5dfd3b818e44b3860898f186894d61",
            "placeholder": "​",
            "style": "IPY_MODEL_46484784b40b42638f546caa894c749b",
            "value": "Downloading data: 100%"
          }
        },
        "a1923de7f96344cd88adfe7a05110968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ea5316a2dd846fdaf92427175b53814",
            "max": 83920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be0a1eacefb045bfa12b07e018bee21b",
            "value": 83920
          }
        },
        "9fa778aa58b34f7eb13fdf99d2788c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5965a00ce5ff4cad8a37d76d244f41ae",
            "placeholder": "​",
            "style": "IPY_MODEL_7ffeb1bcc53c45ba82c32e5fdbee1dfe",
            "value": " 83.9k/83.9k [00:00&lt;00:00, 388kB/s]"
          }
        },
        "354c34a58f814ca88a2b862af261e803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce5dfd3b818e44b3860898f186894d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46484784b40b42638f546caa894c749b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ea5316a2dd846fdaf92427175b53814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be0a1eacefb045bfa12b07e018bee21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5965a00ce5ff4cad8a37d76d244f41ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ffeb1bcc53c45ba82c32e5fdbee1dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f82d292aee447c3a7806a3791001813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48ea77ae58464c3d8134b8dc60ee20c3",
              "IPY_MODEL_2e27672190554069875566454e17c1a6",
              "IPY_MODEL_4cce4b3045ce4cb588787d9ffa731edf"
            ],
            "layout": "IPY_MODEL_d65c9d5f58a0437899d3d4ced13fdb2b"
          }
        },
        "48ea77ae58464c3d8134b8dc60ee20c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b0dadc7d70949fc93638d3af04e0445",
            "placeholder": "​",
            "style": "IPY_MODEL_6ef935e931624cc79f736fd2003491df",
            "value": "Extracting data files: 100%"
          }
        },
        "2e27672190554069875566454e17c1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d1077f61df4494892c4245312c69272",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c6f5dc10e8645799983340cb534ce0e",
            "value": 1
          }
        },
        "4cce4b3045ce4cb588787d9ffa731edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f36950b897eb429f8456fa9e917ca9d9",
            "placeholder": "​",
            "style": "IPY_MODEL_583820280e5a4d249596e9ea80a48f72",
            "value": " 1/1 [00:00&lt;00:00, 56.39it/s]"
          }
        },
        "d65c9d5f58a0437899d3d4ced13fdb2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b0dadc7d70949fc93638d3af04e0445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef935e931624cc79f736fd2003491df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d1077f61df4494892c4245312c69272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c6f5dc10e8645799983340cb534ce0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f36950b897eb429f8456fa9e917ca9d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "583820280e5a4d249596e9ea80a48f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eea878f4085e44c79a9d95b6d07821ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e8fbbc17c984ab1b2780ce608084e0a",
              "IPY_MODEL_9c02ede9e574458fa29e437cb6dd3918",
              "IPY_MODEL_7dbed2a12ab545269e8dfba97053ed1f"
            ],
            "layout": "IPY_MODEL_d2c653a20eda407a82428e3d21193f1c"
          }
        },
        "4e8fbbc17c984ab1b2780ce608084e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bacc5eaf5a254a10b738b23f088b5797",
            "placeholder": "​",
            "style": "IPY_MODEL_c1f5a43ec37843f0a879b8a2276f19fe",
            "value": "Generating test split: 100%"
          }
        },
        "9c02ede9e574458fa29e437cb6dd3918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_159dc1815c6740e19a360539aed8b6a3",
            "max": 164,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e37078b891845769ece3f3a95a3b585",
            "value": 164
          }
        },
        "7dbed2a12ab545269e8dfba97053ed1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae887f1f93b4fa2aabdfd4dbb465e8a",
            "placeholder": "​",
            "style": "IPY_MODEL_13e4b092956f400da022a37bf7741541",
            "value": " 164/164 [00:00&lt;00:00, 8141.97 examples/s]"
          }
        },
        "d2c653a20eda407a82428e3d21193f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bacc5eaf5a254a10b738b23f088b5797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1f5a43ec37843f0a879b8a2276f19fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "159dc1815c6740e19a360539aed8b6a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e37078b891845769ece3f3a95a3b585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ae887f1f93b4fa2aabdfd4dbb465e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13e4b092956f400da022a37bf7741541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing LLMs with One-Shot Pruning and Quantization\n",
        "\n",
        "This guide delves into optimizing large language models (LLMs) for efficient text generation using neural network compression techniques like sparsification and quantization.\n",
        "You'll learn how to:\n",
        "\n",
        "- <b>Sparsify Models:</b> Apply pruning techniques to eliminate redundant parameters from an LLM, reducing its size and computational requirements.\n",
        "- <b>Quantize Models:</b> Lower the numerical precision of model weights and activations for faster inference with minimal impact on accuracy.\n",
        "- <b>Evaluate Performance:</b> Measure the impact of sparsification and quantization on model accuracy.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- <b>Training Environment:</b> A system that meets the minimum hardware and software requirements as outlined in the [Install Guide](https://docs.neuralmagic.com/get-started/install/#prerequisites)."
      ],
      "metadata": {
        "id": "jmDZCNe4fyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"sparseml[transformers]==1.7\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yAR3Z1-bf8yv",
        "outputId": "4ff84018-66f6-4f42-b606-46de0e71b778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sparseml[transformers]\n",
            "  Downloading sparseml-1.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sparsezoo~=1.7.0 (from sparseml[transformers])\n",
            "  Downloading sparsezoo-1.7.0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools<=59.5.0 (from sparseml[transformers])\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (3.7.1)\n",
            "Collecting merge-args>=0.1.0 (from sparseml[transformers])\n",
            "  Downloading merge_args-0.1.5-py2.py3-none-any.whl (6.0 kB)\n",
            "Collecting onnx<1.15.0,>=1.5.0 (from sparseml[transformers])\n",
            "  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (2.0.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (24.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (5.9.5)\n",
            "Collecting pydantic<2.0.0,>=1.8.2 (from sparseml[transformers])\n",
            "  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (4.66.2)\n",
            "Collecting toposort>=1.0 (from sparseml[transformers])\n",
            "  Downloading toposort-1.10-py3-none-any.whl (8.5 kB)\n",
            "Collecting GPUtil>=1.4.0 (from sparseml[transformers])\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf<=3.20.3,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (3.20.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (8.1.7)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[transformers]) (1.11.4)\n",
            "Collecting torch<2.2,>=1.7.0 (from sparseml[transformers])\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gputils (from sparseml[transformers])\n",
            "  Downloading gputils-1.0.6-py3-none-any.whl (3.8 kB)\n",
            "Collecting nm-transformers~=1.7.0 (from sparseml[transformers])\n",
            "  Downloading nm_transformers-1.7.0.43401-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets<=2.14.6 (from sparseml[transformers])\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dvc (from sparseml[transformers])\n",
            "  Downloading dvc-3.49.0-py3-none-any.whl (450 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.8/450.8 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from sparseml[transformers])\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops (from sparseml[transformers])\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate>=0.4.1 (from sparseml[transformers])\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.20.3 (from sparseml[transformers])\n",
            "  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->sparseml[transformers]) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->sparseml[transformers]) (0.4.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.14.6->sparseml[transformers]) (14.0.2)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets<=2.14.6->sparseml[transformers])\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets<=2.14.6->sparseml[transformers])\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets<=2.14.6->sparseml[transformers])\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.14.6->sparseml[transformers]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=2.14.6->sparseml[transformers]) (3.9.3)\n",
            "Collecting responses<0.19 (from evaluate>=0.4.1->sparseml[transformers])\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[transformers]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[transformers]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[transformers]) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[transformers]) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[transformers]) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[transformers]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[transformers]) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from nm-transformers~=1.7.0->sparseml[transformers]) (3.13.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from nm-transformers~=1.7.0->sparseml[transformers]) (2023.12.25)\n",
            "Collecting tokenizers<0.15,>=0.14 (from nm-transformers~=1.7.0->sparseml[transformers])\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx<1.15.0,>=1.5.0->sparseml[transformers]) (4.10.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->sparseml[transformers]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->sparseml[transformers]) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->sparseml[transformers]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->sparseml[transformers]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->sparseml[transformers]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->sparseml[transformers]) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->sparseml[transformers]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->sparseml[transformers]) (3.4.0)\n",
            "Collecting py-machineid>=0.3.0 (from sparsezoo~=1.7.0->sparseml[transformers])\n",
            "  Downloading py_machineid-0.5.1-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: geocoder>=1.38.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.7.0->sparseml[transformers]) (1.38.1)\n",
            "Collecting onnxruntime>=1.0.0 (from sparsezoo~=1.7.0->sparseml[transformers])\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.7.0->sparseml[transformers]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.7.0->sparseml[transformers]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.7.0->sparseml[transformers]) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.1.0 (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from dvc->sparseml[transformers]) (23.2.0)\n",
            "Collecting celery (from dvc->sparseml[transformers])\n",
            "  Downloading celery-5.3.6-py3-none-any.whl (422 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.0/422.0 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama>=0.3.9 (from dvc->sparseml[transformers])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting configobj>=5.0.6 (from dvc->sparseml[transformers])\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: distro>=1.3 in /usr/lib/python3/dist-packages (from dvc->sparseml[transformers]) (1.7.0)\n",
            "Collecting dpath<3,>=2.1.0 (from dvc->sparseml[transformers])\n",
            "  Downloading dpath-2.1.6-py3-none-any.whl (17 kB)\n",
            "Collecting dulwich (from dvc->sparseml[transformers])\n",
            "  Downloading dulwich-0.21.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (514 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.7/514.7 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dvc-data<3.16,>=3.15 (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_data-3.15.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dvc-http>=2.29.0 (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_http-2.32.0-py3-none-any.whl (12 kB)\n",
            "Collecting dvc-objects (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_objects-5.1.0-py3-none-any.whl (33 kB)\n",
            "Collecting dvc-render<2,>=1.0.1 (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_render-1.0.1-py3-none-any.whl (22 kB)\n",
            "Collecting dvc-studio-client<1,>=0.20 (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_studio_client-0.20.0-py3-none-any.whl (16 kB)\n",
            "Collecting dvc-task<1,>=0.3.0 (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_task-0.4.0-py3-none-any.whl (21 kB)\n",
            "Collecting flatten-dict<1,>=0.4.1 (from dvc->sparseml[transformers])\n",
            "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting flufl.lock<8,>=5 (from dvc->sparseml[transformers])\n",
            "  Downloading flufl.lock-7.1.1-py3-none-any.whl (11 kB)\n",
            "Collecting funcy>=1.14 (from dvc->sparseml[transformers])\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Collecting grandalf<1,>=0.7 (from dvc->sparseml[transformers])\n",
            "  Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gto<2,>=1.6.0 (from dvc->sparseml[transformers])\n",
            "  Downloading gto-1.7.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1 (from dvc->sparseml[transformers])\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting iterative-telemetry>=0.0.7 (from dvc->sparseml[transformers])\n",
            "  Downloading iterative_telemetry-0.0.8-py3-none-any.whl (10 kB)\n",
            "Collecting kombu (from dvc->sparseml[transformers])\n",
            "  Downloading kombu-5.3.6-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf (from dvc->sparseml[transformers])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathspec>=0.10.3 (from dvc->sparseml[transformers])\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Collecting platformdirs<4,>=3.1.1 (from dvc->sparseml[transformers])\n",
            "  Downloading platformdirs-3.11.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pydot>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from dvc->sparseml[transformers]) (1.4.2)\n",
            "Collecting pygtrie>=2.3.2 (from dvc->sparseml[transformers])\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: rich>=12 in /usr/local/lib/python3.10/dist-packages (from dvc->sparseml[transformers]) (13.7.1)\n",
            "Collecting ruamel.yaml>=0.17.11 (from dvc->sparseml[transformers])\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scmrepo<4,>=3 (from dvc->sparseml[transformers])\n",
            "  Downloading scmrepo-3.3.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shortuuid>=0.5 (from dvc->sparseml[transformers])\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Collecting shtab<2,>=1.3.4 (from dvc->sparseml[transformers])\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.10/dist-packages (from dvc->sparseml[transformers]) (0.9.0)\n",
            "Collecting tomlkit>=0.11.1 (from dvc->sparseml[transformers])\n",
            "  Downloading tomlkit-0.12.4-py3-none-any.whl (37 kB)\n",
            "Collecting voluptuous>=0.11.7 (from dvc->sparseml[transformers])\n",
            "  Downloading voluptuous-0.14.2-py3-none-any.whl (31 kB)\n",
            "Collecting zc.lockfile>=1.2.1 (from dvc->sparseml[transformers])\n",
            "  Downloading zc.lockfile-3.0.post1-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj>=5.0.6->dvc->sparseml[transformers]) (1.16.0)\n",
            "Collecting dictdiffer>=0.8.1 (from dvc-data<3.16,>=3.15->dvc->sparseml[transformers])\n",
            "  Downloading dictdiffer-0.9.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting fsspec (from torch<2.2,>=1.7.0->sparseml[transformers])\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.2.1 (from dvc-data<3.16,>=3.15->dvc->sparseml[transformers])\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqltrie<1,>=0.11.0 (from dvc-data<3.16,>=3.15->dvc->sparseml[transformers])\n",
            "  Downloading sqltrie-0.11.0-py3-none-any.whl (17 kB)\n",
            "Collecting aiohttp-retry>=2.5.0 (from dvc-http>=2.29.0->dvc->sparseml[transformers])\n",
            "  Downloading aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
            "Collecting billiard<5.0,>=4.2.0 (from celery->dvc->sparseml[transformers])\n",
            "  Downloading billiard-4.2.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click-didyoumean>=0.3.0 (from celery->dvc->sparseml[transformers])\n",
            "  Downloading click_didyoumean-0.3.1-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: click-plugins>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from celery->dvc->sparseml[transformers]) (1.1.1)\n",
            "Collecting click-repl>=0.2.0 (from celery->dvc->sparseml[transformers])\n",
            "  Downloading click_repl-0.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting vine<6.0,>=5.1.0 (from celery->dvc->sparseml[transformers])\n",
            "  Downloading vine-5.1.0-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: atpublic>=2.3 in /usr/local/lib/python3.10/dist-packages (from flufl.lock<8,>=5->dvc->sparseml[transformers]) (4.1.0)\n",
            "INFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets<=2.14.6->sparseml[transformers])\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.9.1-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.9.0-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dvc-objects (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_objects-5.0.0-py3-none-any.whl (33 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading dvc_objects-4.0.1-py3-none-any.whl (36 kB)\n",
            "Collecting dvc-http>=2.29.0 (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_http-2.31.0-py3-none-any.whl (12 kB)\n",
            "Collecting dvc-data<3.16,>=3.15 (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_data-3.15.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dvc (from sparseml[transformers])\n",
            "  Downloading dvc-3.48.4-py3-none-any.whl (450 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.1/450.1 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dvc-data<3.15,>=3.13 (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_data-3.14.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dvc_data-3.14.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dvc_data-3.13.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dvc (from sparseml[transformers])\n",
            "  Downloading dvc-3.48.3-py3-none-any.whl (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.9/449.9 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of dvc-data to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dvc-3.48.2-py3-none-any.whl (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.5/449.5 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dvc-3.48.1-py3-none-any.whl (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of dvc-data to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dvc-3.48.0-py3-none-any.whl (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.4/449.4 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dvc-3.47.0-py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.9/440.9 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dvc-3.46.0-py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dvc-3.45.0-py3-none-any.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.5/442.5 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading dvc-3.44.0-py3-none-any.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.4/442.4 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dvc-data<3.12,>=3.10 (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_data-3.11.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading dvc_data-3.10.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dvc (from sparseml[transformers])\n",
            "  Downloading dvc-3.43.1-py3-none-any.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.4/442.4 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dvc-data<3.10,>=3.9 (from dvc->sparseml[transformers])\n",
            "  Downloading dvc_data-3.9.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.3/69.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scmrepo<3,>=2.0.2 (from dvc->sparseml[transformers])\n",
            "  Downloading scmrepo-2.1.1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dvc-objects<4,>=3 (from dvc-data<3.10,>=3.9->dvc->sparseml[transformers])\n",
            "  Downloading dvc_objects-3.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.14.6->sparseml[transformers]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.14.6->sparseml[transformers]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.14.6->sparseml[transformers]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.14.6->sparseml[transformers]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.14.6->sparseml[transformers]) (4.0.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.7.0->sparseml[transformers]) (0.18.3)\n",
            "Requirement already satisfied: ratelim in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.7.0->sparseml[transformers]) (0.1.6)\n",
            "INFO: pip is looking at multiple versions of gto to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gto<2,>=1.6.0 (from dvc->sparseml[transformers])\n",
            "  Downloading gto-1.7.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading gto-1.6.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from gto<2,>=1.6.0->dvc->sparseml[transformers]) (0.9.4)\n",
            "Collecting semver>=3.0.0 (from gto<2,>=1.6.0->dvc->sparseml[transformers])\n",
            "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from gto<2,>=1.6.0->dvc->sparseml[transformers]) (0.4)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->dvc->sparseml[transformers])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from iterative-telemetry>=0.0.7->dvc->sparseml[transformers]) (1.4.4)\n",
            "Collecting coloredlogs (from onnxruntime>=1.0.0->sparsezoo~=1.7.0->sparseml[transformers])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.0.0->sparsezoo~=1.7.0->sparseml[transformers]) (24.3.25)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12->dvc->sparseml[transformers]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12->dvc->sparseml[transformers]) (2.16.1)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.11->dvc->sparseml[transformers])\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitpython>3 (from scmrepo<3,>=2.0.2->dvc->sparseml[transformers])\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygit2>=1.14.0 (from scmrepo<3,>=2.0.2->dvc->sparseml[transformers])\n",
            "  Downloading pygit2-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asyncssh<3,>=2.13.1 (from scmrepo<3,>=2.0.2->dvc->sparseml[transformers])\n",
            "  Downloading asyncssh-2.14.2-py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.5/352.5 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub (from accelerate>=0.20.3->sparseml[transformers])\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.2,>=1.7.0->sparseml[transformers]) (2.1.5)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets<=2.14.6->sparseml[transformers])\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.2,>=1.7.0->sparseml[transformers]) (1.3.0)\n",
            "Requirement already satisfied: cryptography>=39.0 in /usr/local/lib/python3.10/dist-packages (from asyncssh<3,>=2.13.1->scmrepo<3,>=2.0.2->dvc->sparseml[transformers]) (42.0.5)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>3->scmrepo<3,>=2.0.2->dvc->sparseml[transformers])\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting amqp<6.0.0,>=5.1.1 (from kombu->dvc->sparseml[transformers])\n",
            "  Downloading amqp-5.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12->dvc->sparseml[transformers]) (0.1.2)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pygit2>=1.14.0->scmrepo<3,>=2.0.2->dvc->sparseml[transformers]) (1.16.0)\n",
            "Collecting orjson (from sqltrie<1,>=0.11.0->dvc-data<3.16,>=3.15->dvc->sparseml[transformers])\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.0.0->sparsezoo~=1.7.0->sparseml[transformers])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ratelim->geocoder>=1.38.0->sparsezoo~=1.7.0->sparseml[transformers]) (4.4.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.16.0->pygit2>=1.14.0->scmrepo<3,>=2.0.2->dvc->sparseml[transformers]) (2.22)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.36 in /usr/local/lib/python3.10/dist-packages (from click-repl>=0.2.0->celery->dvc->sparseml[transformers]) (3.0.43)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>3->scmrepo<3,>=2.0.2->dvc->sparseml[transformers])\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery->dvc->sparseml[transformers]) (0.2.13)\n",
            "Building wheels for collected packages: GPUtil, seqeval, antlr4-python3-runtime\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=ed7bb3b801f3c77268b3a1f1f5a892f37554156687bec9f3cad8e9854cc42562\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=60beb0dd3042458b7818143427bfda9592d30169e11a645d20a5205dd06b9acd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=ae74bf7fe3b939c16834d2189561245597b34f3f6111e3194006ae368bd8203d\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built GPUtil seqeval antlr4-python3-runtime\n",
            "Installing collected packages: toposort, pygtrie, py-machineid, merge-args, GPUtil, funcy, dictdiffer, antlr4-python3-runtime, xxhash, voluptuous, vine, triton, tomlkit, smmap, shtab, shortuuid, setuptools, semver, ruamel.yaml.clib, pydantic, platformdirs, pathspec, orjson, onnx, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, grandalf, flufl.lock, flatten-dict, einops, dvc-render, dvc-objects, dulwich, dpath, diskcache, dill, configobj, colorama, click-didyoumean, billiard, zc.lockfile, sqltrie, ruamel.yaml, responses, pygit2, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, iterative-telemetry, hydra-core, huggingface-hub, gitdb, dvc-studio-client, coloredlogs, click-repl, amqp, tokenizers, seqeval, onnxruntime, nvidia-cusolver-cu12, kombu, gputils, gitpython, dvc-data, asyncssh, aiohttp-retry, torch, sparsezoo, nm-transformers, dvc-http, datasets, celery, sparseml, scmrepo, evaluate, dvc-task, accelerate, gto, dvc\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.4\n",
            "    Uninstalling pydantic-2.6.4:\n",
            "      Successfully uninstalled pydantic-2.6.4\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 4.2.0\n",
            "    Uninstalling platformdirs-4.2.0:\n",
            "      Successfully uninstalled platformdirs-4.2.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\n",
            "cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 59.5.0 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\n",
            "transformers 4.38.2 requires huggingface-hub<1.0,>=0.19.3, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GPUtil-1.4.0 accelerate-0.29.2 aiohttp-retry-2.8.3 amqp-5.2.0 antlr4-python3-runtime-4.9.3 asyncssh-2.14.2 billiard-4.2.0 celery-5.3.6 click-didyoumean-0.3.1 click-repl-0.3.0 colorama-0.4.6 coloredlogs-15.0.1 configobj-5.0.8 datasets-2.14.6 dictdiffer-0.9.0 dill-0.3.7 diskcache-5.6.3 dpath-2.1.6 dulwich-0.21.7 dvc-3.43.1 dvc-data-3.9.0 dvc-http-2.32.0 dvc-objects-3.0.6 dvc-render-1.0.1 dvc-studio-client-0.20.0 dvc-task-0.4.0 einops-0.7.0 evaluate-0.4.1 flatten-dict-0.4.2 flufl.lock-7.1.1 funcy-2.0 gitdb-4.0.11 gitpython-3.1.43 gputils-1.0.6 grandalf-0.8 gto-1.6.2 huggingface-hub-0.17.3 humanfriendly-10.0 hydra-core-1.3.2 iterative-telemetry-0.0.8 kombu-5.3.6 merge-args-0.1.5 multiprocess-0.70.15 nm-transformers-1.7.0.43401 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 onnx-1.14.1 onnxruntime-1.17.1 orjson-3.10.0 pathspec-0.12.1 platformdirs-3.11.0 py-machineid-0.5.1 pydantic-1.10.15 pygit2-1.14.1 pygtrie-2.5.0 responses-0.18.0 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 scmrepo-2.1.1 semver-3.0.2 seqeval-1.2.2 setuptools-59.5.0 shortuuid-1.0.13 shtab-1.7.1 smmap-5.0.1 sparseml-1.7.0 sparsezoo-1.7.0 sqltrie-0.11.0 tokenizers-0.14.1 tomlkit-0.12.4 toposort-1.10 torch-2.1.2 triton-2.1.0 vine-5.1.0 voluptuous-0.14.2 xxhash-3.4.1 zc.lockfile-3.0.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "pydevd_plugins",
                  "setuptools"
                ]
              },
              "id": "0a846c36873c4fcf860de1257f69fd9e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Sparsifying a Llama Model\n",
        "\n",
        "We'll use a pre-trained, unoptimized [TinyLlama 1.1B chat model](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0) from the HuggingFace Hub.\n",
        "The model is referenced by the following stub:\n",
        "```text\n",
        "TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
        "```\n",
        "\n",
        "For additional models that work with SparseML, consider the following options:\n",
        "- Explore pre-sparsified [Generative AI models in the SparseZoo](https://sparsezoo.neuralmagic.com/?modelSet=generative_ai).\n",
        "- Try out popular LLMs from the [Hugging Face Model Hub](https://huggingface.co/models?pipeline_tag=causal-lm)."
      ],
      "metadata": {
        "id": "ZqpLNT70gOQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation\n",
        "\n",
        "SparseML requires a dataset to be used for calibration during the sparsification process.\n",
        "For this example, we'll use the Open Platypus dataset, which is available in the Hugging Face dataset hub and can be loaded as follows:"
      ],
      "metadata": {
        "id": "UITJUrfkf8Rh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "f88e7912644644cc9aebde158506dc85",
            "b5613f09607d4931a1b6b416a62b96b1",
            "cbe8cbc443c6477bbf6ae9e308798e24",
            "b9e1df5d33af4959864474bc34a57bd5",
            "26aa6d41217a41b18c4f374d815de764",
            "d172de3545ad45fca55377f9cf885797",
            "4d883091390a43d9989db7fa35d569bf",
            "14e6cf5d1cb44bf8b8aef9db167d27ba",
            "2132083cadb34d3a945964c41c3f1663",
            "0b2b7cb1e2414ab5b5d10f253c552c36",
            "d7123dcd52c0452583c3ad987b45d7fd",
            "9d5068e1150a4a6fb37479e951afb021",
            "9a2aff8bd85547aaa4c9653fdd6df456",
            "63ed9a07377b43aa853896815418b8c6",
            "a022a1fe4cb94b33a3338ffe49f7a407",
            "4b0539dffc3b49d1aa83c4b061c8649a",
            "7604dad8589d4889b97893e06aa1c467",
            "3d0e7ecce8e94c06af51842cf2d69456",
            "60baad141b7f4f3b83c6877a8993c541",
            "cea37a88bba94744b936af4b8c5b6519",
            "3f601c6f2c524b5eba928c2a80c9b63a",
            "b82da9a5c2ec4d09bd1f0156182b1321",
            "668badd5598b4da7af99bdf32f31bdd3",
            "f70b8a6637f444c0ac0ed44749b78697",
            "541442e255294dfa9d2fdb8eacee84ee",
            "2d1aca37e36d4cb2b0366a7932056270",
            "4b9149f4721a4d9ab959334ccf7f4254",
            "5b936680e59443f6861cd89af51d30a8",
            "cd5dd0c507b547cf94c346cf0112ba79",
            "0ed569c0a3ce43e8be760b0cbb74254e",
            "04eff42db8dd4c8aba8af3b1f81b72a0",
            "19b19a009311428981b292b176174b00",
            "293f27e94dfb4b2bab3472baa1726a94",
            "9146b61b3201444e9fb373c0b3b7b14c",
            "e45c83311cd94ac99160fb288abbbd29",
            "291ea8a22bb14538886c98a3f3d0e7f1",
            "93384fbfec79426db3be4b64e4990acf",
            "c069360907a641c2ab4d51ca896f494a",
            "b47a9f7e3780449f9e4d9af483e0f6d4",
            "d558a7bc2de24045a10aab4f47ec3a9c",
            "86bf644c5f964776ad30d114705b1fe5",
            "24115b25f973427f900c8ccf7d3e43c5",
            "53b2da72dda0487dbac7eb75ed1adfe5",
            "a3b699d0b3c54c8985adbfe1763be57c",
            "4d85c92fbc1641e2bdb0853e7ff1e6c9",
            "49b2b8b38cac4a4da98537f6575e0e7e",
            "b20339935f2e42d4b427f230843a55d2",
            "fa1a692f071c40d7bb4bbe1d7ec8809d",
            "98541916af0646e8a5e4f64b90feff1d",
            "1a3dd6dda51949e7a48e0a0529318259",
            "083bdbd53be045d7ad2c18e5375de3ef",
            "56a1199a0b5045b29c1f75dec65cc8dd",
            "4454e5d8f3014570b69859602be522dc",
            "fa35bb93a4e74833afbfc04f849525c5",
            "493b05f50f6c41deaea605da7dc4fb2e"
          ]
        },
        "id": "XnCawlv2fuHY",
        "outputId": "52684258-6ec6-45e3-cb84-8374e89835e2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/5.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f88e7912644644cc9aebde158506dc85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d5068e1150a4a6fb37479e951afb021"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/15.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "668badd5598b4da7af99bdf32f31bdd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9146b61b3201444e9fb373c0b3b7b14c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/24926 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d85c92fbc1641e2bdb0853e7ff1e6c9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"garage-bAInd/Open-Platypus\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One Shot Compression\n",
        "\n",
        "Applying pruning and quantization to an LLM without fine-tuning can be done utilizing recipes, the SparseGPT algorithm, and the `compress` command in SparseML.\n",
        "This combination enables a quick and easy way to sparsify a model, resulting in medium compression levels with minimal accuracy loss, enabling efficient inference.\n",
        "\n",
        "The code below demonstrates applying one-shot sparsification to the Llama chat model utilizing a recipe.\n",
        "The recipe specifies using the SparseGPTModifier to apply 50% sparsity and quantization (int8 weights and activations) to the targeted layers within the model."
      ],
      "metadata": {
        "id": "yYS8wT1ZgtSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparseml.transformers import (\n",
        "    SparseAutoModelForCausalLM, SparseAutoTokenizer, compress\n",
        ")\n",
        "\n",
        "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "model = SparseAutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
        "tokenizer = SparseAutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "def format_data(data):\n",
        "    return {\n",
        "        \"text\": data[\"instruction\"] + data[\"output\"]\n",
        "    }\n",
        "\n",
        "dataset = dataset.map(format_data)\n",
        "\n",
        "recipe = \"\"\"\n",
        "compression_stage:\n",
        "    run_type: oneshot\n",
        "    oneshot_modifiers:\n",
        "        QuantizationModifier:\n",
        "            ignore: [LlamaRotaryEmbedding, LlamaRMSNorm, SiLUActivation, QuantizableMatMul]\n",
        "            post_oneshot_calibration: true\n",
        "            scheme_overrides:\n",
        "                Linear:\n",
        "                    weights:\n",
        "                        num_bits: 8\n",
        "                        symmetric: true\n",
        "                        strategy: channel\n",
        "                Embedding:\n",
        "                    input_activations: null\n",
        "                    weights:\n",
        "                        num_bits: 8\n",
        "                        symmetric: false\n",
        "        SparseGPTModifier:\n",
        "            sparsity: 0.5\n",
        "            quantize: True\n",
        "            targets: ['re:model.layers.\\d*$']\n",
        "\"\"\"\n",
        "\n",
        "compress(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    dataset=dataset,\n",
        "    recipe=recipe,\n",
        "    output_dir=\"./one-shot-example\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1f890caff902465e8e7dac7b21869836",
            "f800199bc8bb47d59e1236874490d4a0",
            "bf09fe3887b04671aebef9d33608b5b3",
            "b990d04d4e72475ba80823390f66de81",
            "f59a5bd89fca4381aa52e787741b3912",
            "7da13fe7a4ae436faeefed737092ba5a",
            "210b60a9bdc4420695044b9aaa9834e6",
            "876ed6cd27484a04b85766c4ee8fa63f",
            "65c072e48daa4b948ae0722b7555df28",
            "176c7743445440ce8068ce085b3f8ef9",
            "c90075d6148a4b319d9013802910406d",
            "9b5d22f62189499bba79b301f1b82c35",
            "c3785c1bccf943449c61a53117738435",
            "9c2cb8fb37044fadb3f2489046e49c2a",
            "af95c89538d642aba3aedc52517bc273",
            "1893f8c5d22a4399a978c9143c007ebb",
            "859ddf7426664c9db9d48911694cdd0c",
            "278e7e63d81f427b936e1216d9a54aea",
            "803ac0a865f04c68a6ed81f468e0e947",
            "5b453bf2141b43e19b6878e3e7ac9f98",
            "e5b165ed08d44010927ad9c692d11f5c",
            "aa24312996d34ae980d633d5a33e2b0b",
            "0845f9268c0e4611ae06453c427ba0e7",
            "587e5bbc302e4e1ea788b3d6566f8b44",
            "9b11504298ef42c59f116d4a87b633e5",
            "6b6c9d1d40844e82ab1f9a77245e9c55",
            "052aab2e46c04aec9d74a2d2c790c89b",
            "ac6ecb4e2138488899e562a479c3ccf3",
            "f85c6233cf4f4db890eba08dbb033ccd",
            "05140cbe91884cddbf91d1bc4fee97b6",
            "c7e6e30493e74fef87038c6bb33e15e4",
            "ec6e29307b8945a6bb5c897ac39e722a",
            "7da61493a2834b909345f564a1a3f952",
            "457f2f1288ee4ef7b42e4b74f6d8c98d",
            "0f7e797b92cd4b17a96b78e612d60cc9",
            "55d92469e7e148ed81c1bfb65d164549",
            "84e705e3f8494fcabed8d36286ed9055",
            "d68c61025f384a69896795d65f81c846",
            "04d43110b54e44b3a938da85d89c11ac",
            "a651933758224425b82b107539c84bdb",
            "20f0af5f21994973a675e28fe6749f87",
            "642fa87839214e7e921a3032b51106dc",
            "a30b5e378fce4cb0bd2be85896d1e1c0",
            "ae143e5099744d1fb8dccf775cb7e3b3"
          ]
        },
        "id": "PPFDGDHNg_Bt",
        "outputId": "ef671e7d-c96f-4543-b345-4a3a762bce70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-04-09 20:33:32 sparseml.transformers.utils.helpers INFO     model_path is a huggingface model id. Attempting to download recipe from https://huggingface.co/\n",
            "INFO:sparseml.transformers.utils.helpers:model_path is a huggingface model id. Attempting to download recipe from https://huggingface.co/\n",
            "2024-04-09 20:33:32 sparseml.transformers.utils.helpers INFO     Found recipe: recipe.yaml for model id: TinyLlama/TinyLlama-1.1B-Chat-v1.0. Downloading...\n",
            "INFO:sparseml.transformers.utils.helpers:Found recipe: recipe.yaml for model id: TinyLlama/TinyLlama-1.1B-Chat-v1.0. Downloading...\n",
            "2024-04-09 20:33:32 sparseml.transformers.utils.helpers INFO     Unable to to find recipe recipe.yaml for model id: TinyLlama/TinyLlama-1.1B-Chat-v1.0: 404 Client Error. (Request ID: Root=1-6615a61c-65654cad30dc82d40293b87a;9622e80a-d4fb-4a6e-bd44-2d2c2dd7456b)\n",
            "\n",
            "Entry Not Found for url: https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/recipe.yaml.. Skipping recipe resolution.\n",
            "INFO:sparseml.transformers.utils.helpers:Unable to to find recipe recipe.yaml for model id: TinyLlama/TinyLlama-1.1B-Chat-v1.0: 404 Client Error. (Request ID: Root=1-6615a61c-65654cad30dc82d40293b87a;9622e80a-d4fb-4a6e-bd44-2d2c2dd7456b)\n",
            "\n",
            "Entry Not Found for url: https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/recipe.yaml.. Skipping recipe resolution.\n",
            "2024-04-09 20:33:32 sparseml.transformers.utils.helpers INFO     Failed to infer the recipe from the model_path\n",
            "INFO:sparseml.transformers.utils.helpers:Failed to infer the recipe from the model_path\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/24926 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f890caff902465e8e7dac7b21869836"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-04-09 20:33:34 sparseml.core.recipe.recipe WARNING  Could not process input as a file path or zoo stub, attempting to process it as a string.\n",
            "WARNING:sparseml.core.recipe.recipe:Could not process input as a file path or zoo stub, attempting to process it as a string.\n",
            "2024-04-09 20:33:34 sparseml.core.recipe.recipe WARNING  Input string: \n",
            "compression_stage:\n",
            "    run_type: oneshot\n",
            "    oneshot_modifiers:\n",
            "        QuantizationModifier:\n",
            "            ignore: [LlamaRotaryEmbedding, LlamaRMSNorm, SiLUActivation, QuantizableMatMul]\n",
            "            post_oneshot_calibration: true\n",
            "            scheme_overrides:\n",
            "                Linear:\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: true\n",
            "                        strategy: channel\n",
            "                Embedding:\n",
            "                    input_activations: null\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: false\n",
            "        SparseGPTModifier:\n",
            "            sparsity: 0.5\n",
            "            quantize: True\n",
            "            targets: ['re:model.layers.\\d*$']\n",
            "\n",
            "WARNING:sparseml.core.recipe.recipe:Input string: \n",
            "compression_stage:\n",
            "    run_type: oneshot\n",
            "    oneshot_modifiers:\n",
            "        QuantizationModifier:\n",
            "            ignore: [LlamaRotaryEmbedding, LlamaRMSNorm, SiLUActivation, QuantizableMatMul]\n",
            "            post_oneshot_calibration: true\n",
            "            scheme_overrides:\n",
            "                Linear:\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: true\n",
            "                        strategy: channel\n",
            "                Embedding:\n",
            "                    input_activations: null\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: false\n",
            "        SparseGPTModifier:\n",
            "            sparsity: 0.5\n",
            "            quantize: True\n",
            "            targets: ['re:model.layers.\\d*$']\n",
            "\n",
            "2024-04-09 20:33:34 sparseml.transformers.finetune.text_generation WARNING  Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "WARNING:sparseml.transformers.finetune.text_generation:Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Removing unneeded columns:   0%|          | 0/24926 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b5d22f62189499bba79b301f1b82c35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/24926 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0845f9268c0e4611ae06453c427ba0e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding labels:   0%|          | 0/24926 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "457f2f1288ee4ef7b42e4b74f6d8c98d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
            "  warnings.warn(\n",
            "2024-04-09 20:33:55 sparseml.core.recipe.recipe WARNING  Could not process input as a file path or zoo stub, attempting to process it as a string.\n",
            "WARNING:sparseml.core.recipe.recipe:Could not process input as a file path or zoo stub, attempting to process it as a string.\n",
            "2024-04-09 20:33:55 sparseml.core.recipe.recipe WARNING  Input string: \n",
            "compression_stage:\n",
            "    run_type: oneshot\n",
            "    oneshot_modifiers:\n",
            "        QuantizationModifier:\n",
            "            ignore: [LlamaRotaryEmbedding, LlamaRMSNorm, SiLUActivation, QuantizableMatMul]\n",
            "            post_oneshot_calibration: true\n",
            "            scheme_overrides:\n",
            "                Linear:\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: true\n",
            "                        strategy: channel\n",
            "                Embedding:\n",
            "                    input_activations: null\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: false\n",
            "        SparseGPTModifier:\n",
            "            sparsity: 0.5\n",
            "            quantize: True\n",
            "            targets: ['re:model.layers.\\d*$']\n",
            "\n",
            "WARNING:sparseml.core.recipe.recipe:Input string: \n",
            "compression_stage:\n",
            "    run_type: oneshot\n",
            "    oneshot_modifiers:\n",
            "        QuantizationModifier:\n",
            "            ignore: [LlamaRotaryEmbedding, LlamaRMSNorm, SiLUActivation, QuantizableMatMul]\n",
            "            post_oneshot_calibration: true\n",
            "            scheme_overrides:\n",
            "                Linear:\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: true\n",
            "                        strategy: channel\n",
            "                Embedding:\n",
            "                    input_activations: null\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: false\n",
            "        SparseGPTModifier:\n",
            "            sparsity: 0.5\n",
            "            quantize: True\n",
            "            targets: ['re:model.layers.\\d*$']\n",
            "\n",
            "2024-04-09 20:33:55 sparseml.transformers.finetune.runner INFO     *** One Shot ***\n",
            "INFO:sparseml.transformers.finetune.runner:*** One Shot ***\n",
            "2024-04-09 20:33:55 sparseml.core.recipe.recipe WARNING  Could not process input as a file path or zoo stub, attempting to process it as a string.\n",
            "WARNING:sparseml.core.recipe.recipe:Could not process input as a file path or zoo stub, attempting to process it as a string.\n",
            "2024-04-09 20:33:55 sparseml.core.recipe.recipe WARNING  Input string: \n",
            "compression_stage:\n",
            "    run_type: oneshot\n",
            "    oneshot_modifiers:\n",
            "        QuantizationModifier:\n",
            "            ignore: [LlamaRotaryEmbedding, LlamaRMSNorm, SiLUActivation, QuantizableMatMul]\n",
            "            post_oneshot_calibration: true\n",
            "            scheme_overrides:\n",
            "                Linear:\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: true\n",
            "                        strategy: channel\n",
            "                Embedding:\n",
            "                    input_activations: null\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: false\n",
            "        SparseGPTModifier:\n",
            "            sparsity: 0.5\n",
            "            quantize: True\n",
            "            targets: ['re:model.layers.\\d*$']\n",
            "\n",
            "WARNING:sparseml.core.recipe.recipe:Input string: \n",
            "compression_stage:\n",
            "    run_type: oneshot\n",
            "    oneshot_modifiers:\n",
            "        QuantizationModifier:\n",
            "            ignore: [LlamaRotaryEmbedding, LlamaRMSNorm, SiLUActivation, QuantizableMatMul]\n",
            "            post_oneshot_calibration: true\n",
            "            scheme_overrides:\n",
            "                Linear:\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: true\n",
            "                        strategy: channel\n",
            "                Embedding:\n",
            "                    input_activations: null\n",
            "                    weights:\n",
            "                        num_bits: 8\n",
            "                        symmetric: false\n",
            "        SparseGPTModifier:\n",
            "            sparsity: 0.5\n",
            "            quantize: True\n",
            "            targets: ['re:model.layers.\\d*$']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': ['input_ids', 'attention_mask', 'labels']}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-04-09 20:33:55 sparseml.modifiers.quantization.pytorch INFO     Running QuantizationModifier calibration with 512 samples...\n",
            "INFO:sparseml.modifiers.quantization.pytorch:Running QuantizationModifier calibration with 512 samples...\n",
            "100%|██████████| 512/512 [04:42<00:00,  1.81it/s]\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.0 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.0 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.1 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.1 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.2 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.2 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.3 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.3 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.4 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.4 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.5 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.5 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.6 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.6 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.7 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.7 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.8 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.8 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.9 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.9 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.10 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.10 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.11 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.11 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.12 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.12 for compression\n",
            "2024-04-09 20:38:38 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.13 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.13 for compression\n",
            "2024-04-09 20:38:39 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.14 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.14 for compression\n",
            "2024-04-09 20:38:39 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.15 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.15 for compression\n",
            "2024-04-09 20:38:39 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.16 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.16 for compression\n",
            "2024-04-09 20:38:39 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.17 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.17 for compression\n",
            "2024-04-09 20:38:39 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.18 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.18 for compression\n",
            "2024-04-09 20:38:39 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.19 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.19 for compression\n",
            "2024-04-09 20:38:39 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.20 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.20 for compression\n",
            "2024-04-09 20:38:39 sparseml.modifiers.pruning.wanda.pytorch INFO     Preparing model.layers.21 for compression\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Preparing model.layers.21 for compression\n",
            "2024-04-09 20:38:39 sparseml.modifiers.pruning.wanda.pytorch INFO     Running SparseGPTModifier calibration with 512 samples...\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:Running SparseGPTModifier calibration with 512 samples...\n",
            "100%|██████████| 512/512 [06:19<00:00,  1.35it/s]\n",
            "2024-04-09 20:44:58 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 1/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 1/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:44:58 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.0.model.layers.0.self_attn.q_proj.module...\n",
            "2024-04-09 20:44:59 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 0.99\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 0.99\n",
            "2024-04-09 20:44:59 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 0.51\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 0.51\n",
            "2024-04-09 20:44:59 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.0.model.layers.0.self_attn.k_proj.module...\n",
            "2024-04-09 20:45:00 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.00\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.00\n",
            "2024-04-09 20:45:00 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 0.43\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 0.43\n",
            "2024-04-09 20:45:00 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.0.model.layers.0.self_attn.v_proj.module...\n",
            "2024-04-09 20:45:01 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.10\n",
            "2024-04-09 20:45:01 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 0.02\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 0.02\n",
            "2024-04-09 20:45:01 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.0.model.layers.0.self_attn.o_proj.module...\n",
            "2024-04-09 20:45:02 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:45:02 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 0.02\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 0.02\n",
            "2024-04-09 20:45:02 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.0.model.layers.0.mlp.gate_proj.module...\n",
            "2024-04-09 20:45:03 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.18\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.18\n",
            "2024-04-09 20:45:03 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 80.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 80.10\n",
            "2024-04-09 20:45:03 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.0.model.layers.0.mlp.up_proj.module...\n",
            "2024-04-09 20:45:04 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.11\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.11\n",
            "2024-04-09 20:45:04 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 86.40\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 86.40\n",
            "2024-04-09 20:45:04 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.0.model.layers.0.mlp.down_proj.module...\n",
            "2024-04-09 20:45:07 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.98\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.98\n",
            "2024-04-09 20:45:07 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 0.31\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 0.31\n",
            "2024-04-09 20:45:07 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 2/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 2/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:45:07 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.1.model.layers.1.self_attn.q_proj.module...\n",
            "2024-04-09 20:45:08 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:45:08 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 37.61\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 37.61\n",
            "2024-04-09 20:45:08 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.1.model.layers.1.self_attn.k_proj.module...\n",
            "2024-04-09 20:45:09 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.02\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.02\n",
            "2024-04-09 20:45:09 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 9.86\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 9.86\n",
            "2024-04-09 20:45:09 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.1.model.layers.1.self_attn.v_proj.module...\n",
            "2024-04-09 20:45:10 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:45:10 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1.43\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1.43\n",
            "2024-04-09 20:45:10 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.1.model.layers.1.self_attn.o_proj.module...\n",
            "2024-04-09 20:45:12 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.05\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.05\n",
            "2024-04-09 20:45:12 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 0.40\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 0.40\n",
            "2024-04-09 20:45:12 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.1.model.layers.1.mlp.gate_proj.module...\n",
            "2024-04-09 20:45:13 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.09\n",
            "2024-04-09 20:45:13 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 329.56\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 329.56\n",
            "2024-04-09 20:45:13 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.1.model.layers.1.mlp.up_proj.module...\n",
            "2024-04-09 20:45:14 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.10\n",
            "2024-04-09 20:45:14 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 298.14\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 298.14\n",
            "2024-04-09 20:45:14 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.1.model.layers.1.mlp.down_proj.module...\n",
            "2024-04-09 20:45:17 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.89\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.89\n",
            "2024-04-09 20:45:17 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 0.87\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 0.87\n",
            "2024-04-09 20:45:17 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 3/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 3/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:45:17 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.2.model.layers.2.self_attn.q_proj.module...\n",
            "2024-04-09 20:45:18 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.07\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.07\n",
            "2024-04-09 20:45:18 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 174.46\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 174.46\n",
            "2024-04-09 20:45:18 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.2.model.layers.2.self_attn.k_proj.module...\n",
            "2024-04-09 20:45:19 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.07\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.07\n",
            "2024-04-09 20:45:19 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 51.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 51.09\n",
            "2024-04-09 20:45:19 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.2.model.layers.2.self_attn.v_proj.module...\n",
            "2024-04-09 20:45:20 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.05\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.05\n",
            "2024-04-09 20:45:20 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3.67\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3.67\n",
            "2024-04-09 20:45:20 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.2.model.layers.2.self_attn.o_proj.module...\n",
            "2024-04-09 20:45:21 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:45:21 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 0.91\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 0.91\n",
            "2024-04-09 20:45:21 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.2.model.layers.2.mlp.gate_proj.module...\n",
            "2024-04-09 20:45:22 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.11\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.11\n",
            "2024-04-09 20:45:22 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 616.55\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 616.55\n",
            "2024-04-09 20:45:22 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.2.model.layers.2.mlp.up_proj.module...\n",
            "2024-04-09 20:45:23 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.09\n",
            "2024-04-09 20:45:23 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 561.61\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 561.61\n",
            "2024-04-09 20:45:23 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.2.model.layers.2.mlp.down_proj.module...\n",
            "2024-04-09 20:45:26 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.95\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.95\n",
            "2024-04-09 20:45:26 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 0.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 0.04\n",
            "2024-04-09 20:45:26 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 4/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 4/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:45:26 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.3.model.layers.3.self_attn.q_proj.module...\n",
            "2024-04-09 20:45:27 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:45:27 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 697.37\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 697.37\n",
            "2024-04-09 20:45:27 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.3.model.layers.3.self_attn.k_proj.module...\n",
            "2024-04-09 20:45:28 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.09\n",
            "2024-04-09 20:45:28 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 249.66\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 249.66\n",
            "2024-04-09 20:45:28 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.3.model.layers.3.self_attn.v_proj.module...\n",
            "2024-04-09 20:45:29 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.10\n",
            "2024-04-09 20:45:29 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 19.36\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 19.36\n",
            "2024-04-09 20:45:29 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.3.model.layers.3.self_attn.o_proj.module...\n",
            "2024-04-09 20:45:31 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:45:31 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1.02\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1.02\n",
            "2024-04-09 20:45:31 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.3.model.layers.3.mlp.gate_proj.module...\n",
            "2024-04-09 20:45:32 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.15\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.15\n",
            "2024-04-09 20:45:32 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 753.91\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 753.91\n",
            "2024-04-09 20:45:32 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.3.model.layers.3.mlp.up_proj.module...\n",
            "2024-04-09 20:45:33 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.19\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.19\n",
            "2024-04-09 20:45:33 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 653.68\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 653.68\n",
            "2024-04-09 20:45:33 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.3.model.layers.3.mlp.down_proj.module...\n",
            "2024-04-09 20:45:36 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 3.00\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 3.00\n",
            "2024-04-09 20:45:36 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2.79\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2.79\n",
            "2024-04-09 20:45:36 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 5/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 5/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:45:36 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.4.model.layers.4.self_attn.q_proj.module...\n",
            "2024-04-09 20:45:37 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.10\n",
            "2024-04-09 20:45:37 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1734.24\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1734.24\n",
            "2024-04-09 20:45:37 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.4.model.layers.4.self_attn.k_proj.module...\n",
            "2024-04-09 20:45:38 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:45:38 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 688.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 688.09\n",
            "2024-04-09 20:45:38 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.4.model.layers.4.self_attn.v_proj.module...\n",
            "2024-04-09 20:45:39 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:45:39 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 38.18\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 38.18\n",
            "2024-04-09 20:45:39 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.4.model.layers.4.self_attn.o_proj.module...\n",
            "2024-04-09 20:45:40 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:45:40 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1.30\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1.30\n",
            "2024-04-09 20:45:40 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.4.model.layers.4.mlp.gate_proj.module...\n",
            "2024-04-09 20:45:41 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.09\n",
            "2024-04-09 20:45:41 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1210.00\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1210.00\n",
            "2024-04-09 20:45:41 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.4.model.layers.4.mlp.up_proj.module...\n",
            "2024-04-09 20:45:42 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:45:42 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1015.94\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1015.94\n",
            "2024-04-09 20:45:42 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.4.model.layers.4.mlp.down_proj.module...\n",
            "2024-04-09 20:45:45 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.92\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.92\n",
            "2024-04-09 20:45:45 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 5.32\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 5.32\n",
            "2024-04-09 20:45:45 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 6/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 6/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:45:45 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.5.model.layers.5.self_attn.q_proj.module...\n",
            "2024-04-09 20:45:46 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:45:46 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1606.81\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1606.81\n",
            "2024-04-09 20:45:46 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.5.model.layers.5.self_attn.k_proj.module...\n",
            "2024-04-09 20:45:47 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.03\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.03\n",
            "2024-04-09 20:45:47 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 624.41\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 624.41\n",
            "2024-04-09 20:45:47 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.5.model.layers.5.self_attn.v_proj.module...\n",
            "2024-04-09 20:45:48 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:45:48 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 44.20\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 44.20\n",
            "2024-04-09 20:45:48 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.5.model.layers.5.self_attn.o_proj.module...\n",
            "2024-04-09 20:45:49 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:45:50 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2.09\n",
            "2024-04-09 20:45:50 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.5.model.layers.5.mlp.gate_proj.module...\n",
            "2024-04-09 20:45:51 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:45:51 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1612.87\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1612.87\n",
            "2024-04-09 20:45:51 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.5.model.layers.5.mlp.up_proj.module...\n",
            "2024-04-09 20:45:52 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:45:52 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1333.33\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1333.33\n",
            "2024-04-09 20:45:52 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.5.model.layers.5.mlp.down_proj.module...\n",
            "2024-04-09 20:45:55 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.85\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.85\n",
            "2024-04-09 20:45:55 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 9.11\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 9.11\n",
            "2024-04-09 20:45:55 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 7/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 7/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:45:55 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.6.model.layers.6.self_attn.q_proj.module...\n",
            "2024-04-09 20:45:56 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.03\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.03\n",
            "2024-04-09 20:45:56 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1304.93\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1304.93\n",
            "2024-04-09 20:45:56 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.6.model.layers.6.self_attn.k_proj.module...\n",
            "2024-04-09 20:45:57 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 0.98\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 0.98\n",
            "2024-04-09 20:45:57 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 511.40\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 511.40\n",
            "2024-04-09 20:45:57 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.6.model.layers.6.self_attn.v_proj.module...\n",
            "2024-04-09 20:45:58 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:45:58 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 36.61\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 36.61\n",
            "2024-04-09 20:45:58 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.6.model.layers.6.self_attn.o_proj.module...\n",
            "2024-04-09 20:45:59 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.11\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.11\n",
            "2024-04-09 20:45:59 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3.40\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3.40\n",
            "2024-04-09 20:45:59 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.6.model.layers.6.mlp.gate_proj.module...\n",
            "2024-04-09 20:46:00 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.10\n",
            "2024-04-09 20:46:00 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1954.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1954.10\n",
            "2024-04-09 20:46:00 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.6.model.layers.6.mlp.up_proj.module...\n",
            "2024-04-09 20:46:01 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.10\n",
            "2024-04-09 20:46:01 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1532.54\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1532.54\n",
            "2024-04-09 20:46:01 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.6.model.layers.6.mlp.down_proj.module...\n",
            "2024-04-09 20:46:04 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 3.12\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 3.12\n",
            "2024-04-09 20:46:04 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 13.64\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 13.64\n",
            "2024-04-09 20:46:04 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 8/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 8/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:46:04 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.7.model.layers.7.self_attn.q_proj.module...\n",
            "2024-04-09 20:46:05 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.15\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.15\n",
            "2024-04-09 20:46:05 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1850.76\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1850.76\n",
            "2024-04-09 20:46:05 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.7.model.layers.7.self_attn.k_proj.module...\n",
            "2024-04-09 20:46:06 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:46:06 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 632.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 632.09\n",
            "2024-04-09 20:46:06 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.7.model.layers.7.self_attn.v_proj.module...\n",
            "2024-04-09 20:46:07 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:46:07 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 69.99\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 69.99\n",
            "2024-04-09 20:46:07 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.7.model.layers.7.self_attn.o_proj.module...\n",
            "2024-04-09 20:46:09 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.16\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.16\n",
            "2024-04-09 20:46:09 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 6.15\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 6.15\n",
            "2024-04-09 20:46:09 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.7.model.layers.7.mlp.gate_proj.module...\n",
            "2024-04-09 20:46:10 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.23\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.23\n",
            "2024-04-09 20:46:10 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2531.16\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2531.16\n",
            "2024-04-09 20:46:10 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.7.model.layers.7.mlp.up_proj.module...\n",
            "2024-04-09 20:46:11 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.13\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.13\n",
            "2024-04-09 20:46:11 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1718.88\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1718.88\n",
            "2024-04-09 20:46:11 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.7.model.layers.7.mlp.down_proj.module...\n",
            "2024-04-09 20:46:14 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.98\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.98\n",
            "2024-04-09 20:46:14 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2.35\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2.35\n",
            "2024-04-09 20:46:14 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 9/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 9/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:46:14 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.8.model.layers.8.self_attn.q_proj.module...\n",
            "2024-04-09 20:46:15 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:46:15 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1927.07\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1927.07\n",
            "2024-04-09 20:46:15 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.8.model.layers.8.self_attn.k_proj.module...\n",
            "2024-04-09 20:46:16 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 0.98\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 0.98\n",
            "2024-04-09 20:46:16 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 717.70\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 717.70\n",
            "2024-04-09 20:46:16 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.8.model.layers.8.self_attn.v_proj.module...\n",
            "2024-04-09 20:46:17 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:46:17 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 63.43\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 63.43\n",
            "2024-04-09 20:46:17 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.8.model.layers.8.self_attn.o_proj.module...\n",
            "2024-04-09 20:46:18 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:46:18 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 10.35\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 10.35\n",
            "2024-04-09 20:46:18 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.8.model.layers.8.mlp.gate_proj.module...\n",
            "2024-04-09 20:46:19 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:46:19 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2878.27\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2878.27\n",
            "2024-04-09 20:46:19 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.8.model.layers.8.mlp.up_proj.module...\n",
            "2024-04-09 20:46:20 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.07\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.07\n",
            "2024-04-09 20:46:20 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2140.31\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2140.31\n",
            "2024-04-09 20:46:20 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.8.model.layers.8.mlp.down_proj.module...\n",
            "2024-04-09 20:46:23 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.94\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.94\n",
            "2024-04-09 20:46:23 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 26.15\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 26.15\n",
            "2024-04-09 20:46:23 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 10/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 10/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:46:23 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.9.model.layers.9.self_attn.q_proj.module...\n",
            "2024-04-09 20:46:24 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.07\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.07\n",
            "2024-04-09 20:46:24 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2233.28\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2233.28\n",
            "2024-04-09 20:46:24 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.9.model.layers.9.self_attn.k_proj.module...\n",
            "2024-04-09 20:46:25 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.01\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.01\n",
            "2024-04-09 20:46:25 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 902.78\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 902.78\n",
            "2024-04-09 20:46:25 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.9.model.layers.9.self_attn.v_proj.module...\n",
            "2024-04-09 20:46:26 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.05\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.05\n",
            "2024-04-09 20:46:26 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 70.15\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 70.15\n",
            "2024-04-09 20:46:26 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.9.model.layers.9.self_attn.o_proj.module...\n",
            "2024-04-09 20:46:28 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:46:28 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 14.99\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 14.99\n",
            "2024-04-09 20:46:28 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.9.model.layers.9.mlp.gate_proj.module...\n",
            "2024-04-09 20:46:29 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:46:29 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3299.90\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3299.90\n",
            "2024-04-09 20:46:29 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.9.model.layers.9.mlp.up_proj.module...\n",
            "2024-04-09 20:46:30 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.10\n",
            "2024-04-09 20:46:30 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2326.58\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2326.58\n",
            "2024-04-09 20:46:30 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.9.model.layers.9.mlp.down_proj.module...\n",
            "2024-04-09 20:46:33 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 3.00\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 3.00\n",
            "2024-04-09 20:46:33 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 37.50\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 37.50\n",
            "2024-04-09 20:46:33 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 11/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 11/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:46:33 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.10.model.layers.10.self_attn.q_proj.module...\n",
            "2024-04-09 20:46:34 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:46:34 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2584.03\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2584.03\n",
            "2024-04-09 20:46:34 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.10.model.layers.10.self_attn.k_proj.module...\n",
            "2024-04-09 20:46:35 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.10\n",
            "2024-04-09 20:46:35 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1093.52\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1093.52\n",
            "2024-04-09 20:46:35 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.10.model.layers.10.self_attn.v_proj.module...\n",
            "2024-04-09 20:46:36 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:46:36 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 81.85\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 81.85\n",
            "2024-04-09 20:46:36 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.10.model.layers.10.self_attn.o_proj.module...\n",
            "2024-04-09 20:46:37 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.05\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.05\n",
            "2024-04-09 20:46:37 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 14.57\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 14.57\n",
            "2024-04-09 20:46:37 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.10.model.layers.10.mlp.gate_proj.module...\n",
            "2024-04-09 20:46:38 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:46:38 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3503.46\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3503.46\n",
            "2024-04-09 20:46:38 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.10.model.layers.10.mlp.up_proj.module...\n",
            "2024-04-09 20:46:39 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:46:39 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2633.11\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2633.11\n",
            "2024-04-09 20:46:39 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.10.model.layers.10.mlp.down_proj.module...\n",
            "2024-04-09 20:46:42 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 3.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 3.06\n",
            "2024-04-09 20:46:42 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 40.38\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 40.38\n",
            "2024-04-09 20:46:42 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 12/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 12/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:46:42 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.11.model.layers.11.self_attn.q_proj.module...\n",
            "2024-04-09 20:46:44 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.09\n",
            "2024-04-09 20:46:44 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2956.71\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2956.71\n",
            "2024-04-09 20:46:44 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.11.model.layers.11.self_attn.k_proj.module...\n",
            "2024-04-09 20:46:45 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.02\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.02\n",
            "2024-04-09 20:46:45 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1186.21\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1186.21\n",
            "2024-04-09 20:46:45 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.11.model.layers.11.self_attn.v_proj.module...\n",
            "2024-04-09 20:46:46 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:46:46 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 101.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 101.09\n",
            "2024-04-09 20:46:46 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.11.model.layers.11.self_attn.o_proj.module...\n",
            "2024-04-09 20:46:47 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:46:47 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 21.31\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 21.31\n",
            "2024-04-09 20:46:47 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.11.model.layers.11.mlp.gate_proj.module...\n",
            "2024-04-09 20:46:48 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:46:48 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 4046.32\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 4046.32\n",
            "2024-04-09 20:46:48 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.11.model.layers.11.mlp.up_proj.module...\n",
            "2024-04-09 20:46:49 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.14\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.14\n",
            "2024-04-09 20:46:49 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3034.11\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3034.11\n",
            "2024-04-09 20:46:49 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.11.model.layers.11.mlp.down_proj.module...\n",
            "2024-04-09 20:46:52 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 3.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 3.04\n",
            "2024-04-09 20:46:52 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 49.37\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 49.37\n",
            "2024-04-09 20:46:52 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 13/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 13/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:46:52 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.12.model.layers.12.self_attn.q_proj.module...\n",
            "2024-04-09 20:46:53 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:46:53 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2867.97\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2867.97\n",
            "2024-04-09 20:46:53 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.12.model.layers.12.self_attn.k_proj.module...\n",
            "2024-04-09 20:46:54 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.01\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.01\n",
            "2024-04-09 20:46:54 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1122.19\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1122.19\n",
            "2024-04-09 20:46:54 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.12.model.layers.12.self_attn.v_proj.module...\n",
            "2024-04-09 20:46:55 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:46:55 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 128.53\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 128.53\n",
            "2024-04-09 20:46:55 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.12.model.layers.12.self_attn.o_proj.module...\n",
            "2024-04-09 20:46:56 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:46:56 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 32.50\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 32.50\n",
            "2024-04-09 20:46:56 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.12.model.layers.12.mlp.gate_proj.module...\n",
            "2024-04-09 20:46:57 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.13\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.13\n",
            "2024-04-09 20:46:57 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 4638.96\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 4638.96\n",
            "2024-04-09 20:46:57 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.12.model.layers.12.mlp.up_proj.module...\n",
            "2024-04-09 20:46:58 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.07\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.07\n",
            "2024-04-09 20:46:58 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3277.83\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3277.83\n",
            "2024-04-09 20:46:58 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.12.model.layers.12.mlp.down_proj.module...\n",
            "2024-04-09 20:47:01 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.95\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.95\n",
            "2024-04-09 20:47:01 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 64.45\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 64.45\n",
            "2024-04-09 20:47:01 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 14/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 14/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:47:01 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.13.model.layers.13.self_attn.q_proj.module...\n",
            "2024-04-09 20:47:03 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.07\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.07\n",
            "2024-04-09 20:47:03 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3317.42\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3317.42\n",
            "2024-04-09 20:47:03 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.13.model.layers.13.self_attn.k_proj.module...\n",
            "2024-04-09 20:47:04 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 0.97\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 0.97\n",
            "2024-04-09 20:47:04 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1345.70\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1345.70\n",
            "2024-04-09 20:47:04 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.13.model.layers.13.self_attn.v_proj.module...\n",
            "2024-04-09 20:47:05 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.09\n",
            "2024-04-09 20:47:05 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 115.58\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 115.58\n",
            "2024-04-09 20:47:05 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.13.model.layers.13.self_attn.o_proj.module...\n",
            "2024-04-09 20:47:06 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.14\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.14\n",
            "2024-04-09 20:47:06 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 33.97\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 33.97\n",
            "2024-04-09 20:47:06 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.13.model.layers.13.mlp.gate_proj.module...\n",
            "2024-04-09 20:47:07 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.16\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.16\n",
            "2024-04-09 20:47:07 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 4965.90\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 4965.90\n",
            "2024-04-09 20:47:07 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.13.model.layers.13.mlp.up_proj.module...\n",
            "2024-04-09 20:47:08 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.09\n",
            "2024-04-09 20:47:08 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3606.21\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3606.21\n",
            "2024-04-09 20:47:08 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.13.model.layers.13.mlp.down_proj.module...\n",
            "2024-04-09 20:47:11 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.91\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.91\n",
            "2024-04-09 20:47:11 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 77.22\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 77.22\n",
            "2024-04-09 20:47:11 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 15/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 15/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:47:11 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.14.model.layers.14.self_attn.q_proj.module...\n",
            "2024-04-09 20:47:12 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:47:12 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 2822.23\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 2822.23\n",
            "2024-04-09 20:47:12 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.14.model.layers.14.self_attn.k_proj.module...\n",
            "2024-04-09 20:47:13 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 0.99\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 0.99\n",
            "2024-04-09 20:47:13 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1189.49\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1189.49\n",
            "2024-04-09 20:47:13 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.14.model.layers.14.self_attn.v_proj.module...\n",
            "2024-04-09 20:47:14 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:47:14 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 119.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 119.10\n",
            "2024-04-09 20:47:14 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.14.model.layers.14.self_attn.o_proj.module...\n",
            "2024-04-09 20:47:15 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:47:15 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 53.83\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 53.83\n",
            "2024-04-09 20:47:15 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.14.model.layers.14.mlp.gate_proj.module...\n",
            "2024-04-09 20:47:16 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.09\n",
            "2024-04-09 20:47:16 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 5233.68\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 5233.68\n",
            "2024-04-09 20:47:16 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.14.model.layers.14.mlp.up_proj.module...\n",
            "2024-04-09 20:47:17 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.12\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.12\n",
            "2024-04-09 20:47:17 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3964.18\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3964.18\n",
            "2024-04-09 20:47:17 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.14.model.layers.14.mlp.down_proj.module...\n",
            "2024-04-09 20:47:20 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.87\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.87\n",
            "2024-04-09 20:47:20 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 93.60\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 93.60\n",
            "2024-04-09 20:47:20 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 16/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 16/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:47:20 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.15.model.layers.15.self_attn.q_proj.module...\n",
            "2024-04-09 20:47:21 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.05\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.05\n",
            "2024-04-09 20:47:21 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3261.41\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3261.41\n",
            "2024-04-09 20:47:21 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.15.model.layers.15.self_attn.k_proj.module...\n",
            "2024-04-09 20:47:22 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.01\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.01\n",
            "2024-04-09 20:47:22 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1191.31\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1191.31\n",
            "2024-04-09 20:47:22 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.15.model.layers.15.self_attn.v_proj.module...\n",
            "2024-04-09 20:47:23 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.05\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.05\n",
            "2024-04-09 20:47:23 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 147.60\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 147.60\n",
            "2024-04-09 20:47:23 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.15.model.layers.15.self_attn.o_proj.module...\n",
            "2024-04-09 20:47:25 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.09\n",
            "2024-04-09 20:47:25 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 64.84\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 64.84\n",
            "2024-04-09 20:47:25 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.15.model.layers.15.mlp.gate_proj.module...\n",
            "2024-04-09 20:47:26 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.14\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.14\n",
            "2024-04-09 20:47:26 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 5997.93\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 5997.93\n",
            "2024-04-09 20:47:26 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.15.model.layers.15.mlp.up_proj.module...\n",
            "2024-04-09 20:47:27 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.14\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.14\n",
            "2024-04-09 20:47:27 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 4654.57\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 4654.57\n",
            "2024-04-09 20:47:27 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.15.model.layers.15.mlp.down_proj.module...\n",
            "2024-04-09 20:47:30 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 3.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 3.08\n",
            "2024-04-09 20:47:30 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 142.53\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 142.53\n",
            "2024-04-09 20:47:30 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 17/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 17/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:47:30 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.16.model.layers.16.self_attn.q_proj.module...\n",
            "2024-04-09 20:47:31 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.07\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.07\n",
            "2024-04-09 20:47:31 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3604.72\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3604.72\n",
            "2024-04-09 20:47:31 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.16.model.layers.16.self_attn.k_proj.module...\n",
            "2024-04-09 20:47:32 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.05\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.05\n",
            "2024-04-09 20:47:32 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1380.22\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1380.22\n",
            "2024-04-09 20:47:32 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.16.model.layers.16.self_attn.v_proj.module...\n",
            "2024-04-09 20:47:33 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.10\n",
            "2024-04-09 20:47:33 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 190.93\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 190.93\n",
            "2024-04-09 20:47:33 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.16.model.layers.16.self_attn.o_proj.module...\n",
            "2024-04-09 20:47:34 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.18\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.18\n",
            "2024-04-09 20:47:34 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 75.53\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 75.53\n",
            "2024-04-09 20:47:34 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.16.model.layers.16.mlp.gate_proj.module...\n",
            "2024-04-09 20:47:36 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.16\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.16\n",
            "2024-04-09 20:47:36 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 7951.11\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 7951.11\n",
            "2024-04-09 20:47:36 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.16.model.layers.16.mlp.up_proj.module...\n",
            "2024-04-09 20:47:37 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.11\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.11\n",
            "2024-04-09 20:47:37 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 5859.41\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 5859.41\n",
            "2024-04-09 20:47:37 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.16.model.layers.16.mlp.down_proj.module...\n",
            "2024-04-09 20:47:40 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.95\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.95\n",
            "2024-04-09 20:47:40 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 235.21\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 235.21\n",
            "2024-04-09 20:47:40 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 18/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 18/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:47:40 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.17.model.layers.17.self_attn.q_proj.module...\n",
            "2024-04-09 20:47:41 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.13\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.13\n",
            "2024-04-09 20:47:41 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3446.65\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3446.65\n",
            "2024-04-09 20:47:41 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.17.model.layers.17.self_attn.k_proj.module...\n",
            "2024-04-09 20:47:42 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:47:42 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1294.36\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1294.36\n",
            "2024-04-09 20:47:42 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.17.model.layers.17.self_attn.v_proj.module...\n",
            "2024-04-09 20:47:43 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.03\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.03\n",
            "2024-04-09 20:47:43 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 313.69\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 313.69\n",
            "2024-04-09 20:47:43 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.17.model.layers.17.self_attn.o_proj.module...\n",
            "2024-04-09 20:47:44 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.05\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.05\n",
            "2024-04-09 20:47:44 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 107.85\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 107.85\n",
            "2024-04-09 20:47:44 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.17.model.layers.17.mlp.gate_proj.module...\n",
            "2024-04-09 20:47:45 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:47:45 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 9555.27\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 9555.27\n",
            "2024-04-09 20:47:45 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.17.model.layers.17.mlp.up_proj.module...\n",
            "2024-04-09 20:47:46 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:47:46 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 7125.96\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 7125.96\n",
            "2024-04-09 20:47:46 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.17.model.layers.17.mlp.down_proj.module...\n",
            "2024-04-09 20:47:49 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.86\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.86\n",
            "2024-04-09 20:47:49 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 277.63\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 277.63\n",
            "2024-04-09 20:47:49 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 19/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 19/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:47:49 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.18.model.layers.18.self_attn.q_proj.module...\n",
            "2024-04-09 20:47:50 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:47:50 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3906.97\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3906.97\n",
            "2024-04-09 20:47:50 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.18.model.layers.18.self_attn.k_proj.module...\n",
            "2024-04-09 20:47:51 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.00\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.00\n",
            "2024-04-09 20:47:51 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1318.30\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1318.30\n",
            "2024-04-09 20:47:51 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.18.model.layers.18.self_attn.v_proj.module...\n",
            "2024-04-09 20:47:52 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.05\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.05\n",
            "2024-04-09 20:47:52 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 350.72\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 350.72\n",
            "2024-04-09 20:47:52 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.18.model.layers.18.self_attn.o_proj.module...\n",
            "2024-04-09 20:47:53 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.05\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.05\n",
            "2024-04-09 20:47:53 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 180.94\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 180.94\n",
            "2024-04-09 20:47:53 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.18.model.layers.18.mlp.gate_proj.module...\n",
            "2024-04-09 20:47:54 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.10\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.10\n",
            "2024-04-09 20:47:54 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 11848.42\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 11848.42\n",
            "2024-04-09 20:47:54 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.18.model.layers.18.mlp.up_proj.module...\n",
            "2024-04-09 20:47:55 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.07\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.07\n",
            "2024-04-09 20:47:55 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 9062.95\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 9062.95\n",
            "2024-04-09 20:47:55 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.18.model.layers.18.mlp.down_proj.module...\n",
            "2024-04-09 20:47:58 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.84\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.84\n",
            "2024-04-09 20:47:58 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 455.24\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 455.24\n",
            "2024-04-09 20:47:58 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 20/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 20/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:47:58 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.19.model.layers.19.self_attn.q_proj.module...\n",
            "2024-04-09 20:47:59 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.03\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.03\n",
            "2024-04-09 20:47:59 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 3656.74\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 3656.74\n",
            "2024-04-09 20:47:59 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.19.model.layers.19.self_attn.k_proj.module...\n",
            "2024-04-09 20:48:00 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 0.95\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 0.95\n",
            "2024-04-09 20:48:00 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1258.27\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1258.27\n",
            "2024-04-09 20:48:00 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.19.model.layers.19.self_attn.v_proj.module...\n",
            "2024-04-09 20:48:01 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.03\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.03\n",
            "2024-04-09 20:48:01 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 464.64\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 464.64\n",
            "2024-04-09 20:48:01 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.19.model.layers.19.self_attn.o_proj.module...\n",
            "2024-04-09 20:48:02 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.07\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.07\n",
            "2024-04-09 20:48:02 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 156.70\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 156.70\n",
            "2024-04-09 20:48:02 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.19.model.layers.19.mlp.gate_proj.module...\n",
            "2024-04-09 20:48:03 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.09\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.09\n",
            "2024-04-09 20:48:03 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 13781.76\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 13781.76\n",
            "2024-04-09 20:48:03 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.19.model.layers.19.mlp.up_proj.module...\n",
            "2024-04-09 20:48:05 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:48:05 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 10891.39\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 10891.39\n",
            "2024-04-09 20:48:05 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.19.model.layers.19.mlp.down_proj.module...\n",
            "2024-04-09 20:48:07 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.93\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.93\n",
            "2024-04-09 20:48:07 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 672.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 672.08\n",
            "2024-04-09 20:48:08 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 21/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 21/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:48:08 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.20.model.layers.20.self_attn.q_proj.module...\n",
            "2024-04-09 20:48:09 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:48:09 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 4000.87\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 4000.87\n",
            "2024-04-09 20:48:09 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.20.model.layers.20.self_attn.k_proj.module...\n",
            "2024-04-09 20:48:10 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.02\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.02\n",
            "2024-04-09 20:48:10 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1418.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1418.04\n",
            "2024-04-09 20:48:10 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.20.model.layers.20.self_attn.v_proj.module...\n",
            "2024-04-09 20:48:11 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.02\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.02\n",
            "2024-04-09 20:48:11 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 550.66\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 550.66\n",
            "2024-04-09 20:48:11 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.20.model.layers.20.self_attn.o_proj.module...\n",
            "2024-04-09 20:48:12 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:48:12 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 207.11\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 207.11\n",
            "2024-04-09 20:48:12 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.20.model.layers.20.mlp.gate_proj.module...\n",
            "2024-04-09 20:48:13 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:48:13 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 15478.79\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 15478.79\n",
            "2024-04-09 20:48:13 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.20.model.layers.20.mlp.up_proj.module...\n",
            "2024-04-09 20:48:14 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.11\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.11\n",
            "2024-04-09 20:48:14 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 12635.82\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 12635.82\n",
            "2024-04-09 20:48:14 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.20.model.layers.20.mlp.down_proj.module...\n",
            "2024-04-09 20:48:17 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.88\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.88\n",
            "2024-04-09 20:48:17 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 956.11\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 956.11\n",
            "2024-04-09 20:48:17 sparseml.modifiers.pruning.wanda.pytorch INFO     \n",
            "===== Compressing layer 22/22 to sparsity 0.5 =====\n",
            "INFO:sparseml.modifiers.pruning.wanda.pytorch:\n",
            "===== Compressing layer 22/22 to sparsity 0.5 =====\n",
            "2024-04-09 20:48:17 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.self_attn.q_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.21.model.layers.21.self_attn.q_proj.module...\n",
            "2024-04-09 20:48:18 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.04\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.04\n",
            "2024-04-09 20:48:18 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 4283.14\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 4283.14\n",
            "2024-04-09 20:48:18 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.self_attn.k_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.21.model.layers.21.self_attn.k_proj.module...\n",
            "2024-04-09 20:48:19 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 0.98\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 0.98\n",
            "2024-04-09 20:48:19 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1609.88\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1609.88\n",
            "2024-04-09 20:48:19 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.self_attn.v_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.21.model.layers.21.self_attn.v_proj.module...\n",
            "2024-04-09 20:48:20 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.02\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.02\n",
            "2024-04-09 20:48:20 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 785.82\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 785.82\n",
            "2024-04-09 20:48:20 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.self_attn.o_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.21.model.layers.21.self_attn.o_proj.module...\n",
            "2024-04-09 20:48:21 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:48:21 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 390.66\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 390.66\n",
            "2024-04-09 20:48:21 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.mlp.gate_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.21.model.layers.21.mlp.gate_proj.module...\n",
            "2024-04-09 20:48:22 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.08\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.08\n",
            "2024-04-09 20:48:22 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 17553.47\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 17553.47\n",
            "2024-04-09 20:48:22 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.mlp.up_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.21.model.layers.21.mlp.up_proj.module...\n",
            "2024-04-09 20:48:23 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 1.06\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 1.06\n",
            "2024-04-09 20:48:23 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 12143.47\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 12143.47\n",
            "2024-04-09 20:48:23 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.mlp.down_proj.module...\n",
            "INFO:sparseml.modifiers.utils.layer_compressor:Compressing model.layers.21.model.layers.21.mlp.down_proj.module...\n",
            "2024-04-09 20:48:26 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     time 2.92\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:time 2.92\n",
            "2024-04-09 20:48:26 sparseml.modifiers.obcq.utils.sgpt_wrapper INFO     error 1333.87\n",
            "INFO:sparseml.modifiers.obcq.utils.sgpt_wrapper:error 1333.87\n",
            "manager stage: Modifiers initialized\n",
            "2024-04-09 20:48:26 sparseml.modifiers.quantization.pytorch INFO     Running QuantizationModifier calibration with 512 samples...\n",
            "INFO:sparseml.modifiers.quantization.pytorch:Running QuantizationModifier calibration with 512 samples...\n",
            "100%|██████████| 512/512 [04:42<00:00,  1.81it/s]\n",
            "manager stage: Modifiers finalized\n",
            "2024-04-09 20:53:27 sparseml.pytorch.model_load.helpers INFO     Saving output to /content/one-shot-example/stage_compression/stage_compression\n",
            "INFO:sparseml.pytorch.model_load.helpers:Saving output to /content/one-shot-example/stage_compression/stage_compression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the above code, the model is pruned to 50% sparsity and quantized, resulting in a smaller model ready for efficient inference."
      ],
      "metadata": {
        "id": "SLwO5pCPh977"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference\n",
        "\n",
        "To test the model's generation capabilities, we can use the following code to generate text utilizing PyTorch:\n"
      ],
      "metadata": {
        "id": "EhuO9Q5HiZ3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparseml.transformers import SparseAutoModelForCausalLM, SparseAutoTokenizer\n",
        "from sparseml.core.utils import session_context_manager\n",
        "\n",
        "model_path = \"./one-shot-example/stage_compression\"\n",
        "\n",
        "with session_context_manager():\n",
        "  model = SparseAutoModelForCausalLM.from_pretrained(model_path, device_map=\"cuda:0\")\n",
        "tokenizer = SparseAutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "chat = [\n",
        "    {\"role\": \"user\", \"content\": \"Tell me about large language models\"}\n",
        "]\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(chat, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
        "generated_ids = model.generate(inputs)\n",
        "outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqmcKrkgjWRl",
        "outputId": "50c20f7f-8623-4bbc-bafa-2edff58d718c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-04-09 21:04:58 sparseml.transformers.utils.helpers INFO     Found recipe in the model_path: ./one-shot-example/stage_compression/recipe.yaml\n",
            "INFO:sparseml.transformers.utils.helpers:Found recipe in the model_path: ./one-shot-example/stage_compression/recipe.yaml\n",
            "2024-04-09 21:04:58 sparseml.core.recipe.recipe INFO     Loading recipe from file ./one-shot-example/stage_compression/recipe.yaml\n",
            "INFO:sparseml.core.recipe.recipe:Loading recipe from file ./one-shot-example/stage_compression/recipe.yaml\n",
            "manager stage: Model structure initialized\n",
            "2024-04-09 21:04:58 sparseml.pytorch.model_load.helpers INFO     Applied an unstaged recipe to the model at ./one-shot-example/stage_compression\n",
            "INFO:sparseml.pytorch.model_load.helpers:Applied an unstaged recipe to the model at ./one-shot-example/stage_compression\n",
            "2024-04-09 21:05:03 sparseml.pytorch.model_load.helpers INFO     Reloaded 3302 model params for SparseML Recipe from ./one-shot-example/stage_compression\n",
            "INFO:sparseml.pytorch.model_load.helpers:Reloaded 3302 model params for SparseML Recipe from ./one-shot-example/stage_compression\n",
            "2024-04-09 21:05:03 sparseml.pytorch.model_load.helpers INFO     Loaded student from ./one-shot-example/stage_compression with 1100048384 total params. Of those there are 1034420224 prunable params which have 47.24113253609396 avg sparsity.\n",
            "INFO:sparseml.pytorch.model_load.helpers:Loaded student from ./one-shot-example/stage_compression with 1100048384 total params. Of those there are 1034420224 prunable params which have 47.24113253609396 avg sparsity.\n",
            "2024-04-09 21:05:04 sparseml.pytorch.model_load.helpers INFO     sparse model detected, all sparsification info: {\"params_summary\": {\"total\": 1100048384, \"sparse\": 488671829, \"sparsity_percent\": 44.422757772079954, \"prunable\": 1034420224, \"prunable_sparse\": 488671829, \"prunable_sparsity_percent\": 47.24113253609396, \"quantizable\": 1034420224, \"quantized\": 1034420224, \"quantized_percent\": 100.0}, \"params_info\": {\"model.layers.0.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5002398490905762, \"quantized\": true}, \"model.layers.0.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5008468627929688, \"quantized\": true}, \"model.layers.0.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500396728515625, \"quantized\": true}, \"model.layers.0.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000495910644531, \"quantized\": true}, \"model.layers.0.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.0.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500002384185791, \"quantized\": true}, \"model.layers.0.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.1.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000109672546387, \"quantized\": true}, \"model.layers.1.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000400543212891, \"quantized\": true}, \"model.layers.1.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.50018310546875, \"quantized\": true}, \"model.layers.1.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.50002121925354, \"quantized\": true}, \"model.layers.1.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.1.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.1.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.2.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.2.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.2.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.2.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000174045562744, \"quantized\": true}, \"model.layers.2.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000014305114746, \"quantized\": true}, \"model.layers.2.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.2.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.8660634160041809, \"quantized\": true}, \"model.layers.3.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.3.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.3.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.3.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000369548797607, \"quantized\": true}, \"model.layers.3.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.3.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.3.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.4.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.4.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.4.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.4.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000314712524414, \"quantized\": true}, \"model.layers.4.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.4.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.4.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039339065552, \"quantized\": true}, \"model.layers.5.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.5.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000178813934326, \"quantized\": true}, \"model.layers.5.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.5.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.5.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041127204895, \"quantized\": true}, \"model.layers.6.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.6.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.6.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500002384185791, \"quantized\": true}, \"model.layers.6.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022053718567, \"quantized\": true}, \"model.layers.6.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039339065552, \"quantized\": true}, \"model.layers.7.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.7.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000126361846924, \"quantized\": true}, \"model.layers.7.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.7.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.7.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000267028808594, \"quantized\": true}, \"model.layers.8.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.8.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.8.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.8.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.8.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.9.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500004768371582, \"quantized\": true}, \"model.layers.9.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.9.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.9.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000216960906982, \"quantized\": true}, \"model.layers.9.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022053718567, \"quantized\": true}, \"model.layers.9.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.9.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.10.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000061988830566, \"quantized\": true}, \"model.layers.10.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000219345092773, \"quantized\": true}, \"model.layers.10.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500003457069397, \"quantized\": true}, \"model.layers.10.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500002384185791, \"quantized\": true}, \"model.layers.10.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039339065552, \"quantized\": true}, \"model.layers.11.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000050067901611, \"quantized\": true}, \"model.layers.11.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000154972076416, \"quantized\": true}, \"model.layers.11.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.11.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.11.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.12.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.12.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000121593475342, \"quantized\": true}, \"model.layers.12.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.12.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022053718567, \"quantized\": true}, \"model.layers.12.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.13.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.13.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.13.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.13.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022649765015, \"quantized\": true}, \"model.layers.13.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.14.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000052452087402, \"quantized\": true}, \"model.layers.14.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000271797180176, \"quantized\": true}, \"model.layers.14.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.14.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.14.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.15.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.15.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000295639038086, \"quantized\": true}, \"model.layers.15.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.15.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.15.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.16.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.16.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000169277191162, \"quantized\": true}, \"model.layers.16.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.16.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020265579224, \"quantized\": true}, \"model.layers.16.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.17.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.17.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000176429748535, \"quantized\": true}, \"model.layers.17.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022053718567, \"quantized\": true}, \"model.layers.17.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000031590461731, \"quantized\": true}, \"model.layers.17.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041127204895, \"quantized\": true}, \"model.layers.18.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.18.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.18.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500002384185791, \"quantized\": true}, \"model.layers.18.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.18.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.19.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.19.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000143051147461, \"quantized\": true}, \"model.layers.19.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500002384185791, \"quantized\": true}, \"model.layers.19.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.19.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.20.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.20.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.20.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.20.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500011682510376, \"quantized\": true}, \"model.layers.20.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.20.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.20.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.21.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.21.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.21.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.21.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000615119934082, \"quantized\": true}, \"model.layers.21.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022053718567, \"quantized\": true}, \"model.layers.21.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020265579224, \"quantized\": true}, \"model.layers.21.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"lm_head.module.weight\": {\"numel\": 65536000, \"sparsity\": 0.0, \"quantized\": true}}}\n",
            "INFO:sparseml.pytorch.model_load.helpers:sparse model detected, all sparsification info: {\"params_summary\": {\"total\": 1100048384, \"sparse\": 488671829, \"sparsity_percent\": 44.422757772079954, \"prunable\": 1034420224, \"prunable_sparse\": 488671829, \"prunable_sparsity_percent\": 47.24113253609396, \"quantizable\": 1034420224, \"quantized\": 1034420224, \"quantized_percent\": 100.0}, \"params_info\": {\"model.layers.0.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5002398490905762, \"quantized\": true}, \"model.layers.0.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5008468627929688, \"quantized\": true}, \"model.layers.0.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500396728515625, \"quantized\": true}, \"model.layers.0.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000495910644531, \"quantized\": true}, \"model.layers.0.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.0.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500002384185791, \"quantized\": true}, \"model.layers.0.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.1.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000109672546387, \"quantized\": true}, \"model.layers.1.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000400543212891, \"quantized\": true}, \"model.layers.1.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.50018310546875, \"quantized\": true}, \"model.layers.1.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.50002121925354, \"quantized\": true}, \"model.layers.1.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.1.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.1.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.2.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.2.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.2.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.2.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000174045562744, \"quantized\": true}, \"model.layers.2.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000014305114746, \"quantized\": true}, \"model.layers.2.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.2.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.8660634160041809, \"quantized\": true}, \"model.layers.3.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.3.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.3.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.3.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000369548797607, \"quantized\": true}, \"model.layers.3.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.3.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.3.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.4.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.4.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.4.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.4.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000314712524414, \"quantized\": true}, \"model.layers.4.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.4.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.4.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039339065552, \"quantized\": true}, \"model.layers.5.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.5.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000178813934326, \"quantized\": true}, \"model.layers.5.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.5.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.5.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041127204895, \"quantized\": true}, \"model.layers.6.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.6.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.6.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500002384185791, \"quantized\": true}, \"model.layers.6.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022053718567, \"quantized\": true}, \"model.layers.6.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039339065552, \"quantized\": true}, \"model.layers.7.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.7.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000126361846924, \"quantized\": true}, \"model.layers.7.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.7.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.7.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000267028808594, \"quantized\": true}, \"model.layers.8.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.8.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.8.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.8.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.8.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.9.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500004768371582, \"quantized\": true}, \"model.layers.9.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.9.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.9.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000216960906982, \"quantized\": true}, \"model.layers.9.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022053718567, \"quantized\": true}, \"model.layers.9.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.9.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.10.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000061988830566, \"quantized\": true}, \"model.layers.10.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000219345092773, \"quantized\": true}, \"model.layers.10.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500003457069397, \"quantized\": true}, \"model.layers.10.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500002384185791, \"quantized\": true}, \"model.layers.10.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039339065552, \"quantized\": true}, \"model.layers.11.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000050067901611, \"quantized\": true}, \"model.layers.11.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000154972076416, \"quantized\": true}, \"model.layers.11.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.11.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.11.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.12.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.12.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000121593475342, \"quantized\": true}, \"model.layers.12.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.12.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022053718567, \"quantized\": true}, \"model.layers.12.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.13.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.13.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.13.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.13.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022649765015, \"quantized\": true}, \"model.layers.13.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.14.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000052452087402, \"quantized\": true}, \"model.layers.14.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000271797180176, \"quantized\": true}, \"model.layers.14.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.14.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.14.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.15.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.15.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000295639038086, \"quantized\": true}, \"model.layers.15.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.15.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.15.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.16.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.16.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000169277191162, \"quantized\": true}, \"model.layers.16.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.16.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020265579224, \"quantized\": true}, \"model.layers.16.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.17.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.17.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000176429748535, \"quantized\": true}, \"model.layers.17.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022053718567, \"quantized\": true}, \"model.layers.17.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000031590461731, \"quantized\": true}, \"model.layers.17.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041127204895, \"quantized\": true}, \"model.layers.18.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.18.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.18.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500002384185791, \"quantized\": true}, \"model.layers.18.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.18.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.19.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.19.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000143051147461, \"quantized\": true}, \"model.layers.19.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500002384185791, \"quantized\": true}, \"model.layers.19.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.19.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.20.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.20.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.20.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.20.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500011682510376, \"quantized\": true}, \"model.layers.20.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.20.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.20.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.21.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.21.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.21.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.21.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000615119934082, \"quantized\": true}, \"model.layers.21.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022053718567, \"quantized\": true}, \"model.layers.21.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020265579224, \"quantized\": true}, \"model.layers.21.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"lm_head.module.weight\": {\"numel\": 65536000, \"sparsity\": 0.0, \"quantized\": true}}}\n",
            "2024-04-09 21:05:04 sparseml.pytorch.model_load.helpers INFO     Reloaded model state after SparseML recipe structure modifications from ./one-shot-example/stage_compression\n",
            "INFO:sparseml.pytorch.model_load.helpers:Reloaded model state after SparseML recipe structure modifications from ./one-shot-example/stage_compression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|user|>\\nTell me about large language models \\n<|assistant|>\\nLarge language models are computer programs that learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforcing learning. The goal of large language models is to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. These models can be trained on large corpora of text using various techniques such as supervised learning, unsupervised learning, and reinforing learning. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. Large language models are used in various ways to learn to recognize and generate large sets of words or phrases from a large corpus of text. Large language models are used in various ways to learn to recognize and generate large sets of']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating Accuracy\n",
        "\n",
        "Evaluating the model's accuracy is important to ensure it meets the desired performance requirements.\n",
        "To do so, we can use the following code to evaluate the model's perplexity on a sample dataset:"
      ],
      "metadata": {
        "id": "Fro9wJPznFZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparseml import evaluate\n",
        "\n",
        "eval = evaluate(\n",
        "    \"./one-shot-example/stage_compression\",\n",
        "    datasets=\"openai_humaneval\",\n",
        "    integration=\"perplexity\",\n",
        "    text_column_name=[\"prompt\", \"canonical_solution\"]\n",
        ")\n",
        "print(eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544,
          "referenced_widgets": [
            "3f9920e370e04da8a47874cd5899dc9c",
            "fa9cfab7cbf9469e98789961e725f30c",
            "04a557a9e21b46368e9d211ebfb626a0",
            "ff732003a9af43b2a8863b8fdbe87108",
            "ae66997262a3431db7fa6762ecc84621",
            "e4993e670b42432e885c7c9da59d0a5c",
            "7d6e5f99c58a4d0aaf39677afbdf8de7",
            "d0238ea41c4940b0adcdfdb601cfc32b",
            "c2f053ad2e384a1c97c49a855e38b34a",
            "76355ffa043347c3b943221a8568b159",
            "ab6bae775f7a4b898e7b0f387fd19334",
            "6a1098f07ccd4ee8a11952b5354a2e26",
            "a3a407ec7ebd41cb849e4698eaadb2fc",
            "e4df270ad2df44babd51e4f09a3c5eff",
            "0ea82ed228bc452c8c1794912f01e407",
            "5f6bc092dc334150ad8d33847387d105",
            "7dc9849214994df482649fd0e33c1a98",
            "61837b439b16479580349dd826032aaf",
            "676a8aacf7654e3e94e18dae1a3ae746",
            "8b5ace557181434daa24edd76a2ffa0d",
            "7bba53d4759b4f2fa4895e2a268b9387",
            "bf82aeefef2a4dffabaf10d436e6e0b4",
            "eb13eb0b01d64f52aaef8a947390d200",
            "59a1231e607f42fa8ec51beea31797fd",
            "a1923de7f96344cd88adfe7a05110968",
            "9fa778aa58b34f7eb13fdf99d2788c20",
            "354c34a58f814ca88a2b862af261e803",
            "ce5dfd3b818e44b3860898f186894d61",
            "46484784b40b42638f546caa894c749b",
            "8ea5316a2dd846fdaf92427175b53814",
            "be0a1eacefb045bfa12b07e018bee21b",
            "5965a00ce5ff4cad8a37d76d244f41ae",
            "7ffeb1bcc53c45ba82c32e5fdbee1dfe",
            "0f82d292aee447c3a7806a3791001813",
            "48ea77ae58464c3d8134b8dc60ee20c3",
            "2e27672190554069875566454e17c1a6",
            "4cce4b3045ce4cb588787d9ffa731edf",
            "d65c9d5f58a0437899d3d4ced13fdb2b",
            "7b0dadc7d70949fc93638d3af04e0445",
            "6ef935e931624cc79f736fd2003491df",
            "0d1077f61df4494892c4245312c69272",
            "9c6f5dc10e8645799983340cb534ce0e",
            "f36950b897eb429f8456fa9e917ca9d9",
            "583820280e5a4d249596e9ea80a48f72",
            "eea878f4085e44c79a9d95b6d07821ae",
            "4e8fbbc17c984ab1b2780ce608084e0a",
            "9c02ede9e574458fa29e437cb6dd3918",
            "7dbed2a12ab545269e8dfba97053ed1f",
            "d2c653a20eda407a82428e3d21193f1c",
            "bacc5eaf5a254a10b738b23f088b5797",
            "c1f5a43ec37843f0a879b8a2276f19fe",
            "159dc1815c6740e19a360539aed8b6a3",
            "4e37078b891845769ece3f3a95a3b585",
            "8ae887f1f93b4fa2aabdfd4dbb465e8a",
            "13e4b092956f400da022a37bf7741541"
          ]
        },
        "id": "gLf37y22h7Ga",
        "outputId": "dc7dedd9-61c0-455a-ebfe-871fbea26faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-09 21:13:19 sparseml.evaluation.registry INFO     Auto collected perplexity integration for eval\n",
            "INFO:sparseml.evaluation.registry:Auto collected perplexity integration for eval\n",
            "2024-04-09 21:13:30 sparseml.transformers.utils.helpers INFO     Found recipe in the model_path: ./one-shot-example/stage_compression/recipe.yaml\n",
            "INFO:sparseml.transformers.utils.helpers:Found recipe in the model_path: ./one-shot-example/stage_compression/recipe.yaml\n",
            "2024-04-09 21:13:30 sparseml.core.recipe.recipe INFO     Loading recipe from file ./one-shot-example/stage_compression/recipe.yaml\n",
            "INFO:sparseml.core.recipe.recipe:Loading recipe from file ./one-shot-example/stage_compression/recipe.yaml\n",
            "manager stage: Model structure initialized\n",
            "2024-04-09 21:13:30 sparseml.pytorch.model_load.helpers INFO     Applied an unstaged recipe to the model at ./one-shot-example/stage_compression\n",
            "INFO:sparseml.pytorch.model_load.helpers:Applied an unstaged recipe to the model at ./one-shot-example/stage_compression\n",
            "2024-04-09 21:13:35 sparseml.pytorch.model_load.helpers INFO     Reloaded 3302 model params for SparseML Recipe from ./one-shot-example/stage_compression\n",
            "INFO:sparseml.pytorch.model_load.helpers:Reloaded 3302 model params for SparseML Recipe from ./one-shot-example/stage_compression\n",
            "2024-04-09 21:13:37 sparseml.pytorch.model_load.helpers INFO     Loaded student from ./one-shot-example/stage_compression with 1100048384 total params. Of those there are 1034420224 prunable params which have 47.241131956058894 avg sparsity.\n",
            "INFO:sparseml.pytorch.model_load.helpers:Loaded student from ./one-shot-example/stage_compression with 1100048384 total params. Of those there are 1034420224 prunable params which have 47.241131956058894 avg sparsity.\n",
            "2024-04-09 21:13:50 sparseml.pytorch.model_load.helpers INFO     sparse model detected, all sparsification info: {\"params_summary\": {\"total\": 1100048384, \"sparse\": 488671823, \"sparsity_percent\": 44.42275722664941, \"prunable\": 1034420224, \"prunable_sparse\": 488671823, \"prunable_sparsity_percent\": 47.241131956058894, \"quantizable\": 1034420224, \"quantized\": 1034420224, \"quantized_percent\": 100.0}, \"params_info\": {\"model.layers.0.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5002398490905762, \"quantized\": true}, \"model.layers.0.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5008468627929688, \"quantized\": true}, \"model.layers.0.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500396728515625, \"quantized\": true}, \"model.layers.0.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000495910644531, \"quantized\": true}, \"model.layers.0.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.0.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.0.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.1.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000109672546387, \"quantized\": true}, \"model.layers.1.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000400543212891, \"quantized\": true}, \"model.layers.1.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.50018310546875, \"quantized\": true}, \"model.layers.1.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.50002121925354, \"quantized\": true}, \"model.layers.1.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.1.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.1.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.2.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.2.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.2.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.2.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000174045562744, \"quantized\": true}, \"model.layers.2.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000013709068298, \"quantized\": true}, \"model.layers.2.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.2.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.8660633563995361, \"quantized\": true}, \"model.layers.3.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.3.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.3.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.3.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000369548797607, \"quantized\": true}, \"model.layers.3.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.3.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.3.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.4.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.4.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.4.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.4.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000314712524414, \"quantized\": true}, \"model.layers.4.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.4.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.4.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.5.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.5.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000178813934326, \"quantized\": true}, \"model.layers.5.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.5.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.5.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000040531158447, \"quantized\": true}, \"model.layers.6.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.6.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.6.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.6.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.6.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.7.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.7.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000126361846924, \"quantized\": true}, \"model.layers.7.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.7.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.7.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000267028808594, \"quantized\": true}, \"model.layers.8.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.8.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.8.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.8.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.8.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.9.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500004768371582, \"quantized\": true}, \"model.layers.9.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.9.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.9.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000216960906982, \"quantized\": true}, \"model.layers.9.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.9.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.9.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.10.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000061988830566, \"quantized\": true}, \"model.layers.10.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000219345092773, \"quantized\": true}, \"model.layers.10.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500003457069397, \"quantized\": true}, \"model.layers.10.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.10.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.11.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000050067901611, \"quantized\": true}, \"model.layers.11.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000154972076416, \"quantized\": true}, \"model.layers.11.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.11.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.11.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.12.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.12.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000121593475342, \"quantized\": true}, \"model.layers.12.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.12.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.12.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.13.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.13.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.13.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.13.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022649765015, \"quantized\": true}, \"model.layers.13.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.14.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000052452087402, \"quantized\": true}, \"model.layers.14.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000271797180176, \"quantized\": true}, \"model.layers.14.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.14.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.14.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.15.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.15.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000295639038086, \"quantized\": true}, \"model.layers.15.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.15.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.15.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.16.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.16.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000169277191162, \"quantized\": true}, \"model.layers.16.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.16.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019669532776, \"quantized\": true}, \"model.layers.16.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.17.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.17.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000176429748535, \"quantized\": true}, \"model.layers.17.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.17.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000030994415283, \"quantized\": true}, \"model.layers.17.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000040531158447, \"quantized\": true}, \"model.layers.18.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.18.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.18.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.18.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.18.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.19.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.19.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000143051147461, \"quantized\": true}, \"model.layers.19.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.19.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.19.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500004231929779, \"quantized\": true}, \"model.layers.20.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.20.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.20.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.20.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500011682510376, \"quantized\": true}, \"model.layers.20.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.20.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.20.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.21.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.21.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.21.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.21.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000615119934082, \"quantized\": true}, \"model.layers.21.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.21.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019669532776, \"quantized\": true}, \"model.layers.21.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"lm_head.module.weight\": {\"numel\": 65536000, \"sparsity\": 0.0, \"quantized\": true}}}\n",
            "INFO:sparseml.pytorch.model_load.helpers:sparse model detected, all sparsification info: {\"params_summary\": {\"total\": 1100048384, \"sparse\": 488671823, \"sparsity_percent\": 44.42275722664941, \"prunable\": 1034420224, \"prunable_sparse\": 488671823, \"prunable_sparsity_percent\": 47.241131956058894, \"quantizable\": 1034420224, \"quantized\": 1034420224, \"quantized_percent\": 100.0}, \"params_info\": {\"model.layers.0.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5002398490905762, \"quantized\": true}, \"model.layers.0.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5008468627929688, \"quantized\": true}, \"model.layers.0.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500396728515625, \"quantized\": true}, \"model.layers.0.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000495910644531, \"quantized\": true}, \"model.layers.0.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.0.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.0.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.1.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000109672546387, \"quantized\": true}, \"model.layers.1.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000400543212891, \"quantized\": true}, \"model.layers.1.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.50018310546875, \"quantized\": true}, \"model.layers.1.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.50002121925354, \"quantized\": true}, \"model.layers.1.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.1.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.1.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.2.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.2.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.2.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.2.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000174045562744, \"quantized\": true}, \"model.layers.2.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000013709068298, \"quantized\": true}, \"model.layers.2.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.2.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.8660633563995361, \"quantized\": true}, \"model.layers.3.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.3.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.3.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.3.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000369548797607, \"quantized\": true}, \"model.layers.3.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.3.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.3.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.4.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.4.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.4.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.4.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000314712524414, \"quantized\": true}, \"model.layers.4.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.4.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.4.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.5.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.5.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000178813934326, \"quantized\": true}, \"model.layers.5.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.5.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.5.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000040531158447, \"quantized\": true}, \"model.layers.6.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.6.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.6.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.6.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.6.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.7.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.7.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000126361846924, \"quantized\": true}, \"model.layers.7.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.7.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.7.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000267028808594, \"quantized\": true}, \"model.layers.8.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.8.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.8.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.8.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.8.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.9.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500004768371582, \"quantized\": true}, \"model.layers.9.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.9.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.9.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000216960906982, \"quantized\": true}, \"model.layers.9.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.9.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.9.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.10.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000061988830566, \"quantized\": true}, \"model.layers.10.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000219345092773, \"quantized\": true}, \"model.layers.10.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500003457069397, \"quantized\": true}, \"model.layers.10.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.10.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.11.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000050067901611, \"quantized\": true}, \"model.layers.11.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000154972076416, \"quantized\": true}, \"model.layers.11.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.11.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.11.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.12.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.12.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000121593475342, \"quantized\": true}, \"model.layers.12.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.12.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.12.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.13.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.13.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.13.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.13.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022649765015, \"quantized\": true}, \"model.layers.13.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.14.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000052452087402, \"quantized\": true}, \"model.layers.14.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000271797180176, \"quantized\": true}, \"model.layers.14.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.14.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.14.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.15.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.15.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000295639038086, \"quantized\": true}, \"model.layers.15.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.15.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.15.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.16.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.16.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000169277191162, \"quantized\": true}, \"model.layers.16.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.16.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019669532776, \"quantized\": true}, \"model.layers.16.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.17.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.17.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000176429748535, \"quantized\": true}, \"model.layers.17.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.17.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000030994415283, \"quantized\": true}, \"model.layers.17.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000040531158447, \"quantized\": true}, \"model.layers.18.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.18.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.18.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.18.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.18.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.19.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.19.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000143051147461, \"quantized\": true}, \"model.layers.19.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.19.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.19.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500004231929779, \"quantized\": true}, \"model.layers.20.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.20.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.20.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.20.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500011682510376, \"quantized\": true}, \"model.layers.20.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.20.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.20.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.21.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.21.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.21.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.21.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000615119934082, \"quantized\": true}, \"model.layers.21.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.21.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019669532776, \"quantized\": true}, \"model.layers.21.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"lm_head.module.weight\": {\"numel\": 65536000, \"sparsity\": 0.0, \"quantized\": true}}}\n",
            "2024-04-09 21:13:50 sparseml.pytorch.model_load.helpers INFO     Reloaded model state after SparseML recipe structure modifications from ./one-shot-example/stage_compression\n",
            "INFO:sparseml.pytorch.model_load.helpers:Reloaded model state after SparseML recipe structure modifications from ./one-shot-example/stage_compression\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f9920e370e04da8a47874cd5899dc9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/6.52k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a1098f07ccd4ee8a11952b5354a2e26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb13eb0b01d64f52aaef8a947390d200",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/83.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f82d292aee447c3a7806a3791001813",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eea878f4085e44c79a9d95b6d07821ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/164 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[WARNING|tokenization_utils_base.py:791] 2024-04-09 21:13:52,892 >> Attempting to cast a BatchEncoding to type None. This is not supported.\n",
            "100%|██████████| 164/164 [32:02<00:00, 11.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatted=[Evaluation(task='text-generation', dataset=Dataset(type='text-generation', name='openai_humaneval', config=None, split=None), metrics=[Metric(name='perplexity', value=5.673565062080941)], samples=None)] raw={'mean_perplexity': 5.673565062080941}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code, however, does not leverage the sparsity within the model for efficient inference.\n",
        "To do so, we need to export the model to ONNX to be ready for efficient inference on CPUs with DeepSparse.\n",
        "SparseML provides a simple export command to do so:"
      ],
      "metadata": {
        "id": "K_CAJOIujalz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparseml import export\n",
        "\n",
        "export(\n",
        "    \"./one-shot-example/stage_compression\",\n",
        "    task=\"text-generation\",\n",
        "    sequence_length=1024,\n",
        "    target_path=\"./exported\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9je0mA83ja2Y",
        "outputId": "b42de136-6645-48cb-b2c4-aa10c25252f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-04-09 21:46:02 sparseml.export.export INFO     Starting export for transformers model...\n",
            "INFO:sparseml.export.export:Starting export for transformers model...\n",
            "2024-04-09 21:46:02 sparseml.export.export INFO     Creating model for the export...\n",
            "INFO:sparseml.export.export:Creating model for the export...\n",
            "2024-04-09 21:46:02 sparseml.transformers.integration_helper_functions WARNING  trust_remote_code is set to False. It is possible, that the model will not be loaded correctly.\n",
            "WARNING:sparseml.transformers.integration_helper_functions:trust_remote_code is set to False. It is possible, that the model will not be loaded correctly.\n",
            "2024-04-09 21:46:15 sparseml.transformers.utils.helpers INFO     Found recipe in the model_path: /content/one-shot-example/stage_compression/recipe.yaml\n",
            "INFO:sparseml.transformers.utils.helpers:Found recipe in the model_path: /content/one-shot-example/stage_compression/recipe.yaml\n",
            "2024-04-09 21:46:15 sparseml.core.recipe.recipe INFO     Loading recipe from file /content/one-shot-example/stage_compression/recipe.yaml\n",
            "INFO:sparseml.core.recipe.recipe:Loading recipe from file /content/one-shot-example/stage_compression/recipe.yaml\n",
            "manager stage: Model structure initialized\n",
            "2024-04-09 21:46:15 sparseml.pytorch.model_load.helpers INFO     Applied an unstaged recipe to the model at /content/one-shot-example/stage_compression\n",
            "INFO:sparseml.pytorch.model_load.helpers:Applied an unstaged recipe to the model at /content/one-shot-example/stage_compression\n",
            "2024-04-09 21:46:19 sparseml.pytorch.model_load.helpers INFO     Reloaded 3302 model params for SparseML Recipe from /content/one-shot-example/stage_compression\n",
            "INFO:sparseml.pytorch.model_load.helpers:Reloaded 3302 model params for SparseML Recipe from /content/one-shot-example/stage_compression\n",
            "2024-04-09 21:46:21 sparseml.pytorch.model_load.helpers INFO     Loaded student from /content/one-shot-example/stage_compression with 1100048384 total params. Of those there are 1034420224 prunable params which have 47.241131956058894 avg sparsity.\n",
            "INFO:sparseml.pytorch.model_load.helpers:Loaded student from /content/one-shot-example/stage_compression with 1100048384 total params. Of those there are 1034420224 prunable params which have 47.241131956058894 avg sparsity.\n",
            "2024-04-09 21:46:35 sparseml.pytorch.model_load.helpers INFO     sparse model detected, all sparsification info: {\"params_summary\": {\"total\": 1100048384, \"sparse\": 488671823, \"sparsity_percent\": 44.42275722664941, \"prunable\": 1034420224, \"prunable_sparse\": 488671823, \"prunable_sparsity_percent\": 47.241131956058894, \"quantizable\": 1034420224, \"quantized\": 1034420224, \"quantized_percent\": 100.0}, \"params_info\": {\"model.layers.0.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5002398490905762, \"quantized\": true}, \"model.layers.0.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5008468627929688, \"quantized\": true}, \"model.layers.0.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500396728515625, \"quantized\": true}, \"model.layers.0.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000495910644531, \"quantized\": true}, \"model.layers.0.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.0.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.0.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.1.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000109672546387, \"quantized\": true}, \"model.layers.1.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000400543212891, \"quantized\": true}, \"model.layers.1.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.50018310546875, \"quantized\": true}, \"model.layers.1.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.50002121925354, \"quantized\": true}, \"model.layers.1.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.1.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.1.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.2.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.2.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.2.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.2.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000174045562744, \"quantized\": true}, \"model.layers.2.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000013709068298, \"quantized\": true}, \"model.layers.2.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.2.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.8660633563995361, \"quantized\": true}, \"model.layers.3.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.3.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.3.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.3.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000369548797607, \"quantized\": true}, \"model.layers.3.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.3.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.3.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.4.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.4.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.4.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.4.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000314712524414, \"quantized\": true}, \"model.layers.4.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.4.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.4.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.5.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.5.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000178813934326, \"quantized\": true}, \"model.layers.5.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.5.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.5.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000040531158447, \"quantized\": true}, \"model.layers.6.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.6.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.6.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.6.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.6.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.7.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.7.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000126361846924, \"quantized\": true}, \"model.layers.7.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.7.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.7.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000267028808594, \"quantized\": true}, \"model.layers.8.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.8.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.8.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.8.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.8.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.9.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500004768371582, \"quantized\": true}, \"model.layers.9.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.9.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.9.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000216960906982, \"quantized\": true}, \"model.layers.9.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.9.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.9.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.10.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000061988830566, \"quantized\": true}, \"model.layers.10.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000219345092773, \"quantized\": true}, \"model.layers.10.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500003457069397, \"quantized\": true}, \"model.layers.10.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.10.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.11.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000050067901611, \"quantized\": true}, \"model.layers.11.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000154972076416, \"quantized\": true}, \"model.layers.11.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.11.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.11.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.12.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.12.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000121593475342, \"quantized\": true}, \"model.layers.12.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.12.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.12.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.13.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.13.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.13.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.13.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022649765015, \"quantized\": true}, \"model.layers.13.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.14.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000052452087402, \"quantized\": true}, \"model.layers.14.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000271797180176, \"quantized\": true}, \"model.layers.14.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.14.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.14.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.15.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.15.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000295639038086, \"quantized\": true}, \"model.layers.15.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.15.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.15.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.16.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.16.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000169277191162, \"quantized\": true}, \"model.layers.16.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.16.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019669532776, \"quantized\": true}, \"model.layers.16.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.17.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.17.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000176429748535, \"quantized\": true}, \"model.layers.17.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.17.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000030994415283, \"quantized\": true}, \"model.layers.17.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000040531158447, \"quantized\": true}, \"model.layers.18.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.18.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.18.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.18.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.18.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.19.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.19.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000143051147461, \"quantized\": true}, \"model.layers.19.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.19.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.19.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500004231929779, \"quantized\": true}, \"model.layers.20.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.20.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.20.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.20.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500011682510376, \"quantized\": true}, \"model.layers.20.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.20.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.20.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.21.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.21.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.21.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.21.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000615119934082, \"quantized\": true}, \"model.layers.21.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.21.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019669532776, \"quantized\": true}, \"model.layers.21.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"lm_head.module.weight\": {\"numel\": 65536000, \"sparsity\": 0.0, \"quantized\": true}}}\n",
            "INFO:sparseml.pytorch.model_load.helpers:sparse model detected, all sparsification info: {\"params_summary\": {\"total\": 1100048384, \"sparse\": 488671823, \"sparsity_percent\": 44.42275722664941, \"prunable\": 1034420224, \"prunable_sparse\": 488671823, \"prunable_sparsity_percent\": 47.241131956058894, \"quantizable\": 1034420224, \"quantized\": 1034420224, \"quantized_percent\": 100.0}, \"params_info\": {\"model.layers.0.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5002398490905762, \"quantized\": true}, \"model.layers.0.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5008468627929688, \"quantized\": true}, \"model.layers.0.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500396728515625, \"quantized\": true}, \"model.layers.0.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000495910644531, \"quantized\": true}, \"model.layers.0.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.0.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.0.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.1.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000109672546387, \"quantized\": true}, \"model.layers.1.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000400543212891, \"quantized\": true}, \"model.layers.1.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.50018310546875, \"quantized\": true}, \"model.layers.1.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.50002121925354, \"quantized\": true}, \"model.layers.1.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.1.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.1.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.2.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.2.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.2.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.2.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000174045562744, \"quantized\": true}, \"model.layers.2.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000013709068298, \"quantized\": true}, \"model.layers.2.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.2.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.8660633563995361, \"quantized\": true}, \"model.layers.3.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.3.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.3.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.3.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000369548797607, \"quantized\": true}, \"model.layers.3.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.3.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.3.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.4.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.4.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.4.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.4.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000314712524414, \"quantized\": true}, \"model.layers.4.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.4.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.4.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.5.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.5.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.5.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000178813934326, \"quantized\": true}, \"model.layers.5.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.5.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026226043701, \"quantized\": true}, \"model.layers.5.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000040531158447, \"quantized\": true}, \"model.layers.6.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.6.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.6.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.6.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.6.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.6.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.7.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.7.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.7.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000126361846924, \"quantized\": true}, \"model.layers.7.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.7.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.7.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000267028808594, \"quantized\": true}, \"model.layers.8.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.8.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.8.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.8.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.8.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.8.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.9.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500004768371582, \"quantized\": true}, \"model.layers.9.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.9.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000343322753906, \"quantized\": true}, \"model.layers.9.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000216960906982, \"quantized\": true}, \"model.layers.9.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.9.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.9.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000044107437134, \"quantized\": true}, \"model.layers.10.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000061988830566, \"quantized\": true}, \"model.layers.10.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.10.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000219345092773, \"quantized\": true}, \"model.layers.10.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500003457069397, \"quantized\": true}, \"model.layers.10.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.10.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038743019104, \"quantized\": true}, \"model.layers.11.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000050067901611, \"quantized\": true}, \"model.layers.11.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.11.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000154972076416, \"quantized\": true}, \"model.layers.11.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000016689300537, \"quantized\": true}, \"model.layers.11.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000017285346985, \"quantized\": true}, \"model.layers.11.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.12.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.12.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.12.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000121593475342, \"quantized\": true}, \"model.layers.12.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.12.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.12.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.13.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.13.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.13.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000250339508057, \"quantized\": true}, \"model.layers.13.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.13.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000022649765015, \"quantized\": true}, \"model.layers.13.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.14.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000052452087402, \"quantized\": true}, \"model.layers.14.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.14.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000271797180176, \"quantized\": true}, \"model.layers.14.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000025033950806, \"quantized\": true}, \"model.layers.14.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500001847743988, \"quantized\": true}, \"model.layers.14.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.15.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.15.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.15.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000295639038086, \"quantized\": true}, \"model.layers.15.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.15.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.15.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.16.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.16.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.16.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000169277191162, \"quantized\": true}, \"model.layers.16.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000024437904358, \"quantized\": true}, \"model.layers.16.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019669532776, \"quantized\": true}, \"model.layers.16.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000039935112, \"quantized\": true}, \"model.layers.17.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000045299530029, \"quantized\": true}, \"model.layers.17.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.17.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000176429748535, \"quantized\": true}, \"model.layers.17.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.17.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000030994415283, \"quantized\": true}, \"model.layers.17.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000040531158447, \"quantized\": true}, \"model.layers.18.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000059604644775, \"quantized\": true}, \"model.layers.18.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.18.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500006914138794, \"quantized\": true}, \"model.layers.18.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.18.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000020861625671, \"quantized\": true}, \"model.layers.18.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000038146972656, \"quantized\": true}, \"model.layers.19.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000057220458984, \"quantized\": true}, \"model.layers.19.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.19.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000143051147461, \"quantized\": true}, \"model.layers.19.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000023245811462, \"quantized\": true}, \"model.layers.19.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000032186508179, \"quantized\": true}, \"model.layers.19.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.500004231929779, \"quantized\": true}, \"model.layers.20.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000042915344238, \"quantized\": true}, \"model.layers.20.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.20.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.20.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.500011682510376, \"quantized\": true}, \"model.layers.20.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019073486328, \"quantized\": true}, \"model.layers.20.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000026822090149, \"quantized\": true}, \"model.layers.20.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"model.layers.21.self_attn.q_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000054836273193, \"quantized\": true}, \"model.layers.21.self_attn.k_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.5000324249267578, \"quantized\": true}, \"model.layers.21.self_attn.v_proj.module.weight\": {\"numel\": 524288, \"sparsity\": 0.500030517578125, \"quantized\": true}, \"model.layers.21.self_attn.o_proj.module.weight\": {\"numel\": 4194304, \"sparsity\": 0.5000615119934082, \"quantized\": true}, \"model.layers.21.mlp.gate_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000021457672119, \"quantized\": true}, \"model.layers.21.mlp.up_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000019669532776, \"quantized\": true}, \"model.layers.21.mlp.down_proj.module.weight\": {\"numel\": 11534336, \"sparsity\": 0.5000041723251343, \"quantized\": true}, \"lm_head.module.weight\": {\"numel\": 65536000, \"sparsity\": 0.0, \"quantized\": true}}}\n",
            "2024-04-09 21:46:35 sparseml.pytorch.model_load.helpers INFO     Reloaded model state after SparseML recipe structure modifications from /content/one-shot-example/stage_compression\n",
            "INFO:sparseml.pytorch.model_load.helpers:Reloaded model state after SparseML recipe structure modifications from /content/one-shot-example/stage_compression\n",
            "2024-04-09 21:46:35 sparseml.export.export INFO     Creating data loader for the export...\n",
            "INFO:sparseml.export.export:Creating data loader for the export...\n",
            "2024-04-09 21:46:35 sparseml.export.export INFO     Created additional items that will be used for the export: ['tokenizer', 'sequence_length', 'config', 'input_names']\n",
            "INFO:sparseml.export.export:Created additional items that will be used for the export: ['tokenizer', 'sequence_length', 'config', 'input_names']\n",
            "2024-04-09 21:46:35 sparseml.export.export INFO     Exporting model.onnx to ./exported...\n",
            "INFO:sparseml.export.export:Exporting model.onnx to ./exported...\n",
            "/usr/local/lib/python3.10/dist-packages/sparseml/modifiers/quantization/utils/fake_quant_wrapper.py:43: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.fake_quant_enabled[0] == 0:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:856: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if input_shape[-1] > 1:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:190: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if seq_len > self.max_seq_len_cached:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:423: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if attn_weights.size() != (bsz, self.num_heads, q_len, kv_seq_len):\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:430: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if attention_mask.size() != (bsz, 1, q_len, kv_seq_len):\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:440: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:49:25 sparseml.exporters.transforms.onnx_transform INFO     [FoldIdentityInitializers] Transformed 449 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[FoldIdentityInitializers] Transformed 449 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:49:30 sparseml.exporters.transforms.onnx_transform INFO     [FlattenQParams] Transformed 278 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[FlattenQParams] Transformed 278 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:49:34 sparseml.exporters.transforms.onnx_transform INFO     [UnwrapBatchNorms] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[UnwrapBatchNorms] Transformed 0 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:49:38 sparseml.exporters.transforms.onnx_transform INFO     [DeleteTrivialOnnxAdds] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[DeleteTrivialOnnxAdds] Transformed 0 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:50:07 sparseml.exporters.transforms.onnx_transform INFO     [ConstantsToInitializers] Transformed 2094 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[ConstantsToInitializers] Transformed 2094 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:50:11 sparseml.exporters.transforms.onnx_transform INFO     [FoldIdentityInitializers] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[FoldIdentityInitializers] Transformed 0 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:50:17 sparseml.exporters.transforms.onnx_transform INFO     [InitializersToUint8] Transformed 81 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[InitializersToUint8] Transformed 81 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:50:21 sparseml.exporters.transforms.onnx_transform INFO     [FlattenQParams] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[FlattenQParams] Transformed 0 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:50:25 sparseml.exporters.transforms.onnx_transform INFO     [FoldConvDivBn] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[FoldConvDivBn] Transformed 0 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:50:29 sparseml.exporters.transforms.onnx_transform INFO     [DeleteRepeatedQdq] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[DeleteRepeatedQdq] Transformed 0 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:50:33 sparseml.exporters.transforms.onnx_transform INFO     [QuantizeQATEmbedding] Transformed 1 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[QuantizeQATEmbedding] Transformed 1 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:50:37 sparseml.exporters.transforms.onnx_transform INFO     [PropagateEmbeddingQuantization] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[PropagateEmbeddingQuantization] Transformed 0 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:50:41 sparseml.exporters.transforms.onnx_transform INFO     [PropagateDequantThroughSplit] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[PropagateDequantThroughSplit] Transformed 0 matches\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "WARNING:sparsezoo.utils.onnx.external_data:Attempting to validate an in-memory ONNX model with size > 2000000000 bytes.`validate_onnx` skipped, as large ONNX models cannot be validated in-memory. To validate this model, save it to disk and call `validate_onnx` on the file path.\n",
            "2024-04-09 21:51:13 sparseml.exporters.transforms.onnx_transform INFO     [MatMulAddToMatMulIntegerAddCastMul] Transformed 155 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[MatMulAddToMatMulIntegerAddCastMul] Transformed 155 matches\n",
            "2024-04-09 21:51:21 sparseml.exporters.transforms.onnx_transform INFO     [MatMulToMatMulIntegerCastMul] Transformed 44 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[MatMulToMatMulIntegerCastMul] Transformed 44 matches\n",
            "2024-04-09 21:51:27 sparseml.exporters.transforms.onnx_transform INFO     [FoldReLUQuants] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[FoldReLUQuants] Transformed 0 matches\n",
            "2024-04-09 21:51:34 sparseml.exporters.transforms.onnx_transform INFO     [ConvToConvIntegerAddCastMul] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[ConvToConvIntegerAddCastMul] Transformed 0 matches\n",
            "2024-04-09 21:51:40 sparseml.exporters.transforms.onnx_transform INFO     [GemmToQLinearMatMul] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[GemmToQLinearMatMul] Transformed 0 matches\n",
            "2024-04-09 21:51:46 sparseml.exporters.transforms.onnx_transform INFO     [GemmToMatMulIntegerAddCastMul] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[GemmToMatMulIntegerAddCastMul] Transformed 0 matches\n",
            "2024-04-09 21:51:53 sparseml.exporters.transforms.onnx_transform INFO     [QuantizeResiduals] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[QuantizeResiduals] Transformed 0 matches\n",
            "2024-04-09 21:51:58 sparseml.exporters.transforms.onnx_transform INFO     [RemoveDuplicateQConvWeights] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[RemoveDuplicateQConvWeights] Transformed 0 matches\n",
            "2024-04-09 21:52:13 sparseml.exporters.transforms.onnx_transform INFO     [RemoveDuplicateQuantizeOps] Transformed 0 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[RemoveDuplicateQuantizeOps] Transformed 0 matches\n",
            "2024-04-09 21:52:26 sparseml.export.export INFO     Successfully exported model.onnx to ./exported/model.onnx...\n",
            "INFO:sparseml.export.export:Successfully exported model.onnx to ./exported/model.onnx...\n",
            "2024-04-09 21:52:26 sparseml.export.export INFO     Creating deployment folder deployment at directory: ./exported...\n",
            "INFO:sparseml.export.export:Creating deployment folder deployment at directory: ./exported...\n",
            "2024-04-09 21:52:26 sparseml.export.helpers WARNING  Optional file vocab.json not found in source path /content/one-shot-example/stage_compression\n",
            "WARNING:sparseml.export.helpers:Optional file vocab.json not found in source path /content/one-shot-example/stage_compression\n",
            "2024-04-09 21:52:26 sparseml.export.helpers WARNING  Optional file model-orig.onnx not found in source path /content/one-shot-example/stage_compression\n",
            "WARNING:sparseml.export.helpers:Optional file model-orig.onnx not found in source path /content/one-shot-example/stage_compression\n",
            "2024-04-09 21:52:26 sparseml.export.helpers WARNING  Optional file merges.txt not found in source path /content/one-shot-example/stage_compression\n",
            "WARNING:sparseml.export.helpers:Optional file merges.txt not found in source path /content/one-shot-example/stage_compression\n",
            "2024-04-09 21:52:26 sparseml.export.export INFO     Applying optimizations: all to the exported model...\n",
            "INFO:sparseml.export.export:Applying optimizations: all to the exported model...\n",
            "2024-04-09 21:52:26 sparseml.export.helpers INFO     Attempting to apply optimization: kv_cache_injection... \n",
            "INFO:sparseml.export.helpers:Attempting to apply optimization: kv_cache_injection... \n",
            "2024-04-09 21:52:29 sparseml.transformers.utils.optimizations INFO     Created a copy of the ONNX model before KV cache injection at exported/deployment/model-orig.onnx\n",
            "INFO:sparseml.transformers.utils.optimizations:Created a copy of the ONNX model before KV cache injection at exported/deployment/model-orig.onnx\n",
            "2024-04-09 21:52:30 sparseml.exporters.transforms.kv_cache.configs INFO     Loaded config file exported/deployment/config.json for model: llama\n",
            "INFO:sparseml.exporters.transforms.kv_cache.configs:Loaded config file exported/deployment/config.json for model: llama\n",
            "2024-04-09 21:52:30 sparseml.exporters.transforms.kv_cache.configs INFO     Adapted the model: llama to work with GQA.\n",
            "INFO:sparseml.exporters.transforms.kv_cache.configs:Adapted the model: llama to work with GQA.\n",
            "2024-04-09 21:52:30 sparseml.exporters.transforms.kv_cache.configs INFO     Properly configured arguments for KV Cache Transformation\n",
            "INFO:sparseml.exporters.transforms.kv_cache.configs:Properly configured arguments for KV Cache Transformation\n",
            "2024-04-09 21:52:32 sparseml.exporters.transforms.onnx_transform INFO     [CacheKeysAndValues] Transformed 44 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[CacheKeysAndValues] Transformed 44 matches\n",
            "/usr/local/lib/python3.10/dist-packages/sparseml/exporters/transforms/kv_cache/transforms_llama.py:125: UserWarning: Number of Slice nodes updated 44 does not match the expected values [64, 80] for the 7 billion or 13 billion parameter models.\n",
            "  warnings.warn(\n",
            "2024-04-09 21:52:42 sparseml.exporters.transforms.kv_cache.transforms_llama INFO     Found 44 Slice nodes to update\n",
            "INFO:sparseml.exporters.transforms.kv_cache.transforms_llama:Found 44 Slice nodes to update\n",
            "2024-04-09 21:52:42 sparseml.exporters.transforms.kv_cache.transforms_base INFO     Inserted positions input to the ONNX model\n",
            "INFO:sparseml.exporters.transforms.kv_cache.transforms_base:Inserted positions input to the ONNX model\n",
            "2024-04-09 21:52:42 sparseml.exporters.transforms.kv_cache.transforms_base INFO     Inserted causal_mask input to the ONNX model\n",
            "INFO:sparseml.exporters.transforms.kv_cache.transforms_base:Inserted causal_mask input to the ONNX model\n",
            "2024-04-09 21:52:42 sparseml.exporters.transforms.kv_cache.transforms_base INFO     Successfully swapped 1 nodes for input 'positions'\n",
            "INFO:sparseml.exporters.transforms.kv_cache.transforms_base:Successfully swapped 1 nodes for input 'positions'\n",
            "2024-04-09 21:52:43 sparseml.exporters.transforms.kv_cache.transforms_base INFO     Successfully swapped 1 nodes for input 'causal_mask'\n",
            "INFO:sparseml.exporters.transforms.kv_cache.transforms_base:Successfully swapped 1 nodes for input 'causal_mask'\n",
            "2024-04-09 21:52:52 sparseml.exporters.transforms.kv_cache.transforms_llama INFO     Successfully adjusted the causal_mask input\n",
            "INFO:sparseml.exporters.transforms.kv_cache.transforms_llama:Successfully adjusted the causal_mask input\n",
            "2024-04-09 21:52:52 sparseml.exporters.transforms.onnx_transform INFO     [AdditionalTransformsLLAMA] Transformed 49 matches\n",
            "INFO:sparseml.exporters.transforms.onnx_transform:[AdditionalTransformsLLAMA] Transformed 49 matches\n",
            "2024-04-09 21:52:59 sparseml.export.helpers INFO     Optimization: kv_cache_injection has been successfully applied to the ONNX model: ./exported/deployment/model.onnx\n",
            "INFO:sparseml.export.helpers:Optimization: kv_cache_injection has been successfully applied to the ONNX model: ./exported/deployment/model.onnx\n",
            "2024-04-09 21:52:59 sparseml.export.export INFO     Validating model structure...\n",
            "INFO:sparseml.export.export:Validating model structure...\n",
            "2024-04-09 21:52:59 sparseml.export.validators INFO     Exported model contains 1 external data files\n",
            "INFO:sparseml.export.validators:Exported model contains 1 external data files\n",
            "2024-04-09 21:52:59 sparseml.export.validators WARNING  File ./exported/sample-outputs is missing.\n",
            "WARNING:sparseml.export.validators:File ./exported/sample-outputs is missing.\n",
            "2024-04-09 21:52:59 sparseml.export.validators WARNING  File ./exported/sample-labels is missing.\n",
            "WARNING:sparseml.export.validators:File ./exported/sample-labels is missing.\n",
            "2024-04-09 21:52:59 sparseml.export.validators WARNING  File ./exported/sample-inputs is missing.\n",
            "WARNING:sparseml.export.validators:File ./exported/sample-inputs is missing.\n",
            "2024-04-09 21:52:59 sparseml.export.validators WARNING  File ./exported/deployment/merges.txt is missing.\n",
            "WARNING:sparseml.export.validators:File ./exported/deployment/merges.txt is missing.\n",
            "2024-04-09 21:52:59 sparseml.export.validators WARNING  File ./exported/deployment/vocab.json is missing.\n",
            "WARNING:sparseml.export.validators:File ./exported/deployment/vocab.json is missing.\n",
            "2024-04-09 21:52:59 sparseml.export.export INFO     Successfully exported model from:\n",
            "./exported\n",
            "to\n",
            "./exported/deployment\n",
            "for integration: transformers\n",
            "INFO:sparseml.export.export:Successfully exported model from:\n",
            "./exported\n",
            "to\n",
            "./exported/deployment\n",
            "for integration: transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The exported model located at `./exported` can now be used for efficient inference with DeepSparse!"
      ],
      "metadata": {
        "id": "TQJ8oP5BjhES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RQgf0kPL6A45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n",
        "!huggingface-cli upload mgoin/TinyLlama-1.1B-Chat-v1.0-pruned50-quant-ds exported/deployment/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7_uG3SZxKAR",
        "outputId": "216d0e1c-454b-4720-a150-0741b429ea65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rmodel-orig.onnx:   0% 0.00/1.10G [00:00<?, ?B/s]\n",
            "\rmodel.data:   0% 0.00/4.40G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\rmodel.onnx:   0% 0.00/1.10G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\rUpload 4 LFS files:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rtokenizer.model:   0% 0.00/500k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\rmodel.data:   0% 16.4k/4.40G [00:00<9:53:19, 124kB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:   0% 16.4k/1.10G [00:00<3:22:26, 90.9kB/s]\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.model:   3% 16.4k/500k [00:00<00:05, 92.3kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:   1% 6.39M/1.10G [00:00<00:44, 24.5MB/s] \u001b[A\u001b[A\n",
            "model-orig.onnx:   0% 4.33M/1.10G [00:00<01:08, 16.1MB/s]  \n",
            "\n",
            "model-orig.onnx:   1% 7.37M/1.10G [00:00<01:17, 14.2MB/s]\n",
            "model.data:   0% 8.22M/4.40G [00:00<05:16, 13.9MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:   1% 10.3M/1.10G [00:00<01:06, 16.4MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 696kB/s]  \n",
            "model-orig.onnx:   1% 16.0M/1.10G [00:01<01:13, 14.8MB/s]\n",
            "\n",
            "model.onnx:   1% 16.0M/1.10G [00:01<01:23, 13.0MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:   2% 22.2M/1.10G [00:01<00:46, 23.5MB/s]\n",
            "model.data:   1% 23.2M/4.40G [00:01<03:22, 21.6MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:   2% 27.3M/1.10G [00:01<00:42, 25.6MB/s]\n",
            "model.data:   1% 31.2M/4.40G [00:01<02:19, 31.4MB/s]\u001b[A\n",
            "\n",
            "model.onnx:   2% 24.8M/1.10G [00:01<00:55, 19.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:   2% 27.5M/1.10G [00:01<00:54, 19.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:   3% 31.1M/1.10G [00:01<00:48, 22.4MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:   3% 32.0M/1.10G [00:01<00:58, 18.2MB/s]\n",
            "model-orig.onnx:   3% 38.4M/1.10G [00:01<00:47, 22.4MB/s]\n",
            "\n",
            "model.onnx:   3% 33.6M/1.10G [00:02<01:17, 13.7MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:   4% 42.6M/1.10G [00:02<00:49, 21.5MB/s]\n",
            "\n",
            "model.onnx:   3% 38.5M/1.10G [00:02<00:57, 18.5MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:   4% 45.6M/1.10G [00:02<00:51, 20.7MB/s]\n",
            "\n",
            "model.onnx:   4% 44.7M/1.10G [00:02<00:46, 23.0MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:   4% 48.0M/1.10G [00:02<01:18, 13.4MB/s]\n",
            "\n",
            "model-orig.onnx:   6% 62.1M/1.10G [00:02<00:34, 30.5MB/s]\n",
            "\n",
            "model.onnx:   5% 54.6M/1.10G [00:02<00:51, 20.4MB/s]\u001b[A\u001b[A\n",
            "model.data:   1% 64.0M/4.40G [00:03<04:52, 14.8MB/s]\u001b[A\n",
            "\n",
            "model.onnx:   5% 59.2M/1.10G [00:03<00:51, 20.3MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:   6% 67.3M/1.10G [00:03<00:43, 23.6MB/s]\n",
            "\n",
            "model-orig.onnx:   6% 71.4M/1.10G [00:03<00:40, 25.2MB/s]\n",
            "model.data:   2% 83.7M/4.40G [00:03<02:46, 25.9MB/s]\u001b[A\n",
            "model-orig.onnx:   7% 75.2M/1.10G [00:03<00:48, 21.3MB/s]\n",
            "\n",
            "model-orig.onnx:   7% 78.3M/1.10G [00:03<00:49, 20.8MB/s]\n",
            "\n",
            "model.onnx:   7% 76.1M/1.10G [00:03<00:37, 27.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:   7% 81.1M/1.10G [00:04<01:10, 14.5MB/s]\n",
            "model-orig.onnx:   8% 90.8M/1.10G [00:04<00:39, 25.7MB/s]\n",
            "model.data:   2% 101M/4.40G [00:04<03:10, 22.5MB/s] \u001b[A\n",
            "\n",
            "model-orig.onnx:   9% 95.8M/1.10G [00:04<00:34, 29.0MB/s]\n",
            "model-orig.onnx:   9% 100M/1.10G [00:04<00:39, 25.2MB/s] \n",
            "model.data:   3% 112M/4.40G [00:04<03:21, 21.3MB/s]\u001b[A\n",
            "\n",
            "model.onnx:   8% 90.7M/1.10G [00:04<00:59, 17.0MB/s]\u001b[A\u001b[A\n",
            "model.data:   3% 126M/4.40G [00:04<01:57, 36.3MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  10% 110M/1.10G [00:05<00:46, 21.6MB/s]\n",
            "model.data:   3% 132M/4.40G [00:05<02:19, 30.6MB/s]\u001b[A\n",
            "\n",
            "model.onnx:   9% 96.1M/1.10G [00:05<01:19, 12.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:  10% 111M/1.10G [00:05<00:33, 29.3MB/s] \u001b[A\u001b[A\n",
            "model-orig.onnx:  10% 112M/1.10G [00:05<01:08, 14.5MB/s]\n",
            "model-orig.onnx:  12% 127M/1.10G [00:05<00:34, 28.0MB/s]\n",
            "\n",
            "model.onnx:  11% 117M/1.10G [00:05<00:41, 23.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  12% 131M/1.10G [00:06<00:37, 26.0MB/s]\n",
            "model.data:   4% 160M/4.40G [00:06<02:17, 30.9MB/s]\u001b[A\n",
            "model-orig.onnx:  13% 140M/1.10G [00:06<00:27, 35.5MB/s]\n",
            "model.data:   4% 175M/4.40G [00:06<01:42, 41.4MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  12% 132M/1.10G [00:06<00:35, 27.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  14% 158M/1.10G [00:06<00:21, 44.2MB/s]\n",
            "model.data:   4% 180M/4.40G [00:06<02:24, 29.3MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  13% 146M/1.10G [00:06<00:33, 28.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  16% 175M/1.10G [00:07<00:20, 45.6MB/s]\n",
            "model.data:   4% 188M/4.40G [00:07<02:51, 24.6MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  16% 182M/1.10G [00:07<00:27, 33.7MB/s]\n",
            "\n",
            "model.onnx:  16% 176M/1.10G [00:07<00:29, 31.3MB/s]\u001b[A\u001b[A\n",
            "model.data:   4% 192M/4.40G [00:07<03:55, 17.9MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  17% 188M/1.10G [00:07<00:21, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  17% 192M/1.10G [00:07<00:29, 31.3MB/s]\n",
            "model-orig.onnx:  18% 200M/1.10G [00:07<00:24, 36.8MB/s]\n",
            "\n",
            "model.onnx:  18% 195M/1.10G [00:07<00:25, 35.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  20% 223M/1.10G [00:08<00:17, 49.7MB/s]\n",
            "model.data:   5% 210M/4.40G [00:08<03:37, 19.3MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  19% 212M/1.10G [00:08<00:24, 36.9MB/s]\u001b[A\u001b[A\n",
            "model.data:   5% 219M/4.40G [00:08<02:35, 26.9MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  21% 231M/1.10G [00:08<00:23, 37.2MB/s]\n",
            "model.data:   5% 224M/4.40G [00:08<02:57, 23.5MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  20% 224M/1.10G [00:08<00:26, 33.2MB/s]\u001b[A\u001b[A\n",
            "model.data:   5% 232M/4.40G [00:08<02:12, 31.5MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  21% 231M/1.10G [00:08<00:22, 39.1MB/s]\u001b[A\u001b[A\n",
            "model.data:   5% 238M/4.40G [00:08<01:58, 35.2MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  22% 240M/1.10G [00:09<00:28, 30.2MB/s]\n",
            "model-orig.onnx:  23% 252M/1.10G [00:09<00:21, 40.4MB/s]\n",
            "\n",
            "model.onnx:  22% 243M/1.10G [00:09<00:25, 33.8MB/s]\u001b[A\u001b[A\n",
            "model.data:   6% 249M/4.40G [00:09<01:55, 36.0MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  22% 248M/1.10G [00:09<00:25, 34.0MB/s]\u001b[A\u001b[A\n",
            "model.data:   6% 254M/4.40G [00:09<01:54, 36.2MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  25% 272M/1.10G [00:09<00:18, 45.7MB/s]\n",
            "\n",
            "model.onnx:  23% 258M/1.10G [00:09<00:29, 28.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:  25% 272M/1.10G [00:09<00:17, 47.8MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  25% 279M/1.10G [00:09<00:22, 37.5MB/s]\n",
            "model-orig.onnx:  26% 284M/1.10G [00:10<00:20, 39.9MB/s]\n",
            "model.data:   6% 271M/4.40G [00:10<02:03, 33.5MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  25% 278M/1.10G [00:10<00:23, 35.0MB/s]\u001b[A\u001b[A\n",
            "model.data:   6% 276M/4.40G [00:10<02:23, 28.8MB/s]\u001b[A\n",
            "model-orig.onnx:  26% 290M/1.10G [00:10<00:27, 29.4MB/s]\n",
            "\n",
            "model-orig.onnx:  27% 301M/1.10G [00:10<00:19, 41.4MB/s]\n",
            "\n",
            "model.onnx:  27% 297M/1.10G [00:10<00:19, 40.9MB/s]\u001b[A\u001b[A\n",
            "model.data:   7% 293M/4.40G [00:10<01:52, 36.4MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  28% 304M/1.10G [00:10<00:18, 43.9MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  28% 313M/1.10G [00:10<00:20, 38.5MB/s]\n",
            "\n",
            "model.onnx:  28% 310M/1.10G [00:10<00:22, 35.3MB/s]\u001b[A\u001b[A\n",
            "model.data:   7% 304M/4.40G [00:11<02:18, 29.5MB/s]\u001b[A\n",
            "model-orig.onnx:  29% 320M/1.10G [00:11<00:26, 29.5MB/s]\n",
            "\n",
            "model-orig.onnx:  30% 334M/1.10G [00:11<00:16, 46.0MB/s]\n",
            "\n",
            "model.onnx:  30% 330M/1.10G [00:11<00:17, 43.2MB/s]\u001b[A\u001b[A\n",
            "model.data:   7% 320M/4.40G [00:11<02:05, 32.6MB/s]\u001b[A\n",
            "model-orig.onnx:  31% 341M/1.10G [00:11<00:21, 35.9MB/s]\n",
            "model.data:   8% 336M/4.40G [00:11<01:55, 35.3MB/s]\u001b[A\n",
            "model.data:   8% 351M/4.40G [00:11<01:15, 53.6MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  32% 352M/1.10G [00:12<00:21, 34.7MB/s]\n",
            "\n",
            "model-orig.onnx:  33% 361M/1.10G [00:12<00:18, 40.2MB/s]\n",
            "model.data:   8% 358M/4.40G [00:12<01:41, 40.0MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  33% 368M/1.10G [00:12<00:22, 33.3MB/s]\n",
            "\n",
            "model-orig.onnx:  34% 375M/1.10G [00:12<00:18, 38.6MB/s]\n",
            "model.data:   8% 368M/4.40G [00:12<01:58, 34.1MB/s]\u001b[A\n",
            "model.data:   9% 382M/4.40G [00:12<01:22, 48.8MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  34% 373M/1.10G [00:12<00:20, 35.7MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  36% 398M/1.10G [00:13<00:17, 40.7MB/s]\n",
            "\n",
            "model.onnx:  35% 384M/1.10G [00:13<00:22, 32.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:  36% 393M/1.10G [00:13<00:17, 39.7MB/s]\u001b[A\u001b[A\n",
            "model.data:   9% 400M/4.40G [00:13<01:48, 36.8MB/s]\u001b[A\n",
            "model-orig.onnx:  37% 413M/1.10G [00:13<00:16, 41.5MB/s]\n",
            "\n",
            "model.onnx:  36% 400M/1.10G [00:13<00:22, 32.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:  38% 415M/1.10G [00:13<00:14, 48.4MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  38% 420M/1.10G [00:13<00:21, 32.1MB/s]\n",
            "model-orig.onnx:  39% 425M/1.10G [00:14<00:19, 34.3MB/s]\n",
            "\n",
            "model-orig.onnx:  39% 432M/1.10G [00:14<00:17, 39.2MB/s]\n",
            "\n",
            "model.onnx:  39% 429M/1.10G [00:14<00:17, 39.5MB/s]\u001b[A\u001b[A\n",
            "model.data:  10% 438M/4.40G [00:14<01:58, 33.6MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  40% 437M/1.10G [00:14<00:22, 29.9MB/s]\n",
            "\n",
            "model-orig.onnx:  40% 443M/1.10G [00:14<00:20, 33.0MB/s]\n",
            "\n",
            "model.onnx:  41% 447M/1.10G [00:14<00:15, 42.2MB/s]\u001b[A\u001b[A\n",
            "model.data:  10% 448M/4.40G [00:14<02:07, 31.0MB/s]\u001b[A\n",
            "model.data:  10% 462M/4.40G [00:14<01:29, 43.9MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  41% 448M/1.10G [00:15<00:29, 22.6MB/s]\n",
            "\n",
            "model-orig.onnx:  41% 455M/1.10G [00:15<00:22, 29.4MB/s]\n",
            "model-orig.onnx:  42% 462M/1.10G [00:15<00:18, 35.0MB/s]\n",
            "model.data:  11% 474M/4.40G [00:15<01:45, 37.2MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  42% 467M/1.10G [00:15<00:20, 30.9MB/s]\n",
            "\n",
            "model-orig.onnx:  43% 473M/1.10G [00:15<00:17, 35.1MB/s]\n",
            "model-orig.onnx:  43% 480M/1.10G [00:15<00:14, 42.1MB/s]\n",
            "model.data:  11% 489M/4.40G [00:15<01:46, 36.6MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  44% 482M/1.10G [00:15<00:19, 31.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  45% 494M/1.10G [00:16<00:14, 42.8MB/s]\n",
            "model.data:  11% 496M/4.40G [00:16<02:05, 31.1MB/s]\u001b[A\n",
            "model.data:  12% 508M/4.40G [00:16<01:29, 43.5MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  46% 510M/1.10G [00:16<00:13, 43.3MB/s]\n",
            "model.data:  12% 514M/4.40G [00:16<01:54, 33.9MB/s]\u001b[A\n",
            "model-orig.onnx:  48% 527M/1.10G [00:16<00:10, 53.2MB/s]\n",
            "model.data:  12% 532M/4.40G [00:16<01:44, 37.1MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  46% 512M/1.10G [00:16<00:23, 25.1MB/s]\u001b[A\u001b[A\n",
            "model.data:  12% 541M/4.40G [00:17<01:27, 44.2MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  48% 534M/1.10G [00:17<00:15, 36.4MB/s]\n",
            "\n",
            "model-orig.onnx:  49% 540M/1.10G [00:17<00:14, 40.2MB/s]\n",
            "model.data:  12% 547M/4.40G [00:17<01:53, 34.0MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  48% 530M/1.10G [00:17<00:20, 28.1MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  49% 546M/1.10G [00:17<00:15, 35.0MB/s]\n",
            "\n",
            "model-orig.onnx:  50% 552M/1.10G [00:17<00:13, 40.4MB/s]\n",
            "\n",
            "model-orig.onnx:  51% 558M/1.10G [00:17<00:12, 42.4MB/s]\n",
            "model.data:  13% 566M/4.40G [00:17<01:44, 36.7MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  51% 563M/1.10G [00:17<00:18, 29.8MB/s]\n",
            "\n",
            "model-orig.onnx:  52% 569M/1.10G [00:18<00:15, 33.7MB/s]\n",
            "\n",
            "model.onnx:  51% 562M/1.10G [00:18<00:19, 28.4MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  52% 576M/1.10G [00:18<00:18, 28.4MB/s]\n",
            "\n",
            "model-orig.onnx:  53% 582M/1.10G [00:18<00:16, 32.0MB/s]\n",
            "model-orig.onnx:  53% 588M/1.10G [00:18<00:14, 36.7MB/s]\n",
            "model.data:  13% 589M/4.40G [00:18<02:01, 31.3MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  53% 580M/1.10G [00:18<00:15, 33.6MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  54% 592M/1.10G [00:19<00:19, 26.0MB/s]\n",
            "model-orig.onnx:  54% 601M/1.10G [00:19<00:14, 33.8MB/s]\n",
            "\n",
            "model.onnx:  54% 592M/1.10G [00:19<00:16, 30.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:  55% 606M/1.10G [00:19<00:11, 44.1MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  55% 608M/1.10G [00:19<00:15, 31.6MB/s]\n",
            "model-orig.onnx:  56% 622M/1.10G [00:19<00:11, 42.8MB/s]\n",
            "\n",
            "model.onnx:  55% 612M/1.10G [00:19<00:13, 35.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  57% 627M/1.10G [00:19<00:12, 38.8MB/s]\n",
            "model-orig.onnx:  57% 634M/1.10G [00:19<00:10, 45.7MB/s]\n",
            "model.data:  14% 633M/4.40G [00:19<01:43, 36.6MB/s]\u001b[A\n",
            "model.data:  15% 639M/4.40G [00:20<01:30, 41.4MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  57% 628M/1.10G [00:20<00:13, 35.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  59% 652M/1.10G [00:20<00:09, 49.7MB/s]\n",
            "model.data:  15% 645M/4.40G [00:20<01:56, 32.1MB/s]\u001b[A\n",
            "model.data:  15% 654M/4.40G [00:20<01:29, 41.9MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  60% 658M/1.10G [00:20<00:11, 37.6MB/s]\n",
            "\n",
            "model-orig.onnx:  60% 667M/1.10G [00:20<00:09, 46.9MB/s]\n",
            "model.data:  15% 660M/4.40G [00:20<01:52, 33.4MB/s]\u001b[A\n",
            "model-orig.onnx:  61% 674M/1.10G [00:20<00:11, 38.0MB/s]\n",
            "\n",
            "model-orig.onnx:  62% 681M/1.10G [00:21<00:09, 43.1MB/s]\n",
            "model.data:  15% 674M/4.40G [00:21<01:52, 33.0MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  62% 688M/1.10G [00:21<00:08, 46.8MB/s]\n",
            "model-orig.onnx:  63% 693M/1.10G [00:21<00:11, 35.6MB/s]\n",
            "model.data:  16% 688M/4.40G [00:21<01:51, 33.3MB/s]\u001b[A\n",
            "model.data:  16% 700M/4.40G [00:21<01:19, 46.9MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  64% 704M/1.10G [00:21<00:12, 33.1MB/s]\n",
            "\n",
            "model-orig.onnx:  65% 713M/1.10G [00:21<00:09, 39.2MB/s]\n",
            "model-orig.onnx:  65% 719M/1.10G [00:22<00:08, 43.3MB/s]\n",
            "model.data:  16% 711M/4.40G [00:22<01:38, 37.3MB/s]\u001b[A\n",
            "model.data:  16% 720M/4.40G [00:22<01:19, 46.4MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  62% 690M/1.10G [00:22<00:16, 25.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  66% 732M/1.10G [00:22<00:09, 41.3MB/s]\n",
            "model.data:  16% 726M/4.40G [00:22<01:49, 33.7MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  64% 707M/1.10G [00:22<00:12, 31.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  68% 751M/1.10G [00:22<00:07, 47.5MB/s]\n",
            "model.data:  17% 736M/4.40G [00:22<01:59, 30.6MB/s]\u001b[A\n",
            "model.data:  17% 751M/4.40G [00:22<01:18, 46.3MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  65% 722M/1.10G [00:22<00:12, 31.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  69% 758M/1.10G [00:23<00:10, 33.9MB/s]\n",
            "model-orig.onnx:  69% 767M/1.10G [00:23<00:08, 42.0MB/s]\n",
            "model.data:  17% 763M/4.40G [00:23<01:31, 39.7MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  67% 740M/1.10G [00:23<00:10, 34.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  71% 782M/1.10G [00:23<00:07, 43.7MB/s]\n",
            "model.data:  17% 769M/4.40G [00:23<01:56, 31.1MB/s]\u001b[A\n",
            "model.data:  18% 780M/4.40G [00:23<01:23, 43.3MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  68% 754M/1.10G [00:23<00:10, 32.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:  69% 762M/1.10G [00:23<00:08, 40.6MB/s]\u001b[A\u001b[A\n",
            "model.data:  18% 786M/4.40G [00:24<01:41, 35.5MB/s]\u001b[A\n",
            "model.data:  18% 799M/4.40G [00:24<01:11, 50.6MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  71% 789M/1.10G [00:24<00:13, 23.8MB/s]\n",
            "\n",
            "model-orig.onnx:  72% 795M/1.10G [00:24<00:11, 27.8MB/s]\n",
            "model.data:  18% 807M/4.40G [00:24<01:39, 36.0MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  72% 800M/1.10G [00:24<00:12, 24.5MB/s]\n",
            "\n",
            "model-orig.onnx:  73% 807M/1.10G [00:24<00:09, 30.8MB/s]\n",
            "model-orig.onnx:  74% 815M/1.10G [00:24<00:07, 39.2MB/s]\n",
            "model.data:  19% 828M/4.40G [00:25<01:22, 43.5MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  73% 803M/1.10G [00:25<00:08, 37.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  74% 821M/1.10G [00:25<00:08, 31.9MB/s]\n",
            "model-orig.onnx:  75% 830M/1.10G [00:25<00:06, 39.8MB/s]\n",
            "model.data:  19% 841M/4.40G [00:25<01:28, 40.1MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  76% 835M/1.10G [00:25<00:07, 34.2MB/s]\n",
            "\n",
            "model-orig.onnx:  76% 841M/1.10G [00:25<00:07, 37.4MB/s]\n",
            "\n",
            "model.onnx:  75% 833M/1.10G [00:25<00:08, 30.5MB/s]\u001b[A\u001b[A\n",
            "model.data:  19% 848M/4.40G [00:25<02:24, 24.7MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  77% 848M/1.10G [00:26<00:09, 27.0MB/s]\n",
            "model-orig.onnx:  77% 854M/1.10G [00:26<00:08, 29.7MB/s]\n",
            "model-orig.onnx:  78% 860M/1.10G [00:26<00:06, 35.1MB/s]\n",
            "\n",
            "model.onnx:  77% 851M/1.10G [00:26<00:07, 33.4MB/s]\u001b[A\u001b[A\n",
            "model.data:  20% 867M/4.40G [00:26<02:05, 28.1MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  78% 865M/1.10G [00:26<00:08, 27.6MB/s]\n",
            "model-orig.onnx:  79% 873M/1.10G [00:26<00:06, 35.2MB/s]\n",
            "\n",
            "model.onnx:  79% 871M/1.10G [00:26<00:06, 38.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:  80% 879M/1.10G [00:26<00:05, 44.9MB/s]\u001b[A\u001b[A\n",
            "model.data:  20% 880M/4.40G [00:26<02:10, 27.0MB/s]\u001b[A\n",
            "model-orig.onnx:  81% 892M/1.10G [00:27<00:04, 42.8MB/s]\n",
            "\n",
            "model.onnx:  80% 886M/1.10G [00:27<00:06, 33.7MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  83% 912M/1.10G [00:27<00:04, 47.0MB/s]\n",
            "\n",
            "model.onnx:  81% 896M/1.10G [00:27<00:06, 30.4MB/s]\u001b[A\u001b[A\n",
            "model.data:  21% 912M/4.40G [00:27<01:45, 33.0MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  82% 910M/1.10G [00:27<00:04, 43.6MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  83% 919M/1.10G [00:27<00:04, 39.7MB/s]\n",
            "model-orig.onnx:  84% 925M/1.10G [00:28<00:04, 42.4MB/s]\n",
            "\n",
            "model-orig.onnx:  84% 931M/1.10G [00:28<00:05, 28.9MB/s]\n",
            "\n",
            "model-orig.onnx:  85% 941M/1.10G [00:28<00:04, 39.2MB/s]\n",
            "\n",
            "model-orig.onnx:  87% 960M/1.10G [00:28<00:03, 47.1MB/s]\n",
            "\n",
            "model.onnx:  85% 944M/1.10G [00:28<00:04, 32.2MB/s]\u001b[A\u001b[A\n",
            "model.data:  21% 933M/4.40G [00:28<03:22, 17.1MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  86% 953M/1.10G [00:29<00:03, 39.2MB/s]\u001b[A\u001b[A\n",
            "model.data:  21% 938M/4.40G [00:29<02:53, 20.0MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  88% 967M/1.10G [00:29<00:03, 36.5MB/s]\n",
            "\n",
            "model.onnx:  87% 965M/1.10G [00:29<00:03, 36.8MB/s]\u001b[A\u001b[A\n",
            "model.data:  21% 944M/4.40G [00:29<02:57, 19.5MB/s]\u001b[A\n",
            "model.data:  22% 951M/4.40G [00:29<02:13, 25.8MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  88% 973M/1.10G [00:29<00:03, 41.7MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  90% 990M/1.10G [00:29<00:02, 44.4MB/s]\n",
            "\n",
            "model.onnx:  89% 978M/1.10G [00:29<00:03, 31.7MB/s]\u001b[A\u001b[A\n",
            "model.data:  22% 963M/4.40G [00:29<02:00, 28.6MB/s]\u001b[A\n",
            "model.data:  22% 969M/4.40G [00:29<01:38, 34.7MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  89% 985M/1.10G [00:29<00:03, 37.8MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  90% 997M/1.10G [00:30<00:02, 36.4MB/s]\n",
            "\n",
            "model-orig.onnx:  91% 1.00G/1.10G [00:30<00:02, 41.0MB/s]\n",
            "model.data:  22% 981M/4.40G [00:30<01:50, 30.8MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  90% 996M/1.10G [00:30<00:03, 29.3MB/s]\u001b[A\u001b[A\n",
            "model.data:  22% 988M/4.40G [00:30<01:27, 38.8MB/s]\u001b[A\n",
            "\n",
            "model-orig.onnx:  92% 1.02G/1.10G [00:30<00:02, 35.3MB/s]\n",
            "model.data:  23% 994M/4.40G [00:30<02:02, 27.9MB/s]\u001b[A\n",
            "model-orig.onnx:  94% 1.04G/1.10G [00:30<00:01, 51.0MB/s]\n",
            "\n",
            "model.onnx:  91% 1.01G/1.10G [00:31<00:04, 20.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:  93% 1.02G/1.10G [00:31<00:02, 36.7MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  95% 1.05G/1.10G [00:31<00:01, 42.6MB/s]\n",
            "model-orig.onnx:  95% 1.05G/1.10G [00:31<00:01, 45.5MB/s]\n",
            "\n",
            "model.onnx:  93% 1.03G/1.10G [00:31<00:02, 31.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:  94% 1.04G/1.10G [00:31<00:01, 40.2MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  96% 1.07G/1.10G [00:31<00:00, 40.7MB/s]\n",
            "model-orig.onnx:  97% 1.07G/1.10G [00:31<00:00, 44.3MB/s]\n",
            "model.data:  24% 1.04G/4.40G [00:31<01:25, 39.4MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  95% 1.04G/1.10G [00:31<00:02, 29.5MB/s]\u001b[A\u001b[A\n",
            "model.data:  24% 1.05G/4.40G [00:32<01:38, 34.1MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  96% 1.06G/1.10G [00:32<00:01, 30.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx:  97% 1.07G/1.10G [00:32<00:00, 44.9MB/s]\u001b[A\u001b[A\n",
            "model-orig.onnx:  98% 1.08G/1.10G [00:32<00:01, 22.2MB/s]\n",
            "model-orig.onnx:  98% 1.08G/1.10G [00:32<00:00, 26.0MB/s]\n",
            "\n",
            "model.onnx:  98% 1.08G/1.10G [00:32<00:00, 37.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-orig.onnx:  99% 1.09G/1.10G [00:32<00:00, 23.3MB/s]\n",
            "model-orig.onnx: 100% 1.10G/1.10G [00:32<00:00, 37.3MB/s]\n",
            "model.data:  25% 1.08G/4.40G [00:33<01:34, 35.0MB/s]\u001b[A\n",
            "\n",
            "model.onnx:  99% 1.09G/1.10G [00:33<00:00, 32.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.onnx: 100% 1.10G/1.10G [00:33<00:00, 42.1MB/s]\u001b[A\u001b[A\n",
            "model.data:  25% 1.09G/4.40G [00:33<01:52, 29.5MB/s]\u001b[A\n",
            "model-orig.onnx: 100% 1.10G/1.10G [00:33<00:00, 32.9MB/s]\n",
            "\n",
            "model.data:  25% 1.11G/4.40G [00:33<01:25, 38.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Upload 4 LFS files:  25% 1/4 [00:34<01:42, 34.03s/it]\u001b[A\u001b[A\u001b[A\n",
            "model.data:  25% 1.12G/4.40G [00:34<01:25, 38.6MB/s]\u001b[A\n",
            "model.onnx: 100% 1.10G/1.10G [00:34<00:00, 32.2MB/s]\n",
            "\n",
            "model.data:  26% 1.14G/4.40G [00:34<01:13, 44.6MB/s]\u001b[A\n",
            "model.data:  26% 1.15G/4.40G [00:34<01:23, 38.7MB/s]\u001b[A\n",
            "model.data:  27% 1.17G/4.40G [00:34<00:59, 54.4MB/s]\u001b[A\n",
            "model.data:  27% 1.18G/4.40G [00:35<01:16, 42.1MB/s]\u001b[A\n",
            "model.data:  27% 1.18G/4.40G [00:35<01:41, 31.7MB/s]\u001b[A\n",
            "model.data:  27% 1.20G/4.40G [00:35<01:10, 45.7MB/s]\u001b[A\n",
            "model.data:  27% 1.21G/4.40G [00:36<01:24, 37.8MB/s]\u001b[A\n",
            "model.data:  28% 1.22G/4.40G [00:36<01:30, 35.3MB/s]\u001b[A\n",
            "model.data:  28% 1.23G/4.40G [00:36<01:03, 50.2MB/s]\u001b[A\n",
            "model.data:  28% 1.24G/4.40G [00:36<01:24, 37.6MB/s]\u001b[A\n",
            "model.data:  28% 1.25G/4.40G [00:37<01:33, 33.6MB/s]\u001b[A\n",
            "model.data:  29% 1.26G/4.40G [00:37<01:04, 48.5MB/s]\u001b[A\n",
            "model.data:  29% 1.27G/4.40G [00:37<01:19, 39.6MB/s]\u001b[A\n",
            "model.data:  29% 1.28G/4.40G [00:38<01:33, 33.3MB/s]\u001b[A\n",
            "model.data:  29% 1.30G/4.40G [00:38<01:04, 48.3MB/s]\u001b[A\n",
            "model.data:  30% 1.30G/4.40G [00:38<01:15, 40.9MB/s]\u001b[A\n",
            "model.data:  30% 1.31G/4.40G [00:38<01:27, 35.2MB/s]\u001b[A\n",
            "model.data:  30% 1.33G/4.40G [00:38<01:03, 48.7MB/s]\u001b[A\n",
            "model.data:  30% 1.33G/4.40G [00:39<01:14, 41.4MB/s]\u001b[A\n",
            "model.data:  31% 1.34G/4.40G [00:39<01:23, 36.5MB/s]\u001b[A\n",
            "model.data:  31% 1.36G/4.40G [00:39<00:59, 51.5MB/s]\u001b[A\n",
            "model.data:  31% 1.37G/4.40G [00:39<01:09, 43.5MB/s]\u001b[A\n",
            "model.data:  31% 1.38G/4.40G [00:40<01:19, 38.3MB/s]\u001b[A\n",
            "model.data:  32% 1.39G/4.40G [00:40<00:55, 53.9MB/s]\u001b[A\n",
            "model.data:  32% 1.40G/4.40G [00:40<01:08, 43.7MB/s]\u001b[A\n",
            "model.data:  32% 1.41G/4.40G [00:41<01:25, 34.9MB/s]\u001b[A\n",
            "model.data:  32% 1.42G/4.40G [00:41<00:59, 49.8MB/s]\u001b[A\n",
            "model.data:  33% 1.43G/4.40G [00:41<01:15, 39.1MB/s]\u001b[A\n",
            "model.data:  33% 1.44G/4.40G [00:42<01:51, 26.5MB/s]\u001b[A\n",
            "model.data:  33% 1.46G/4.40G [00:42<01:15, 39.1MB/s]\u001b[A\n",
            "model.data:  33% 1.46G/4.40G [00:42<01:26, 34.1MB/s]\u001b[A\n",
            "model.data:  33% 1.47G/4.40G [00:42<01:30, 32.3MB/s]\u001b[A\n",
            "model.data:  34% 1.49G/4.40G [00:42<01:02, 46.8MB/s]\u001b[A\n",
            "model.data:  34% 1.50G/4.40G [00:43<01:13, 39.3MB/s]\u001b[A\n",
            "model.data:  34% 1.50G/4.40G [00:43<01:26, 33.6MB/s]\u001b[A\n",
            "model.data:  34% 1.52G/4.40G [00:43<01:00, 47.3MB/s]\u001b[A\n",
            "model.data:  35% 1.53G/4.40G [00:44<01:12, 39.8MB/s]\u001b[A\n",
            "model.data:  35% 1.54G/4.40G [00:44<01:14, 38.3MB/s]\u001b[A\n",
            "model.data:  35% 1.55G/4.40G [00:44<00:52, 54.2MB/s]\u001b[A\n",
            "model.data:  35% 1.56G/4.40G [00:44<01:08, 41.5MB/s]\u001b[A\n",
            "model.data:  36% 1.57G/4.40G [00:45<01:23, 33.8MB/s]\u001b[A\n",
            "model.data:  36% 1.58G/4.40G [00:45<00:59, 47.4MB/s]\u001b[A\n",
            "model.data:  36% 1.59G/4.40G [00:45<01:16, 36.7MB/s]\u001b[A\n",
            "model.data:  36% 1.60G/4.40G [00:45<01:19, 35.4MB/s]\u001b[A\n",
            "model.data:  37% 1.61G/4.40G [00:46<00:55, 50.0MB/s]\u001b[A\n",
            "model.data:  37% 1.62G/4.40G [00:46<01:07, 41.4MB/s]\u001b[A\n",
            "model.data:  37% 1.63G/4.40G [00:46<01:15, 36.9MB/s]\u001b[A\n",
            "model.data:  37% 1.65G/4.40G [00:46<00:52, 52.0MB/s]\u001b[A\n",
            "model.data:  38% 1.66G/4.40G [00:47<01:05, 41.7MB/s]\u001b[A\n",
            "model.data:  38% 1.66G/4.40G [00:47<01:11, 38.3MB/s]\u001b[A\n",
            "model.data:  38% 1.68G/4.40G [00:47<00:50, 53.8MB/s]\u001b[A\n",
            "model.data:  38% 1.69G/4.40G [00:47<01:06, 40.5MB/s]\u001b[A\n",
            "model.data:  39% 1.70G/4.40G [00:48<01:22, 32.8MB/s]\u001b[A\n",
            "model.data:  39% 1.71G/4.40G [00:48<00:56, 47.2MB/s]\u001b[A\n",
            "model.data:  39% 1.72G/4.40G [00:48<01:07, 39.6MB/s]\u001b[A\n",
            "model.data:  39% 1.73G/4.40G [00:48<01:13, 36.3MB/s]\u001b[A\n",
            "model.data:  40% 1.74G/4.40G [00:49<00:50, 52.3MB/s]\u001b[A\n",
            "model.data:  40% 1.75G/4.40G [00:49<00:58, 45.0MB/s]\u001b[A\n",
            "model.data:  40% 1.76G/4.40G [00:49<01:11, 37.1MB/s]\u001b[A\n",
            "model.data:  40% 1.78G/4.40G [00:49<00:49, 53.2MB/s]\u001b[A\n",
            "model.data:  41% 1.78G/4.40G [00:50<01:04, 40.5MB/s]\u001b[A\n",
            "model.data:  41% 1.79G/4.40G [00:50<01:24, 30.9MB/s]\u001b[A\n",
            "model.data:  41% 1.81G/4.40G [00:50<00:57, 44.8MB/s]\u001b[A\n",
            "model.data:  41% 1.81G/4.40G [00:51<01:13, 35.1MB/s]\u001b[A\n",
            "model.data:  41% 1.82G/4.40G [00:51<01:22, 31.2MB/s]\u001b[A\n",
            "model.data:  42% 1.84G/4.40G [00:51<00:56, 45.2MB/s]\u001b[A\n",
            "model.data:  42% 1.85G/4.40G [00:51<01:11, 35.8MB/s]\u001b[A\n",
            "model.data:  42% 1.86G/4.40G [00:52<01:17, 33.0MB/s]\u001b[A\n",
            "model.data:  43% 1.87G/4.40G [00:52<00:53, 47.4MB/s]\u001b[A\n",
            "model.data:  43% 1.88G/4.40G [00:52<00:59, 42.3MB/s]\u001b[A\n",
            "model.data:  43% 1.89G/4.40G [00:53<01:14, 33.6MB/s]\u001b[A\n",
            "model.data:  43% 1.90G/4.40G [00:53<00:51, 48.7MB/s]\u001b[A\n",
            "model.data:  43% 1.91G/4.40G [00:53<01:03, 39.2MB/s]\u001b[A\n",
            "model.data:  44% 1.92G/4.40G [00:53<01:10, 35.4MB/s]\u001b[A\n",
            "model.data:  44% 1.93G/4.40G [00:53<00:49, 49.4MB/s]\u001b[A\n",
            "model.data:  44% 1.94G/4.40G [00:54<01:06, 37.3MB/s]\u001b[A\n",
            "model.data:  44% 1.95G/4.40G [00:54<01:20, 30.3MB/s]\u001b[A\n",
            "model.data:  45% 1.97G/4.40G [00:54<00:56, 42.8MB/s]\u001b[A\n",
            "model.data:  45% 1.97G/4.40G [00:55<01:03, 38.5MB/s]\u001b[A\n",
            "model.data:  45% 1.98G/4.40G [00:55<01:14, 32.4MB/s]\u001b[A\n",
            "model.data:  45% 2.00G/4.40G [00:55<00:51, 46.4MB/s]\u001b[A\n",
            "model.data:  46% 2.01G/4.40G [00:55<00:57, 41.6MB/s]\u001b[A\n",
            "model.data:  46% 2.02G/4.40G [00:56<01:27, 27.1MB/s]\u001b[A\n",
            "model.data:  46% 2.03G/4.40G [00:56<00:59, 39.7MB/s]\u001b[A\n",
            "model.data:  46% 2.04G/4.40G [00:56<01:03, 37.2MB/s]\u001b[A\n",
            "model.data:  47% 2.05G/4.40G [00:57<01:05, 36.1MB/s]\u001b[A\n",
            "model.data:  47% 2.06G/4.40G [00:57<00:46, 50.3MB/s]\u001b[A\n",
            "model.data:  47% 2.07G/4.40G [00:57<00:58, 39.8MB/s]\u001b[A\n",
            "model.data:  47% 2.08G/4.40G [00:58<01:22, 28.0MB/s]\u001b[A\n",
            "model.data:  48% 2.10G/4.40G [00:58<00:56, 40.9MB/s]\u001b[A\n",
            "model.data:  48% 2.10G/4.40G [00:58<01:01, 37.6MB/s]\u001b[A\n",
            "model.data:  48% 2.11G/4.40G [00:58<01:06, 34.4MB/s]\u001b[A\n",
            "model.data:  48% 2.13G/4.40G [00:59<00:47, 48.2MB/s]\u001b[A\n",
            "model.data:  48% 2.13G/4.40G [00:59<01:01, 36.9MB/s]\u001b[A\n",
            "model.data:  49% 2.14G/4.40G [00:59<01:07, 33.5MB/s]\u001b[A\n",
            "model.data:  49% 2.16G/4.40G [00:59<00:46, 47.9MB/s]\u001b[A\n",
            "model.data:  49% 2.17G/4.40G [01:00<00:55, 40.6MB/s]\u001b[A\n",
            "model.data:  49% 2.18G/4.40G [01:00<01:05, 34.0MB/s]\u001b[A\n",
            "model.data:  50% 2.19G/4.40G [01:00<00:45, 48.6MB/s]\u001b[A\n",
            "model.data:  50% 2.20G/4.40G [01:01<00:56, 39.0MB/s]\u001b[A\n",
            "model.data:  50% 2.21G/4.40G [01:01<01:06, 33.2MB/s]\u001b[A\n",
            "model.data:  51% 2.22G/4.40G [01:01<00:45, 47.6MB/s]\u001b[A\n",
            "model.data:  51% 2.23G/4.40G [01:02<01:29, 24.4MB/s]\u001b[A\n",
            "model.data:  51% 2.24G/4.40G [01:02<01:23, 25.8MB/s]\u001b[A\n",
            "model.data:  51% 2.26G/4.40G [01:02<00:55, 38.5MB/s]\u001b[A\n",
            "model.data:  51% 2.26G/4.40G [01:03<01:02, 34.0MB/s]\u001b[A\n",
            "model.data:  52% 2.27G/4.40G [01:03<01:09, 30.5MB/s]\u001b[A\n",
            "model.data:  52% 2.29G/4.40G [01:03<00:47, 44.3MB/s]\u001b[A\n",
            "model.data:  52% 2.30G/4.40G [01:04<01:14, 28.2MB/s]\u001b[A\n",
            "model.data:  52% 2.30G/4.40G [01:04<01:14, 28.0MB/s]\u001b[A\n",
            "model.data:  53% 2.32G/4.40G [01:04<00:50, 41.0MB/s]\u001b[A\n",
            "model.data:  53% 2.33G/4.40G [01:04<01:00, 34.6MB/s]\u001b[A\n",
            "model.data:  53% 2.34G/4.40G [01:05<01:01, 33.6MB/s]\u001b[A\n",
            "model.data:  53% 2.35G/4.40G [01:05<00:42, 48.3MB/s]\u001b[A\n",
            "model.data:  54% 2.36G/4.40G [01:05<00:52, 38.6MB/s]\u001b[A\n",
            "model.data:  54% 2.37G/4.40G [01:06<01:01, 33.1MB/s]\u001b[A\n",
            "model.data:  54% 2.38G/4.40G [01:06<00:42, 47.3MB/s]\u001b[A\n",
            "model.data:  54% 2.39G/4.40G [01:06<00:51, 38.9MB/s]\u001b[A\n",
            "model.data:  55% 2.40G/4.40G [01:06<00:55, 35.8MB/s]\u001b[A\n",
            "model.data:  55% 2.42G/4.40G [01:06<00:39, 50.7MB/s]\u001b[A\n",
            "model.data:  55% 2.42G/4.40G [01:07<00:51, 38.5MB/s]\u001b[A\n",
            "model.data:  55% 2.43G/4.40G [01:08<01:28, 22.3MB/s]\u001b[A\n",
            "model.data:  56% 2.45G/4.40G [01:08<00:59, 32.6MB/s]\u001b[A\n",
            "model.data:  56% 2.45G/4.40G [01:08<01:02, 31.2MB/s]\u001b[A\n",
            "model.data:  56% 2.46G/4.40G [01:08<01:07, 28.7MB/s]\u001b[A\n",
            "model.data:  56% 2.48G/4.40G [01:09<00:45, 42.2MB/s]\u001b[A\n",
            "model.data:  57% 2.49G/4.40G [01:09<01:08, 28.0MB/s]\u001b[A\n",
            "model.data:  57% 2.50G/4.40G [01:10<01:08, 27.8MB/s]\u001b[A\n",
            "model.data:  57% 2.51G/4.40G [01:10<00:46, 40.9MB/s]\u001b[A\n",
            "model.data:  57% 2.52G/4.40G [01:10<00:54, 34.3MB/s]\u001b[A\n",
            "model.data:  57% 2.53G/4.40G [01:10<00:58, 32.2MB/s]\u001b[A\n",
            "model.data:  58% 2.54G/4.40G [01:10<00:40, 46.3MB/s]\u001b[A\n",
            "model.data:  58% 2.55G/4.40G [01:11<00:45, 40.5MB/s]\u001b[A\n",
            "model.data:  58% 2.56G/4.40G [01:11<01:06, 27.6MB/s]\u001b[A\n",
            "model.data:  58% 2.58G/4.40G [01:11<00:44, 40.7MB/s]\u001b[A\n",
            "model.data:  59% 2.58G/4.40G [01:12<00:56, 32.3MB/s]\u001b[A\n",
            "model.data:  59% 2.59G/4.40G [01:12<00:55, 32.5MB/s]\u001b[A\n",
            "model.data:  59% 2.61G/4.40G [01:12<00:38, 46.7MB/s]\u001b[A\n",
            "model.data:  59% 2.62G/4.40G [01:13<00:46, 38.7MB/s]\u001b[A\n",
            "model.data:  60% 2.62G/4.40G [01:13<01:03, 27.8MB/s]\u001b[A\n",
            "model.data:  60% 2.64G/4.40G [01:13<00:43, 40.9MB/s]\u001b[A\n",
            "model.data:  60% 2.65G/4.40G [01:14<00:50, 34.9MB/s]\u001b[A\n",
            "model.data:  60% 2.66G/4.40G [01:14<00:53, 32.8MB/s]\u001b[A\n",
            "model.data:  61% 2.67G/4.40G [01:14<00:37, 46.7MB/s]\u001b[A\n",
            "model.data:  61% 2.68G/4.40G [01:14<00:39, 43.9MB/s]\u001b[A\n",
            "model.data:  61% 2.69G/4.40G [01:15<00:49, 34.9MB/s]\u001b[A\n",
            "model.data:  61% 2.70G/4.40G [01:15<00:34, 49.1MB/s]\u001b[A\n",
            "model.data:  62% 2.71G/4.40G [01:15<00:42, 40.1MB/s]\u001b[A\n",
            "model.data:  62% 2.72G/4.40G [01:15<00:47, 35.1MB/s]\u001b[A\n",
            "model.data:  62% 2.73G/4.40G [01:15<00:33, 49.9MB/s]\u001b[A\n",
            "model.data:  62% 2.74G/4.40G [01:16<00:41, 39.7MB/s]\u001b[A\n",
            "model.data:  63% 2.75G/4.40G [01:16<00:51, 32.1MB/s]\u001b[A\n",
            "model.data:  63% 2.77G/4.40G [01:16<00:35, 45.8MB/s]\u001b[A\n",
            "model.data:  63% 2.77G/4.40G [01:17<00:39, 41.2MB/s]\u001b[A\n",
            "model.data:  63% 2.78G/4.40G [01:17<00:45, 35.4MB/s]\u001b[A\n",
            "model.data:  64% 2.80G/4.40G [01:17<00:31, 50.2MB/s]\u001b[A\n",
            "model.data:  64% 2.81G/4.40G [01:17<00:40, 39.3MB/s]\u001b[A\n",
            "model.data:  64% 2.82G/4.40G [01:18<00:46, 33.9MB/s]\u001b[A\n",
            "model.data:  64% 2.83G/4.40G [01:18<00:33, 47.6MB/s]\u001b[A\n",
            "model.data:  64% 2.84G/4.40G [01:18<00:36, 43.2MB/s]\u001b[A\n",
            "model.data:  65% 2.85G/4.40G [01:18<00:37, 41.3MB/s]\u001b[A\n",
            "model.data:  65% 2.86G/4.40G [01:18<00:27, 55.9MB/s]\u001b[A\n",
            "model.data:  65% 2.87G/4.40G [01:20<01:44, 14.6MB/s]\u001b[A\n",
            "model.data:  65% 2.88G/4.40G [01:21<01:32, 16.4MB/s]\u001b[A\n",
            "model.data:  66% 2.89G/4.40G [01:21<01:01, 24.6MB/s]\u001b[A\n",
            "model.data:  66% 2.90G/4.40G [01:21<01:01, 24.3MB/s]\u001b[A\n",
            "model.data:  66% 2.91G/4.40G [01:22<00:58, 25.3MB/s]\u001b[A\n",
            "model.data:  66% 2.93G/4.40G [01:22<00:40, 36.4MB/s]\u001b[A\n",
            "model.data:  67% 2.93G/4.40G [01:24<02:04, 11.8MB/s]\u001b[A\n",
            "model.data:  67% 2.94G/4.40G [01:24<01:43, 14.0MB/s]\u001b[A\n",
            "model.data:  67% 2.96G/4.40G [01:24<01:08, 21.2MB/s]\u001b[A\n",
            "model.data:  67% 2.97G/4.40G [01:25<01:04, 22.2MB/s]\u001b[A\n",
            "model.data:  68% 2.98G/4.40G [01:25<01:02, 22.8MB/s]\u001b[A\n",
            "model.data:  68% 2.99G/4.40G [01:25<00:42, 33.5MB/s]\u001b[A\n",
            "model.data:  68% 3.00G/4.40G [01:26<00:48, 29.2MB/s]\u001b[A\n",
            "model.data:  68% 3.01G/4.40G [01:26<00:48, 28.5MB/s]\u001b[A\n",
            "model.data:  69% 3.02G/4.40G [01:26<00:33, 41.4MB/s]\u001b[A\n",
            "model.data:  69% 3.03G/4.40G [01:26<00:37, 36.6MB/s]\u001b[A\n",
            "model.data:  69% 3.04G/4.40G [01:27<00:42, 31.8MB/s]\u001b[A\n",
            "model.data:  69% 3.06G/4.40G [01:27<00:29, 45.8MB/s]\u001b[A\n",
            "model.data:  70% 3.06G/4.40G [01:27<00:44, 29.8MB/s]\u001b[A\n",
            "model.data:  70% 3.07G/4.40G [01:28<00:46, 28.5MB/s]\u001b[A\n",
            "model.data:  70% 3.09G/4.40G [01:28<00:31, 41.6MB/s]\u001b[A\n",
            "model.data:  70% 3.09G/4.40G [01:28<00:38, 33.8MB/s]\u001b[A\n",
            "model.data:  71% 3.10G/4.40G [01:29<00:42, 30.3MB/s]\u001b[A\n",
            "model.data:  71% 3.12G/4.40G [01:29<00:29, 43.1MB/s]\u001b[A\n",
            "model.data:  71% 3.13G/4.40G [01:29<00:34, 37.2MB/s]\u001b[A\n",
            "model.data:  71% 3.14G/4.40G [01:29<00:35, 36.1MB/s]\u001b[A\n",
            "model.data:  72% 3.15G/4.40G [01:29<00:24, 50.4MB/s]\u001b[A\n",
            "model.data:  72% 3.16G/4.40G [01:30<00:29, 41.5MB/s]\u001b[A\n",
            "model.data:  72% 3.17G/4.40G [01:30<00:33, 36.3MB/s]\u001b[A\n",
            "model.data:  72% 3.18G/4.40G [01:30<00:24, 50.2MB/s]\u001b[A\n",
            "model.data:  72% 3.19G/4.40G [01:30<00:30, 39.1MB/s]\u001b[A\n",
            "model.data:  73% 3.20G/4.40G [01:31<00:38, 31.6MB/s]\u001b[A\n",
            "model.data:  73% 3.21G/4.40G [01:31<00:26, 44.9MB/s]\u001b[A\n",
            "model.data:  73% 3.22G/4.40G [01:31<00:30, 38.4MB/s]\u001b[A\n",
            "model.data:  73% 3.23G/4.40G [01:32<00:32, 35.6MB/s]\u001b[A\n",
            "model.data:  74% 3.25G/4.40G [01:32<00:23, 49.4MB/s]\u001b[A\n",
            "model.data:  74% 3.25G/4.40G [01:32<00:28, 40.7MB/s]\u001b[A\n",
            "model.data:  74% 3.26G/4.40G [01:32<00:30, 37.2MB/s]\u001b[A\n",
            "model.data:  74% 3.28G/4.40G [01:33<00:21, 52.1MB/s]\u001b[A\n",
            "model.data:  75% 3.29G/4.40G [01:33<00:26, 42.7MB/s]\u001b[A\n",
            "model.data:  75% 3.30G/4.40G [01:33<00:29, 37.6MB/s]\u001b[A\n",
            "model.data:  75% 3.31G/4.40G [01:33<00:20, 52.0MB/s]\u001b[A\n",
            "model.data:  75% 3.32G/4.40G [01:33<00:24, 43.5MB/s]\u001b[A\n",
            "model.data:  76% 3.33G/4.40G [01:34<00:37, 28.5MB/s]\u001b[A\n",
            "model.data:  76% 3.34G/4.40G [01:34<00:25, 40.8MB/s]\u001b[A\n",
            "model.data:  76% 3.35G/4.40G [01:34<00:27, 37.9MB/s]\u001b[A\n",
            "model.data:  76% 3.36G/4.40G [01:35<00:30, 34.6MB/s]\u001b[A\n",
            "model.data:  77% 3.37G/4.40G [01:35<00:20, 49.1MB/s]\u001b[A\n",
            "model.data:  77% 3.38G/4.40G [01:35<00:26, 37.9MB/s]\u001b[A\n",
            "model.data:  77% 3.39G/4.40G [01:36<00:31, 32.1MB/s]\u001b[A\n",
            "model.data:  77% 3.41G/4.40G [01:36<00:21, 46.0MB/s]\u001b[A\n",
            "model.data:  78% 3.41G/4.40G [01:37<00:41, 23.7MB/s]\u001b[A\n",
            "model.data:  78% 3.42G/4.40G [01:37<00:40, 24.2MB/s]\u001b[A\n",
            "model.data:  78% 3.44G/4.40G [01:37<00:26, 36.3MB/s]\u001b[A\n",
            "model.data:  78% 3.45G/4.40G [01:37<00:28, 33.5MB/s]\u001b[A\n",
            "model.data:  79% 3.46G/4.40G [01:38<00:29, 31.6MB/s]\u001b[A\n",
            "model.data:  79% 3.47G/4.40G [01:38<00:20, 46.3MB/s]\u001b[A\n",
            "model.data:  79% 3.48G/4.40G [01:38<00:25, 35.5MB/s]\u001b[A\n",
            "model.data:  79% 3.49G/4.40G [01:39<00:28, 31.7MB/s]\u001b[A\n",
            "model.data:  80% 3.50G/4.40G [01:39<00:19, 46.4MB/s]\u001b[A\n",
            "model.data:  80% 3.51G/4.40G [01:39<00:23, 37.4MB/s]\u001b[A\n",
            "model.data:  80% 3.52G/4.40G [01:39<00:23, 37.2MB/s]\u001b[A\n",
            "model.data:  80% 3.53G/4.40G [01:39<00:16, 52.0MB/s]\u001b[A\n",
            "model.data:  80% 3.54G/4.40G [01:40<00:23, 36.8MB/s]\u001b[A\n",
            "model.data:  81% 3.55G/4.40G [01:40<00:26, 32.2MB/s]\u001b[A\n",
            "model.data:  81% 3.57G/4.40G [01:40<00:18, 46.1MB/s]\u001b[A\n",
            "model.data:  81% 3.57G/4.40G [01:41<00:20, 40.9MB/s]\u001b[A\n",
            "model.data:  81% 3.58G/4.40G [01:41<00:23, 34.6MB/s]\u001b[A\n",
            "model.data:  82% 3.60G/4.40G [01:41<00:16, 48.4MB/s]\u001b[A\n",
            "model.data:  82% 3.61G/4.40G [01:42<00:22, 35.3MB/s]\u001b[A\n",
            "model.data:  82% 3.62G/4.40G [01:42<00:24, 32.3MB/s]\u001b[A\n",
            "model.data:  82% 3.63G/4.40G [01:42<00:17, 45.3MB/s]\u001b[A\n",
            "model.data:  83% 3.64G/4.40G [01:42<00:18, 41.0MB/s]\u001b[A\n",
            "model.data:  83% 3.65G/4.40G [01:43<00:19, 39.3MB/s]\u001b[A\n",
            "model.data:  83% 3.66G/4.40G [01:43<00:13, 55.5MB/s]\u001b[A\n",
            "model.data:  83% 3.67G/4.40G [01:43<00:17, 42.7MB/s]\u001b[A\n",
            "model.data:  84% 3.68G/4.40G [01:43<00:20, 34.7MB/s]\u001b[A\n",
            "model.data:  84% 3.70G/4.40G [01:43<00:14, 49.9MB/s]\u001b[A\n",
            "model.data:  84% 3.70G/4.40G [01:44<00:17, 39.6MB/s]\u001b[A\n",
            "model.data:  84% 3.71G/4.40G [01:44<00:21, 31.5MB/s]\u001b[A\n",
            "model.data:  85% 3.73G/4.40G [01:44<00:15, 44.8MB/s]\u001b[A\n",
            "model.data:  85% 3.73G/4.40G [01:45<00:16, 39.4MB/s]\u001b[A\n",
            "model.data:  85% 3.74G/4.40G [01:45<00:18, 35.9MB/s]\u001b[A\n",
            "model.data:  85% 3.76G/4.40G [01:45<00:12, 50.7MB/s]\u001b[A\n",
            "model.data:  86% 3.77G/4.40G [01:45<00:15, 42.2MB/s]\u001b[A\n",
            "model.data:  86% 3.78G/4.40G [01:46<00:16, 37.8MB/s]\u001b[A\n",
            "model.data:  86% 3.79G/4.40G [01:46<00:11, 52.4MB/s]\u001b[A\n",
            "model.data:  86% 3.80G/4.40G [01:46<00:13, 45.0MB/s]\u001b[A\n",
            "model.data:  87% 3.81G/4.40G [01:46<00:14, 40.2MB/s]\u001b[A\n",
            "model.data:  87% 3.82G/4.40G [01:46<00:10, 55.3MB/s]\u001b[A\n",
            "model.data:  87% 3.83G/4.40G [01:47<00:12, 45.6MB/s]\u001b[A\n",
            "model.data:  87% 3.84G/4.40G [01:47<00:14, 39.7MB/s]\u001b[A\n",
            "model.data:  88% 3.85G/4.40G [01:47<00:10, 54.3MB/s]\u001b[A\n",
            "model.data:  88% 3.86G/4.40G [01:47<00:12, 42.6MB/s]\u001b[A\n",
            "model.data:  88% 3.87G/4.40G [01:48<00:13, 38.3MB/s]\u001b[A\n",
            "model.data:  88% 3.89G/4.40G [01:48<00:09, 54.1MB/s]\u001b[A\n",
            "model.data:  88% 3.90G/4.40G [01:48<00:11, 45.4MB/s]\u001b[A\n",
            "model.data:  89% 3.90G/4.40G [01:48<00:12, 39.5MB/s]\u001b[A\n",
            "model.data:  89% 3.92G/4.40G [01:49<00:08, 55.0MB/s]\u001b[A\n",
            "model.data:  89% 3.93G/4.40G [01:49<00:10, 46.8MB/s]\u001b[A\n",
            "model.data:  89% 3.94G/4.40G [01:49<00:14, 33.2MB/s]\u001b[A\n",
            "model.data:  90% 3.95G/4.40G [01:49<00:09, 46.9MB/s]\u001b[A\n",
            "model.data:  90% 3.96G/4.40G [01:50<00:11, 39.7MB/s]\u001b[A\n",
            "model.data:  90% 3.97G/4.40G [01:50<00:12, 34.1MB/s]\u001b[A\n",
            "model.data:  90% 3.98G/4.40G [01:50<00:08, 48.2MB/s]\u001b[A\n",
            "model.data:  91% 3.99G/4.40G [01:50<00:10, 39.7MB/s]\u001b[A\n",
            "model.data:  91% 4.00G/4.40G [01:51<00:10, 37.5MB/s]\u001b[A\n",
            "model.data:  91% 4.01G/4.40G [01:51<00:07, 51.8MB/s]\u001b[A\n",
            "model.data:  91% 4.02G/4.40G [01:51<00:09, 42.0MB/s]\u001b[A\n",
            "model.data:  92% 4.03G/4.40G [01:52<00:10, 35.8MB/s]\u001b[A\n",
            "model.data:  92% 4.05G/4.40G [01:52<00:07, 50.1MB/s]\u001b[A\n",
            "model.data:  92% 4.05G/4.40G [01:52<00:08, 39.2MB/s]\u001b[A\n",
            "model.data:  92% 4.06G/4.40G [01:52<00:09, 34.8MB/s]\u001b[A\n",
            "model.data:  93% 4.08G/4.40G [01:52<00:06, 49.1MB/s]\u001b[A\n",
            "model.data:  93% 4.09G/4.40G [01:53<00:07, 40.1MB/s]\u001b[A\n",
            "model.data:  93% 4.10G/4.40G [01:53<00:08, 35.8MB/s]\u001b[A\n",
            "model.data:  93% 4.11G/4.40G [01:53<00:05, 49.7MB/s]\u001b[A\n",
            "model.data:  94% 4.12G/4.40G [01:54<00:09, 30.0MB/s]\u001b[A\n",
            "model.data:  94% 4.13G/4.40G [01:54<00:09, 28.5MB/s]\u001b[A\n",
            "model.data:  94% 4.14G/4.40G [01:54<00:06, 41.7MB/s]\u001b[A\n",
            "model.data:  94% 4.15G/4.40G [01:55<00:07, 33.7MB/s]\u001b[A\n",
            "model.data:  95% 4.16G/4.40G [01:55<00:08, 27.4MB/s]\u001b[A\n",
            "model.data:  95% 4.18G/4.40G [01:55<00:05, 40.0MB/s]\u001b[A\n",
            "model.data:  95% 4.18G/4.40G [01:56<00:06, 35.4MB/s]\u001b[A\n",
            "model.data:  95% 4.19G/4.40G [01:56<00:06, 32.5MB/s]\u001b[A\n",
            "model.data:  96% 4.21G/4.40G [01:56<00:04, 46.6MB/s]\u001b[A\n",
            "model.data:  96% 4.21G/4.40G [01:56<00:04, 41.5MB/s]\u001b[A\n",
            "model.data:  96% 4.22G/4.40G [01:57<00:04, 37.2MB/s]\u001b[A\n",
            "model.data:  96% 4.24G/4.40G [01:57<00:03, 52.0MB/s]\u001b[A\n",
            "model.data:  96% 4.25G/4.40G [01:57<00:03, 41.2MB/s]\u001b[A\n",
            "model.data:  97% 4.26G/4.40G [01:57<00:03, 37.7MB/s]\u001b[A\n",
            "model.data:  97% 4.27G/4.40G [01:57<00:02, 52.5MB/s]\u001b[A\n",
            "model.data:  97% 4.28G/4.40G [01:58<00:03, 40.2MB/s]\u001b[A\n",
            "model.data:  97% 4.29G/4.40G [01:58<00:03, 34.7MB/s]\u001b[A\n",
            "model.data:  98% 4.30G/4.40G [01:58<00:02, 49.2MB/s]\u001b[A\n",
            "model.data:  98% 4.31G/4.40G [01:59<00:02, 43.6MB/s]\u001b[A\n",
            "model.data:  98% 4.32G/4.40G [01:59<00:02, 40.1MB/s]\u001b[A\n",
            "model.data:  98% 4.34G/4.40G [01:59<00:01, 55.7MB/s]\u001b[A\n",
            "model.data:  99% 4.34G/4.40G [01:59<00:01, 45.3MB/s]\u001b[A\n",
            "model.data:  99% 4.35G/4.40G [02:00<00:01, 36.8MB/s]\u001b[A\n",
            "model.data:  99% 4.37G/4.40G [02:00<00:00, 51.6MB/s]\u001b[A\n",
            "model.data:  99% 4.37G/4.40G [02:00<00:00, 46.3MB/s]\u001b[A\n",
            "model.data: 100% 4.38G/4.40G [02:00<00:00, 36.4MB/s]\u001b[A\n",
            "model.data: 100% 4.40G/4.40G [02:01<00:00, 36.3MB/s]\n",
            "\n",
            "\n",
            "\n",
            "Upload 4 LFS files: 100% 4/4 [02:01<00:00, 30.45s/it]\n",
            "https://huggingface.co/mgoin/TinyLlama-1.1B-Chat-v1.0-pruned50-quant-ds/tree/main/.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Deploy Sparse LLMs with DeepSparse\n",
        "\n",
        "[DeepSparse](https://github.com/neuralmagic/deepsparse) is a CPU inference runtime that takes advantage of sparsity to accelerate neural network inference.\n",
        "\n",
        "LLM inference in DeepSparse is performant with:\n",
        "* sparse kernels for speedups and memory savings from unstructured sparse weights.\n",
        "* 8-bit weight and activation quantization support.\n",
        "* efficient usage of cached attention keys and values for minimal memory movement.\n",
        "\n",
        "In this section we will explore running the sparse quantized TinyLlama we just made to perform a summarization task.\n",
        "\n",
        "First, we need to install DeepSparse with LLM dependencies:"
      ],
      "metadata": {
        "id": "6lYKzSApmI1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepsparse[transformers]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9CUlsp7W6D_M",
        "outputId": "e4ae9033-46d4-4586-bf48-e34bb52ddd81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepsparse[transformers]\n",
            "  Downloading deepsparse-1.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sparsezoo~=1.7.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (1.25.2)\n",
            "Requirement already satisfied: onnx<1.15.0,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (1.14.1)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (1.10.15)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (4.66.2)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (3.20.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (8.1.7)\n",
            "Collecting transformers<4.37 (from deepsparse[transformers])\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets<2.16 in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (2.14.6)\n",
            "Collecting accelerate<0.26 (from deepsparse[transformers])\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (1.2.2)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (1.2.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from deepsparse[transformers]) (0.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.26->deepsparse[transformers]) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<0.26->deepsparse[transformers]) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.26->deepsparse[transformers]) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.26->deepsparse[transformers]) (2.1.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate<0.26->deepsparse[transformers]) (0.17.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.26->deepsparse[transformers]) (0.4.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<2.16->deepsparse[transformers]) (14.0.2)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<2.16->deepsparse[transformers]) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<2.16->deepsparse[transformers]) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<2.16->deepsparse[transformers]) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<2.16->deepsparse[transformers]) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<2.16->deepsparse[transformers]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<2.16->deepsparse[transformers]) (3.9.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx<1.15.0,>=1.5.0->deepsparse[transformers]) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[transformers]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[transformers]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[transformers]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[transformers]) (2024.2.2)\n",
            "Requirement already satisfied: py-machineid>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.7.0->deepsparse[transformers]) (0.5.1)\n",
            "Requirement already satisfied: geocoder>=1.38.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.7.0->deepsparse[transformers]) (1.38.1)\n",
            "Requirement already satisfied: onnxruntime>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.7.0->deepsparse[transformers]) (1.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<4.37->deepsparse[transformers]) (3.13.3)\n",
            "Collecting huggingface-hub (from accelerate<0.26->deepsparse[transformers])\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37->deepsparse[transformers]) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37->deepsparse[transformers]) (0.14.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate->deepsparse[transformers]) (0.18.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepsparse[transformers]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepsparse[transformers]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepsparse[transformers]) (3.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<2.16->deepsparse[transformers]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<2.16->deepsparse[transformers]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<2.16->deepsparse[transformers]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<2.16->deepsparse[transformers]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<2.16->deepsparse[transformers]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<2.16->deepsparse[transformers]) (4.0.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.7.0->deepsparse[transformers]) (0.18.3)\n",
            "Requirement already satisfied: ratelim in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.7.0->deepsparse[transformers]) (0.1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.7.0->deepsparse[transformers]) (1.16.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.0.0->sparsezoo~=1.7.0->deepsparse[transformers]) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.0.0->sparsezoo~=1.7.0->deepsparse[transformers]) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.0.0->sparsezoo~=1.7.0->deepsparse[transformers]) (1.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<2.16->deepsparse[transformers]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<2.16->deepsparse[transformers]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<2.16->deepsparse[transformers]) (2024.1)\n",
            "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers<4.37->deepsparse[transformers])\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (12.4.127)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.0.0->sparsezoo~=1.7.0->deepsparse[transformers]) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate<0.26->deepsparse[transformers]) (2.1.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ratelim->geocoder>=1.38.0->sparsezoo~=1.7.0->deepsparse[transformers]) (4.4.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.0.0->sparsezoo~=1.7.0->deepsparse[transformers]) (1.3.0)\n",
            "Installing collected packages: huggingface-hub, tokenizers, transformers, deepsparse, accelerate\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.17.3\n",
            "    Uninstalling huggingface-hub-0.17.3:\n",
            "      Successfully uninstalled huggingface-hub-0.17.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.14.1\n",
            "    Uninstalling tokenizers-0.14.1:\n",
            "      Successfully uninstalled tokenizers-0.14.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.29.2\n",
            "    Uninstalling accelerate-0.29.2:\n",
            "      Successfully uninstalled accelerate-0.29.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nm-transformers 1.7.0.43401 requires tokenizers<0.15,>=0.14, but you have tokenizers 0.15.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.25.0 deepsparse-1.7.1 huggingface-hub-0.22.2 tokenizers-0.15.2 transformers-4.36.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "accelerate",
                  "huggingface_hub",
                  "transformers"
                ]
              },
              "id": "cc2b66aa36234b40be5d935a8a2079c7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we want to point to our compressed model:"
      ],
      "metadata": {
        "id": "puET8iOJrSpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"exported/deployment/\""
      ],
      "metadata": {
        "id": "AD-FauM-mIfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The task we want to use the LLM for is summarizing some text describing the problem of climate change. Below you can see what the prompt is with the instruction followed by the content to summarize:"
      ],
      "metadata": {
        "id": "M-IcHb1jrXSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_summarize = \"Climate change is a global problem that is affecting the planet in numerous ways. Rising temperatures are causing glaciers to melt, sea levels to rise, and weather patterns to become more extreme. These changes are having a significant impact on ecosystems, agriculture, and human health. In order to mitigate the effects of climate change, it is essential to reduce greenhouse gas emissions by transitioning to renewable energy sources, implementing energy-efficient technologies, and encouraging sustainable practices in various sectors such as transportation and agriculture. Additionally, adapting to the inevitable consequences of climate change is crucial, which involves developing resilient infrastructure, improving disaster preparedness, and supporting vulnerable communities. Addressing climate change requires a coordinated global effort from governments, businesses, and individuals to ensure a sustainable future for the planet and its inhabitants.\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Please summarize the following text, focusing on the key points and main ideas. Keep the summary concise, around 3-5 sentences.\n",
        "\n",
        "Text:\n",
        "{text_to_summarize}\n",
        "\"\"\"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipnRtwu4mIeA",
        "outputId": "c2bf2a47-d21c-4406-a9f4-d64f539e54e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Please summarize the following text, focusing on the key points and main ideas. Keep the summary concise, around 3-5 sentences.\n",
            "\n",
            "Text:\n",
            "Climate change is a global problem that is affecting the planet in numerous ways. Rising temperatures are causing glaciers to melt, sea levels to rise, and weather patterns to become more extreme. These changes are having a significant impact on ecosystems, agriculture, and human health. In order to mitigate the effects of climate change, it is essential to reduce greenhouse gas emissions by transitioning to renewable energy sources, implementing energy-efficient technologies, and encouraging sustainable practices in various sectors such as transportation and agriculture. Additionally, adapting to the inevitable consequences of climate change is crucial, which involves developing resilient infrastructure, improving disaster preparedness, and supporting vulnerable communities. Addressing climate change requires a coordinated global effort from governments, businesses, and individuals to ensure a sustainable future for the planet and its inhabitants.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will format the prompt to work with the chat template that the model was originally fine-tuned with. You can see in the output from this block what the final input to the model will be before tokenization."
      ],
      "metadata": {
        "id": "2KMVdxAIrkg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "chat = [\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "formatted_prompt = tokenizer.apply_chat_template(chat, add_generation_prompt=True, tokenize=False)\n",
        "print(formatted_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpBX-tMJ0qRt",
        "outputId": "64939d16-5c78-4782-bb20-3de051bda07f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|user|>\n",
            "\n",
            "Please summarize the following text, focusing on the key points and main ideas. Keep the summary concise, around 3-5 sentences.\n",
            "\n",
            "Text:\n",
            "Climate change is a global problem that is affecting the planet in numerous ways. Rising temperatures are causing glaciers to melt, sea levels to rise, and weather patterns to become more extreme. These changes are having a significant impact on ecosystems, agriculture, and human health. In order to mitigate the effects of climate change, it is essential to reduce greenhouse gas emissions by transitioning to renewable energy sources, implementing energy-efficient technologies, and encouraging sustainable practices in various sectors such as transportation and agriculture. Additionally, adapting to the inevitable consequences of climate change is crucial, which involves developing resilient infrastructure, improving disaster preparedness, and supporting vulnerable communities. Addressing climate change requires a coordinated global effort from governments, businesses, and individuals to ensure a sustainable future for the planet and its inhabitants.\n",
            "</s>\n",
            "<|assistant|>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline\n",
        "\n",
        "Now let's plug the model and text into DeepSparse. DeepSparse Pipelines are designed to mirror the Hugging Face Transformers API closely, ensuring a familiar experience if you've worked with Transformers before.\n",
        "The following code demonstrates how to create a pipeline for text generation using the sparsified LLM you just made:"
      ],
      "metadata": {
        "id": "KblS5NVX6fyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepsparse import TextGeneration\n",
        "\n",
        "pipeline = TextGeneration(model_path)\n",
        "result = pipeline(formatted_prompt)\n",
        "\n",
        "print(result.generations[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1P6m9s-zgM0",
        "outputId": "9c5e242f-8131-4222-c3c5-d00e39beab8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Climate change is a global problem that affects the planet in numerous ways. Rising temperatures are causing glaciers to melt, sea levels are rising, and weather patterns are becoming more extreme. These changes are having a significant impact on ecosystems, agriculture, and human health. Climat change is essential to mitigate the effects of climate change, which is crucial to mitigate the effects of climate change, which is crucial to mitigate the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting output printed to the console will be the generated text from the model based on the input prompt.\n",
        "\n",
        "### Server\n",
        "\n",
        "To make your LLM accessible as a web service, you'll wrap it in a DeepSparse Server.\n",
        "The Server lets you interact with the model using HTTP requests, making integrating with web applications, microservices, or other systems easy.\n",
        "DeepSparse Server has an [OpenAI-compatible integration](https://platform.openai.com/docs/api-reference/completions) for request and response formats for seamless integration.\n",
        "\n",
        "First we need to install the server dependencies with DeepSparse:\n"
      ],
      "metadata": {
        "id": "MAkPlLIz6nK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"deepsparse[server]\" -qqqqq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgIbxpyG8qQT",
        "outputId": "6bcd4a39-3a8e-4a93-a082-f1e9ee2df37e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following command starts a DeepSparse Server with the sparsified LLM:"
      ],
      "metadata": {
        "id": "vIWa8K7z8qCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!deepsparse.server --integration openai \"hf:mgoin/TinyLlama-1.1B-Chat-v1.0-pruned50-quant-ds\""
      ],
      "metadata": {
        "id": "RvhvsGU16VLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the server running, you can send an HTTP request that conforms to the OpenAI spec to generate text. You can go to http://localhost:5543/docs to learn more about the available endpoints.\n",
        "\n",
        "Below are examples of using `curl` and `python` to send a request to the server:"
      ],
      "metadata": {
        "id": "5B3gm02S6zl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "url = \"http://localhost:5543/v1/chat/completions\"\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "data = {\n",
        "    \"model\": \"hf:mgoin/TinyLlama-1.1B-Chat-v1.0-pruned50-quant-ds\",\n",
        "    \"messages\": \"Large language models are\",\n",
        "    \"stream\": True\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
        "\n",
        "if response.status_code == 200:\n",
        "    for chunk in response.iter_content(chunk_size=128):\n",
        "        print(chunk.decode('utf-8'))  # Decode and print each data chunk\n",
        "else:\n",
        "    print(\"Request failed with status code:\", response.status_code)"
      ],
      "metadata": {
        "id": "zBmXW51560bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl http://localhost:5543/v1/chat/completions \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"model\": \"hf:mgoin/TinyLlama-1.1B-Chat-v1.0-pruned50-quant-ds\", \"prompt\": \"Say this is a test\", \"stream\": true}'"
      ],
      "metadata": {
        "id": "i-GYNuGG64UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting output will be the generated text from the model based on the input prompt.\n"
      ],
      "metadata": {
        "id": "atdML2wr6-sg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dp-srnN5-Z2r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}