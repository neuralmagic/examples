{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DeepSparse MPT-Instruct Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install via the nightly build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepsparse-nightly[llm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Download and Compile Model**\n",
    "\n",
    "The following downloads a pre-sparsified MPT-Instruct model from our SparseZoo and compiles the model. \n",
    "\n",
    "> Note: It will take a minute or two to compile even if the model is already downloaded, so try to reuse a pipeline as much as possible once its been set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robertgshaw/examples/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "2023-11-09 17:06:31 deepsparse.transformers.pipelines.text_generation INFO     Compiling an auxiliary engine to process a prompt with a larger processing length. This improves performance, but may result in additional memory consumption.\n",
      "DeepSparse, Copyright 2021-present / Neuralmagic, Inc. version: 1.6.0.20231031 COMMUNITY | (74098695) (release) (optimized) (system=avx512_vnni, binary=avx512)\n"
     ]
    }
   ],
   "source": [
    "from deepsparse import TextGeneration\n",
    "\n",
    "pipeline = TextGeneration(model=\"zoo:mpt-7b-dolly_mpt_pretrain-pruned50_quantized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Text**\n",
    "\n",
    "We can now call the pipeline to generate a response to a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are a number of ways to travel from London to Edinburgh. You can take a direct flight from London to Edinburgh, which will take around 1 hour and 20 minutes. Alternatively, you can take the Eurostar train from London to Edinburgh, which will take around 2 hours and 30 minutes. You can also drive from London to Edinburgh, which will take around 8 hours.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: How best should I travel from London to Edinburgh, UK ? ### Response:\"\n",
    "\n",
    "output = pipeline(prompt, max_new_tokens=100)\n",
    "print(output.generations[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stream responses with the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: How best should I travel from London to Edinburgh, UK ? ### Response:\n",
      "\n",
      " There are a number of ways to travel from London to Edinburgh. You can take a direct flight from London to Edinburgh, which will take around 1 hour and 20 minutes. Alternatively, you can take the Eurostar train from London to Edinburgh, which will take around 2 hours and 30 minutes. You can also drive from London to Edinburgh, which will take around 8 hours.<|endoftext|>"
     ]
    }
   ],
   "source": [
    "output_iterator = pipeline(prompt=prompt, streaming=True, max_new_tokens=100)\n",
    "\n",
    "print(prompt, end=\"\\n\\n\")\n",
    "for it in output_iterator:\n",
    "    print(it.generations[0].text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [our documentation](https://github.com/neuralmagic/deepsparse/blob/main/docs/llms/text-generation-pipeline.md) for details on how to customize generation strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(examples):\n",
    "    instruction_str = \"What are three additional example questions that have the same semantic meaning as the questions listed below?\\n\\n\"\n",
    "    for idx, example in enumerate(examples):\n",
    "        instruction_str += (f\"EXAMPLE {(idx+1)}: {example}\\n\")\n",
    "\n",
    "    return instruction_str\n",
    "\n",
    "\n",
    "INSTRUCTION_KEY = \"### Instruction:\"\n",
    "RESPONSE_KEY = \"### Response:\"\n",
    "INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
    "{instruction_key}\n",
    "{instruction}\n",
    "{response_key}\n",
    "\"\"\".format(\n",
    "    intro=INTRO_BLURB,\n",
    "    instruction_key=INSTRUCTION_KEY,\n",
    "    instruction=\"{instruction}\",\n",
    "    response_key=RESPONSE_KEY,\n",
    ")\n",
    "\n",
    "def format_prompt(examples):\n",
    "    return PROMPT_FOR_GENERATION_FORMAT.format(instruction=format_instruction(examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "### Instruction:\n",
      "What are three additional example questions that have the same semantic meaning as the questions listed below?\n",
      "\n",
      "EXAMPLE 1: How much does a new business permit cost?\n",
      "EXAMPLE 2: What is the price of a business permit?\n",
      "EXAMPLE 3: What are the fees for obtaining a new business license?\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    \"How much does a new business permit cost?\",\n",
    "    \"What is the price of a business permit?\",\n",
    "    \"What are the fees for obtaining a new business license?\",\n",
    "]\n",
    "\n",
    "prompt = format_prompt(examples)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "### Instruction:\n",
      "What are three additional example questions that have the same semantic meaning as the questions listed below?\n",
      "\n",
      "EXAMPLE 1: How much does a new business permit cost?\n",
      "EXAMPLE 2: What is the price of a business permit?\n",
      "EXAMPLE 3: What are the fees for obtaining a new business license?\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "Three additional example questions that have the same semantic meaning as the questions listed below are:\n",
      "\n",
      "EXAMPLE 1: How much does a business license cost?\n",
      "EXAMPLE 2: What is the price of a business license?\n",
      "EXAMPLE 3: What are the fees for renewing a business license?<|endoftext|>"
     ]
    }
   ],
   "source": [
    "output_iterator = pipeline(prompt=prompt, streaming=True, max_new_tokens=200, do_sample=False)\n",
    "\n",
    "print(prompt, end=\"\\n\\n\")\n",
    "for it in output_iterator:\n",
    "    print(it.generations[0].text, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
